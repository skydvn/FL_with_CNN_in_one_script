{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bound-active",
   "metadata": {},
   "source": [
    "# Initial Setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "worldwide-swing",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-19T09:03:01.329110Z",
     "start_time": "2021-02-19T09:02:59.407279Z"
    }
   },
   "outputs": [],
   "source": [
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import random\n",
    "\n",
    "FRACTION=0.02\n",
    "BATCH_SIZE = 10 # inf = -1\n",
    "NUM_EPOCHS = 5 # fixed!\n",
    "TRAINING_ROUNDS=2\n",
    "\n",
    "CLIENTS_SHUFFLE_PER_ROUND=False\n",
    "#CLIENTS_SHUFFLE_PER_ROUND=True "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "computational-lover",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-19T09:03:01.339083Z",
     "start_time": "2021-02-19T09:03:01.330107Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parameter_set_20210219180301 directory is created in D:\\jupyter\\fed_network_framework\\FL_in_one_script\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import sys\n",
    "import csv\n",
    "\n",
    "class ParameterSaver:\n",
    "    def __init__(self):\n",
    "        self.save_path = os.getcwd()\n",
    "        \n",
    "        now = time.localtime()\n",
    "        self.directory_name = \"parameter_set_\"+\"%04d%02d%02d%02d%02d%02d\" % (now.tm_year, now.tm_mon, now.tm_mday, now.tm_hour, now.tm_min, now.tm_sec)\n",
    "        \n",
    "        os.mkdir(os.path.join(self.save_path, self.directory_name))\n",
    "        print(f\"{self.directory_name} directory is created in {self.save_path}\")\n",
    "        \n",
    "        self.current_round_directory_name=\"\"\n",
    "\n",
    "    def save_initial_parameter(self, initial_parameter) :\n",
    "        np.savetxt(os.path.join(self.save_path, self.directory_name, \"initial_parameter.csv\"), initial_parameter, fmt='%s', delimiter=',')\n",
    "        \n",
    "    def round_start(self, round_number):\n",
    "        self.current_round_directory_name=f\"round_{round_number:06d}\"\n",
    "        os.mkdir(os.path.join(self.save_path, self.directory_name, self.current_round_directory_name))\n",
    "        \n",
    "    def save_local_parameter(self, client_id, local_parameter) :\n",
    "        np.savetxt(os.path.join(self.save_path, self.directory_name, self.current_round_directory_name, f\"local_parameter_cli_{client_id}.csv\"), local_parameter, fmt='%s', delimiter=',')\n",
    "        \n",
    "    def save_aggreated_global_parameter(self, aggregated_global_parameter) :\n",
    "        np.savetxt(os.path.join(self.save_path, self.directory_name, self.current_round_directory_name, f\"aggregated_global_parameter.csv\"), aggregated_global_parameter, fmt='%s', delimiter=',')\n",
    "\n",
    "        \n",
    "#---------------------------------------------------------------------------------\n",
    "parameter_saver= ParameterSaver() # make directory for saving parameter set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "excellent-provision",
   "metadata": {},
   "source": [
    "# Make Preprocessed-(I.I.D)Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "massive-tradition",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-19T09:03:01.888738Z",
     "start_time": "2021-02-19T09:03:01.343073Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mnist_train, mnist_test = tf.keras.datasets.mnist.load_data() # This dataset is not \"E\"mnist. Don't confuse!\n",
    "\n",
    "raw_dataset_for_iid=list(zip(mnist_train[0].reshape(-1, 28, 28, 1).astype(\"float32\")/255.0, mnist_train[1].astype(\"float32\")))\n",
    "random.shuffle(raw_dataset_for_iid)\n",
    "\n",
    "el_size=600\n",
    "temp_list_for_image=[]\n",
    "temp_list_for_label=[]\n",
    "federated_train_data_for_iid=[]\n",
    "for idx, el in enumerate(raw_dataset_for_iid) :\n",
    "    temp_list_for_image.append(el[0])\n",
    "    temp_list_for_label.append(el[1])\n",
    "    if (idx+1)%(el_size)==0 :\n",
    "        federated_train_data_for_iid.append((np.array(temp_list_for_image, dtype=\"float32\"), np.array(temp_list_for_label, dtype=\"float32\")))\n",
    "        temp_list_for_image=[]\n",
    "        temp_list_for_label=[]\n",
    "        \n",
    "federated_train_data = federated_train_data_for_iid"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "stupid-preparation",
   "metadata": {},
   "source": [
    "# Make MNIST-CNN 99% model using Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "greenhouse-pacific",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-19T09:03:01.996355Z",
     "start_time": "2021-02-19T09:03:01.889610Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 28, 28, 32)        832       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 14, 14, 64)        51264     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 7, 7, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 3136)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 512)               1606144   \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 1,663,370\n",
      "Trainable params: 1,663,370\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "keras_model= tf.keras.models.Sequential([\n",
    "    tf.keras.Input(shape=(28, 28, 1)),\n",
    "    tf.keras.layers.Conv2D(32, kernel_size=(5, 5), activation=\"relu\", padding='same'),\n",
    "    tf.keras.layers.MaxPooling2D(pool_size=(2, 2), padding='same'),\n",
    "    \n",
    "    tf.keras.layers.Conv2D(64, kernel_size=(5, 5), activation=\"relu\", padding='same'),\n",
    "    tf.keras.layers.MaxPooling2D(pool_size=(2, 2), padding='same'),\n",
    "    \n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(512, activation='relu'),\n",
    "    tf.keras.layers.Dense(10, activation=\"softmax\"),\n",
    "])\n",
    "\n",
    "keras_model.summary()\n",
    "\n",
    "keras_model.compile(\n",
    "    optimizer = 'adam',\n",
    "    loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "    metrics = ['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "neutral-request",
   "metadata": {},
   "source": [
    "# Start Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "unlikely-morocco",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-19T09:03:15.877185Z",
     "start_time": "2021-02-19T09:03:01.997351Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total client : 100 , selected client : 2\n",
      "-- prameter shape --\n",
      "(5, 5, 1, 32)\n",
      "(32,)\n",
      "(5, 5, 32, 64)\n",
      "(64,)\n",
      "(3136, 512)\n",
      "(512,)\n",
      "(512, 10)\n",
      "(10,)\n",
      "\n",
      "▶ Round 1 ◀\n",
      "selected clients : [62  9]\n",
      "    clint ID : 62 training complete.\n",
      "        accuracy : 0.7599999904632568 - loss : 1.7014524936676025\n",
      "    clint ID : 9 training complete.\n",
      "        accuracy : 0.9233333468437195 - loss : 1.548226237297058\n",
      "  evaluation mean : accuracy - 0.8416666984558105, loss - 1.6248393058776855\n",
      "\n",
      "▶ Round 2 ◀\n",
      "selected clients : [62  9]\n",
      "    clint ID : 62 training complete.\n",
      "        accuracy : 0.9733333587646484 - loss : 1.489459753036499\n",
      "    clint ID : 9 training complete.\n",
      "        accuracy : 0.9616666436195374 - loss : 1.502359390258789\n",
      "  evaluation mean : accuracy - 0.9674999713897705, loss - 1.495909571647644\n",
      "\n",
      "\n",
      "▶▶▶ Round is over.\n"
     ]
    }
   ],
   "source": [
    "TOTAL_CLIENTS = len(federated_train_data)\n",
    "SELECTED_CLIENTS = int(TOTAL_CLIENTS*FRACTION)\n",
    "print(\"total client :\", TOTAL_CLIENTS, \", selected client :\", SELECTED_CLIENTS)\n",
    "\n",
    "# starting to training\n",
    "selected_clients_list=clients_status_list=np.random.choice(TOTAL_CLIENTS, size=SELECTED_CLIENTS, replace=False) # that is relevant to 4-2 step.\n",
    "\n",
    "global_parameter=keras_model.get_weights()\n",
    "parameter_saver.save_initial_parameter(global_parameter)\n",
    "\n",
    "print(\"-- prameter shape --\")\n",
    "for layer in global_parameter :\n",
    "    print(layer.shape)\n",
    "\n",
    "list_of_local_parameter=[]\n",
    "list_of_local_dataset_size=[]\n",
    "list_of_local_accuracy=[]\n",
    "list_of_local_loss=[]\n",
    "\n",
    "for round in range(TRAINING_ROUNDS) :\n",
    "    print(\"\\n▶ Round\", round+1, \"◀\")\n",
    "    parameter_saver.round_start(round+1)\n",
    "    \n",
    "        # check whether to apply shuffle mode per round\n",
    "    if CLIENTS_SHUFFLE_PER_ROUND == True :\n",
    "        selected_clients_list = np.random.choice(TOTAL_CLIENTS, size=SELECTED_CLIENTS, replace=False)\n",
    "    print(\"selected clients :\", selected_clients_list)\n",
    "\n",
    "        # recevie Local parameter.\n",
    "    for client_dataset in selected_clients_list :\n",
    "        train_images, train_labels=federated_train_data[client_dataset]\n",
    "        \n",
    "        keras_model.set_weights(global_parameter)\n",
    "        \n",
    "        train_result=keras_model.fit(train_images, train_labels, batch_size=BATCH_SIZE, epochs=NUM_EPOCHS, verbose=0)\n",
    "            \n",
    "        local_parameter=keras_model.get_weights()\n",
    "        list_of_local_parameter.append(local_parameter)\n",
    "        parameter_saver.save_local_parameter(client_dataset, local_parameter)\n",
    "        list_of_local_dataset_size.append(len(train_images))\n",
    "        list_of_local_accuracy.append(train_result.history[\"accuracy\"][-1])\n",
    "        list_of_local_loss.append(train_result.history[\"loss\"][-1])\n",
    "        \n",
    "        print(\"    clint ID :\", client_dataset, \"training complete.\")\n",
    "        print(\"        accuracy :\", train_result.history[\"accuracy\"][-1], \"- loss :\", train_result.history[\"loss\"][-1])\n",
    "    \n",
    "        #4-5. aggregate Local parameters.\n",
    "    global_parameter = np.mean(list_of_local_parameter, axis=0)\n",
    "    #global_parameter = np.mean(list_of_local_parameter, axis=0)*np.sum(list_of_local_dataset_size)\n",
    "    #print(\"global_parameter :\",global_parameter)\n",
    "    parameter_saver.save_aggreated_global_parameter(global_parameter)\n",
    "    current_mean_accuracy = np.mean(np.array(list_of_local_accuracy, dtype=\"float32\"))\n",
    "    current_mean_loss = np.mean(np.array(list_of_local_loss, dtype=\"float32\"))\n",
    "    print(f\"  evaluation mean : accuracy - {current_mean_accuracy}, loss - {current_mean_loss}\")   \n",
    "    \n",
    "    list_of_local_parameter.clear()\n",
    "    list_of_local_dataset_size.clear()\n",
    "    list_of_local_accuracy.clear()\n",
    "    list_of_local_loss.clear()\n",
    "    \n",
    "print(\"\\n\\n▶▶▶ Round is over.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
