{
    "# Initial Setting"
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": false
    },
    "colab": {
      "name": "FL_with_CNN_in_one_script.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bound-active"
      },
      "source": [
        "# Initial Setting"
      ],
      "id": "bound-active"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zz7x2v6oaPwl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fd980bff-91a8-4ae6-f553-b27aa4061db7"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive',force_remount=True)"
      ],
      "id": "Zz7x2v6oaPwl",
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-02-19T09:03:01.329110Z",
          "start_time": "2021-02-19T09:02:59.407279Z"
        },
        "id": "worldwide-swing"
      },
      "source": [
        "import nest_asyncio\n",
        "nest_asyncio.apply()\n",
        "\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import random\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "FRACTION=0.1\n",
        "BATCH_SIZE = 10 # inf = -1\n",
        "NUM_EPOCHS = 5 # fixed!\n",
        "TRAINING_ROUNDS= 45\n",
        "\n",
        "CLIENTS_SHUFFLE_PER_ROUND=False\n",
        "#CLIENTS_SHUFFLE_PER_ROUND=True "
      ],
      "id": "worldwide-swing",
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-02-19T09:03:01.339083Z",
          "start_time": "2021-02-19T09:03:01.330107Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "computational-lover",
        "outputId": "b13d8d6c-7037-4238-e7a1-afd2ee07ff7a"
      },
      "source": [
        "import os\n",
        "import time\n",
        "import sys\n",
        "import csv\n",
        "\n",
        "class ParameterSaver:\n",
        "    def __init__(self):\n",
        "        self.save_path = \"/content/drive/MyDrive/Federated-Learning/fl-model-parameters-dataset\"\n",
        "        \n",
        "        now = time.localtime()\n",
        "        self.directory_name = \"parameter_set_\"+\"%04d%02d%02d%02d%02d%02d\" % (now.tm_year, now.tm_mon, now.tm_mday, now.tm_hour, now.tm_min, now.tm_sec)\n",
        "        \n",
        "        os.mkdir(os.path.join(self.save_path, self.directory_name))\n",
        "        print(f\"{self.directory_name} directory is created in {self.save_path}\")\n",
        "        \n",
        "        self.current_round_directory_name=\"\"\n",
        "\n",
        "    def save_initial_parameter(self, initial_parameter) :\n",
        "        np.savetxt(os.path.join(self.save_path, self.directory_name, \"initial_parameter.csv\"), initial_parameter, fmt='%s', delimiter=',')\n",
        "        \n",
        "    def round_start(self, round_number):\n",
        "        self.current_round_directory_name=f\"round_{round_number:06d}\"\n",
        "        os.mkdir(os.path.join(self.save_path, self.directory_name, self.current_round_directory_name))\n",
        "        \n",
        "    def save_local_parameter(self, client_id, local_parameter) :\n",
        "        #np.savetxt(os.path.join(self.save_path, self.directory_name, self.current_round_directory_name, f\"local_parameter_cli_{client_id}.csv\"), local_parameter, fmt='%s', delimiter=',')\n",
        "        # Each Sheet, split to 2D (axa) width + b (height)\n",
        "        # 1st: [5*5=25 width] x [32 height] + [32 height]\n",
        "        temp1 = local_parameter[0].reshape(25,32)\n",
        "        temp2 = local_parameter[1].reshape(1,32)\n",
        "        sheet1 = np.concatenate((temp1,temp2))\n",
        "        df_sheet1 = pd.DataFrame(sheet1)\n",
        "        # 2nd: [5*5*32 width] x [64 height] + [64 height]\n",
        "        temp1 = local_parameter[2].reshape(5*5*32,64)\n",
        "        temp2 = local_parameter[3].reshape(1,64)\n",
        "        sheet2 = np.concatenate((temp1,temp2))\n",
        "        df_sheet2 = pd.DataFrame(sheet2)\n",
        "        #sheet2 = local_parameter[1].reshape(5*5*32 + 64)\n",
        "        # 3rd: [3136 width] * [512 height] + [512 height]\n",
        "        temp1 = local_parameter[4].reshape(3136,512)\n",
        "        temp2 = local_parameter[5].reshape(1,512)\n",
        "        sheet3 = np.concatenate((temp1,temp2))\n",
        "        df_sheet3 = pd.DataFrame(sheet3)\n",
        "        # 4th: [512 width] * [10 height] + [10 height]\n",
        "        temp1 = local_parameter[6].reshape(512,10)\n",
        "        temp2 = local_parameter[7].reshape(1,10)\n",
        "        sheet4 = np.concatenate((temp1,temp2)) \n",
        "        df_sheet4 = pd.DataFrame(sheet4)\n",
        "        with pd.ExcelWriter(os.path.join(self.save_path, self.directory_name, self.current_round_directory_name, f\"local_parameter_cli_{client_id}.xlsx\")) as writer:  \n",
        "            df_sheet1.to_excel(writer, sheet_name='conv_layer1')\n",
        "            df_sheet2.to_excel(writer, sheet_name='conv_layer2')\n",
        "            df_sheet3.to_excel(writer, sheet_name='dense_1')\n",
        "            df_sheet4.to_excel(writer, sheet_name='dense_2')\n",
        "    def save_aggreated_global_parameter(self, aggregated_global_parameter) :\n",
        "        # np.savetxt(os.path.join(self.save_path, self.directory_name, self.current_round_directory_name, f\"aggregated_global_parameter.csv\"), aggregated_global_parameter, fmt='%s', delimiter=',')\n",
        "        temp1 = local_parameter[0].reshape(25,32)\n",
        "        temp2 = local_parameter[1].reshape(1,32)\n",
        "        sheet1 = np.concatenate((temp1,temp2))\n",
        "        df_sheet1 = pd.DataFrame(sheet1)\n",
        "        # 2nd: [5*5*32 width] x [64 height] + [64 height]\n",
        "        temp1 = local_parameter[2].reshape(5*5*32,64)\n",
        "        temp2 = local_parameter[3].reshape(1,64)\n",
        "        sheet2 = np.concatenate((temp1,temp2))\n",
        "        df_sheet2 = pd.DataFrame(sheet2)\n",
        "        #sheet2 = local_parameter[1].reshape(5*5*32 + 64)\n",
        "        # 3rd: [3136 width] * [512 height] + [512 height]\n",
        "        temp1 = local_parameter[4].reshape(3136,512)\n",
        "        temp2 = local_parameter[5].reshape(1,512)\n",
        "        sheet3 = np.concatenate((temp1,temp2))\n",
        "        df_sheet3 = pd.DataFrame(sheet3)\n",
        "        # 4th: [512 width] * [10 height] + [10 height]\n",
        "        temp1 = local_parameter[6].reshape(512,10)\n",
        "        temp2 = local_parameter[7].reshape(1,10)\n",
        "        sheet4 = np.concatenate((temp1,temp2)) \n",
        "        df_sheet4 = pd.DataFrame(sheet4)\n",
        "        with pd.ExcelWriter(os.path.join(self.save_path, self.directory_name, self.current_round_directory_name, f\"aggregated_global_parameter.xlsx\")) as writer:  \n",
        "            df_sheet1.to_excel(writer, sheet_name='conv_layer1')\n",
        "            df_sheet2.to_excel(writer, sheet_name='conv_layer2')\n",
        "            df_sheet3.to_excel(writer, sheet_name='dense_1')\n",
        "            df_sheet4.to_excel(writer, sheet_name='dense_2')\n",
        "\n",
        "\n",
        "        \n",
        "#---------------------------------------------------------------------------------\n",
        "parameter_saver= ParameterSaver() # make directory for saving parameter set"
      ],
      "id": "computational-lover",
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "parameter_set_20210227075510 directory is created in /content/drive/MyDrive/Federated-Learning/fl-model-parameters-dataset\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GzPT6w_SiM1W"
      },
      "source": [
        "class DatasetReader:\r\n",
        "    def __init__(self):\r\n",
        "      self.load_path = \"/content/drive/MyDrive/Federated-Learning/fl-model-parameters-dataset\"\r\n",
        "      \r\n",
        "    def load_dataset(self) :\r\n",
        "      for root, dirs, files in os.walk(self.load_path, topdown=False):\r\n",
        "        for name in files:\r\n",
        "          # print(os.path.join(root, name))\r\n",
        "          link = os.path.join(root, name)\r\n",
        "          dfr_sheet1 = pd.read_excel(open(link, 'rb'), index_col=0, sheet_name='conv_layer1')  \r\n",
        "          dfr_sheet2 = pd.read_excel(open(link, 'rb'), index_col=0, sheet_name='conv_layer2')  \r\n",
        "          dfr_sheet3 = pd.read_excel(open(link, 'rb'), index_col=0, sheet_name='dense_1')  \r\n",
        "          dfr_sheet4 = pd.read_excel(open(link, 'rb'), index_col=0, sheet_name='dense_2')  \r\n",
        "          dfr_array1 = dfr_sheet1.to_numpy()\r\n",
        "          dfr_array2 = dfr_sheet2.to_numpy()\r\n",
        "          dfr_array3 = dfr_sheet3.to_numpy()\r\n",
        "          dfr_array4 = dfr_sheet4.to_numpy()\r\n",
        "\r\n",
        "          # original model parameter reconstruct here\r\n",
        "          conv1_net = dfr_array1[0:25]\r\n",
        "          conv1_net = conv1_net.reshape(5,5,1,32)\r\n",
        "\r\n",
        "          conv1_out = dfr_array1[25]\r\n",
        "          conv1_out = conv1_out.reshape(32,)\r\n",
        "\r\n",
        "          conv2_net = dfr_array2[0:800]\r\n",
        "          conv2_net = conv2_net.reshape(5,5,32,64)\r\n",
        "\r\n",
        "          conv2_out = dfr_array2[800]\r\n",
        "          conv2_out = conv2_out.reshape(64,)\r\n",
        "\r\n",
        "          dense1_net = dfr_array3[0:3136]\r\n",
        "          dense1_net = dense1_net.reshape(3136,512)\r\n",
        "\r\n",
        "          dense1_out = dfr_array3[3136]\r\n",
        "          dense1_out = dense1_out.reshape(512,)\r\n",
        "\r\n",
        "          dense2_net = dfr_array4[0:512]\r\n",
        "          dense2_net = dense2_net.reshape(512,10)\r\n",
        "\r\n",
        "          dense2_out = dfr_array4[512]\r\n",
        "          dense2_out = dense2_out.reshape(10,)\r\n",
        "          return reconstructed_list = [conv1_net,conv1_out,conv2_net,conv2_out,dense1_net,dense1_out,dense2_net,dense2_out]"
      ],
      "id": "GzPT6w_SiM1W",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZwX_kXKSoaul"
      },
      "source": [
        "# Model parameters Array(Layer) split"
      ],
      "id": "ZwX_kXKSoaul"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "excellent-provision"
      },
      "source": [
        "# Make Preprocessed-(I.I.D)Dataset"
      ],
      "id": "excellent-provision"
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-02-19T09:03:01.888738Z",
          "start_time": "2021-02-19T09:03:01.343073Z"
        },
        "scrolled": true,
        "id": "massive-tradition"
      },
      "source": [
        "mnist_train, mnist_test = tf.keras.datasets.mnist.load_data() # This dataset is not \"E\"mnist. Don't confuse!\n",
        "\n",
        "raw_dataset_for_iid=list(zip(mnist_train[0].reshape(-1, 28, 28, 1).astype(\"float32\")/255.0, mnist_train[1].astype(\"float32\")))\n",
        "random.shuffle(raw_dataset_for_iid)\n",
        "\n",
        "el_size=600\n",
        "temp_list_for_image=[]\n",
        "temp_list_for_label=[]\n",
        "federated_train_data_for_iid=[]\n",
        "for idx, el in enumerate(raw_dataset_for_iid) :\n",
        "    temp_list_for_image.append(el[0])\n",
        "    temp_list_for_label.append(el[1])\n",
        "    if (idx+1)%(el_size)==0 :\n",
        "        federated_train_data_for_iid.append((np.array(temp_list_for_image, dtype=\"float32\"), np.array(temp_list_for_label, dtype=\"float32\")))\n",
        "        temp_list_for_image=[]\n",
        "        temp_list_for_label=[]\n",
        "        \n",
        "federated_train_data = federated_train_data_for_iid"
      ],
      "id": "massive-tradition",
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "stupid-preparation"
      },
      "source": [
        "# Make MNIST-CNN 99% model using Keras"
      ],
      "id": "stupid-preparation"
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-02-19T09:03:01.996355Z",
          "start_time": "2021-02-19T09:03:01.889610Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "greenhouse-pacific",
        "outputId": "12fb8d46-71de-4b6f-d038-063761466520"
      },
      "source": [
        "keras_model= tf.keras.models.Sequential([\n",
        "    tf.keras.Input(shape=(28, 28, 1)),\n",
        "    tf.keras.layers.Conv2D(32, kernel_size=(5, 5), activation=\"relu\", padding='same'),\n",
        "    tf.keras.layers.MaxPooling2D(pool_size=(2, 2), padding='same'),\n",
        "    \n",
        "    tf.keras.layers.Conv2D(64, kernel_size=(5, 5), activation=\"relu\", padding='same'),\n",
        "    tf.keras.layers.MaxPooling2D(pool_size=(2, 2), padding='same'),\n",
        "    \n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dense(512, activation='relu'),\n",
        "    tf.keras.layers.Dense(10, activation=\"softmax\"),\n",
        "])\n",
        "\n",
        "keras_model.summary()\n",
        "\n",
        "keras_model.compile(\n",
        "    optimizer = 'adam',\n",
        "    loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "    metrics = ['accuracy']\n",
        ")"
      ],
      "id": "greenhouse-pacific",
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_2 (Conv2D)            (None, 28, 28, 32)        832       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 14, 14, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 14, 14, 64)        51264     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2 (None, 7, 7, 64)          0         \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 3136)              0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 512)               1606144   \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 10)                5130      \n",
            "=================================================================\n",
            "Total params: 1,663,370\n",
            "Trainable params: 1,663,370\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "neutral-request"
      },
      "source": [
        "# Start Training"
      ],
      "id": "neutral-request"
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-02-19T09:03:15.877185Z",
          "start_time": "2021-02-19T09:03:01.997351Z"
        },
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "unlikely-morocco",
        "outputId": "a8a820ff-e32c-46b0-e437-f1ecd6f6d829"
      },
      "source": [
        "TOTAL_CLIENTS = len(federated_train_data)\n",
        "SELECTED_CLIENTS = int(TOTAL_CLIENTS*FRACTION)\n",
        "print(\"total client :\", TOTAL_CLIENTS, \", selected client :\", SELECTED_CLIENTS)\n",
        "\n",
        "# starting to training\n",
        "selected_clients_list=clients_status_list=np.random.choice(TOTAL_CLIENTS, size=SELECTED_CLIENTS, replace=False) # that is relevant to 4-2 step.\n",
        "\n",
        "global_parameter=keras_model.get_weights()\n",
        "parameter_saver.save_initial_parameter(global_parameter)\n",
        "\n",
        "print(\"-- prameter shape --\")\n",
        "for layer in global_parameter :\n",
        "    print(layer.shape)\n",
        "\n",
        "list_of_local_parameter=[]\n",
        "list_of_local_dataset_size=[]\n",
        "list_of_local_accuracy=[]\n",
        "list_of_local_loss=[]\n",
        "\n",
        "for round in range(TRAINING_ROUNDS) :\n",
        "    print(\"\\n▶ Round\", round+1, \"◀\")\n",
        "    parameter_saver.round_start(round+1)\n",
        "    \n",
        "        # check whether to apply shuffle mode per round\n",
        "    if CLIENTS_SHUFFLE_PER_ROUND == True :\n",
        "        selected_clients_list = np.random.choice(TOTAL_CLIENTS, size=SELECTED_CLIENTS, replace=False)\n",
        "    print(\"selected clients :\", selected_clients_list)\n",
        "\n",
        "        # receive Local parameter.\n",
        "    for client_dataset in selected_clients_list :\n",
        "        train_images, train_labels=federated_train_data[client_dataset]\n",
        "        \n",
        "        keras_model.set_weights(global_parameter)\n",
        "        \n",
        "        train_result=keras_model.fit(train_images, train_labels, batch_size=BATCH_SIZE, epochs=NUM_EPOCHS, verbose=0)\n",
        "            \n",
        "        local_parameter=keras_model.get_weights()\n",
        "        list_of_local_parameter.append(local_parameter)\n",
        "        parameter_saver.save_local_parameter(client_dataset, local_parameter)\n",
        "        list_of_local_dataset_size.append(len(train_images))\n",
        "        list_of_local_accuracy.append(train_result.history[\"accuracy\"][-1])\n",
        "        list_of_local_loss.append(train_result.history[\"loss\"][-1])\n",
        "        \n",
        "        print(\"    clint ID :\", client_dataset, \"training complete.\")\n",
        "        print(\"        accuracy :\", train_result.history[\"accuracy\"][-1], \"- loss :\", train_result.history[\"loss\"][-1])\n",
        "    \n",
        "        #4-5. aggregate Local parameters.\n",
        "    global_parameter = np.mean(list_of_local_parameter, axis=0)\n",
        "    #global_parameter = np.mean(list_of_local_parameter, axis=0)*np.sum(list_of_local_dataset_size)\n",
        "    #print(\"global_parameter :\",global_parameter)\n",
        "    parameter_saver.save_aggreated_global_parameter(global_parameter)\n",
        "    current_mean_accuracy = np.mean(np.array(list_of_local_accuracy, dtype=\"float32\"))\n",
        "    current_mean_loss = np.mean(np.array(list_of_local_loss, dtype=\"float32\"))\n",
        "    print(f\"  evaluation mean : accuracy - {current_mean_accuracy}, loss - {current_mean_loss}\")   \n",
        "    \n",
        "    list_of_local_parameter.clear()\n",
        "    list_of_local_dataset_size.clear()\n",
        "    list_of_local_accuracy.clear()\n",
        "    list_of_local_loss.clear()\n",
        "    \n",
        "print(\"\\n\\n▶▶▶ Round is over.\")"
      ],
      "id": "unlikely-morocco",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "total client : 100 , selected client : 10\n",
            "-- prameter shape --\n",
            "(5, 5, 1, 32)\n",
            "(32,)\n",
            "(5, 5, 32, 64)\n",
            "(64,)\n",
            "(3136, 512)\n",
            "(512,)\n",
            "(512, 10)\n",
            "(10,)\n",
            "\n",
            "▶ Round 1 ◀\n",
            "selected clients : [22 23 59 73 38 91 21 96 41  5]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/numpy/core/_asarray.py:83: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  return array(a, dtype, copy=False, order=order)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "    clint ID : 22 training complete.\n",
            "        accuracy : 0.9900000095367432 - loss : 0.036352161318063736\n",
            "    clint ID : 23 training complete.\n",
            "        accuracy : 0.9933333396911621 - loss : 0.012276115827262402\n",
            "    clint ID : 59 training complete.\n",
            "        accuracy : 0.9933333396911621 - loss : 0.035623274743556976\n",
            "    clint ID : 73 training complete.\n",
            "        accuracy : 0.9883333444595337 - loss : 0.025524163618683815\n",
            "    clint ID : 38 training complete.\n",
            "        accuracy : 0.9850000143051147 - loss : 0.05195027217268944\n",
            "    clint ID : 91 training complete.\n",
            "        accuracy : 0.9866666793823242 - loss : 0.03841967135667801\n",
            "    clint ID : 21 training complete.\n",
            "        accuracy : 0.9883333444595337 - loss : 0.02580210752785206\n",
            "    clint ID : 96 training complete.\n",
            "        accuracy : 0.9883333444595337 - loss : 0.03892030566930771\n",
            "    clint ID : 41 training complete.\n",
            "        accuracy : 0.9883333444595337 - loss : 0.04075932502746582\n",
            "    clint ID : 5 training complete.\n",
            "        accuracy : 0.9800000190734863 - loss : 0.05656852200627327\n",
            "  evaluation mean : accuracy - 0.9881666302680969, loss - 0.03621959313750267\n",
            "\n",
            "▶ Round 2 ◀\n",
            "selected clients : [22 23 59 73 38 91 21 96 41  5]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/numpy/core/_asarray.py:136: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  return array(a, dtype, copy=False, order=order, subok=True)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "    clint ID : 22 training complete.\n",
            "        accuracy : 0.9950000047683716 - loss : 0.0171226616948843\n",
            "    clint ID : 23 training complete.\n",
            "        accuracy : 1.0 - loss : 0.0030688378028571606\n",
            "    clint ID : 59 training complete.\n",
            "        accuracy : 0.9983333349227905 - loss : 0.0070622824132442474\n",
            "    clint ID : 73 training complete.\n",
            "        accuracy : 1.0 - loss : 0.0028070870321244\n",
            "    clint ID : 38 training complete.\n",
            "        accuracy : 1.0 - loss : 0.0018182643689215183\n",
            "    clint ID : 91 training complete.\n",
            "        accuracy : 0.996666669845581 - loss : 0.013824420049786568\n",
            "    clint ID : 21 training complete.\n",
            "        accuracy : 0.9900000095367432 - loss : 0.02216981165111065\n",
            "    clint ID : 96 training complete.\n",
            "        accuracy : 0.9950000047683716 - loss : 0.010958521626889706\n",
            "    clint ID : 41 training complete.\n",
            "        accuracy : 1.0 - loss : 0.002139539923518896\n",
            "    clint ID : 5 training complete.\n",
            "        accuracy : 0.9916666746139526 - loss : 0.031347718089818954\n",
            "  evaluation mean : accuracy - 0.9966667294502258, loss - 0.011231914162635803\n",
            "\n",
            "▶ Round 3 ◀\n",
            "selected clients : [22 23 59 73 38 91 21 96 41  5]\n",
            "    clint ID : 22 training complete.\n",
            "        accuracy : 1.0 - loss : 0.002032955177128315\n",
            "    clint ID : 23 training complete.\n",
            "        accuracy : 1.0 - loss : 0.0004726341285277158\n",
            "    clint ID : 59 training complete.\n",
            "        accuracy : 0.9866666793823242 - loss : 0.04106035456061363\n",
            "    clint ID : 73 training complete.\n",
            "        accuracy : 0.996666669845581 - loss : 0.005536390468478203\n",
            "    clint ID : 38 training complete.\n",
            "        accuracy : 1.0 - loss : 0.002368733286857605\n",
            "    clint ID : 91 training complete.\n",
            "        accuracy : 1.0 - loss : 0.0003812932991422713\n",
            "    clint ID : 21 training complete.\n",
            "        accuracy : 0.9950000047683716 - loss : 0.02152073383331299\n",
            "    clint ID : 96 training complete.\n",
            "        accuracy : 1.0 - loss : 0.0004904040251858532\n",
            "    clint ID : 41 training complete.\n",
            "        accuracy : 0.9883333444595337 - loss : 0.03520068898797035\n",
            "    clint ID : 5 training complete.\n",
            "        accuracy : 0.9950000047683716 - loss : 0.018284430727362633\n",
            "  evaluation mean : accuracy - 0.9961667060852051, loss - 0.012734862044453621\n",
            "\n",
            "▶ Round 4 ◀\n",
            "selected clients : [22 23 59 73 38 91 21 96 41  5]\n",
            "    clint ID : 22 training complete.\n",
            "        accuracy : 1.0 - loss : 0.0009841936407610774\n",
            "    clint ID : 23 training complete.\n",
            "        accuracy : 1.0 - loss : 0.00030834050267003477\n",
            "    clint ID : 59 training complete.\n",
            "        accuracy : 0.9933333396911621 - loss : 0.012884296476840973\n",
            "    clint ID : 73 training complete.\n",
            "        accuracy : 1.0 - loss : 0.000791885715443641\n",
            "    clint ID : 38 training complete.\n",
            "        accuracy : 1.0 - loss : 0.002650746377184987\n",
            "    clint ID : 91 training complete.\n",
            "        accuracy : 1.0 - loss : 0.0012573556741699576\n",
            "    clint ID : 21 training complete.\n",
            "        accuracy : 1.0 - loss : 0.0003040923038497567\n",
            "    clint ID : 96 training complete.\n",
            "        accuracy : 0.9983333349227905 - loss : 0.004048118833452463\n",
            "    clint ID : 41 training complete.\n",
            "        accuracy : 1.0 - loss : 0.0004665272426791489\n",
            "    clint ID : 5 training complete.\n",
            "        accuracy : 1.0 - loss : 0.0004128914442844689\n",
            "  evaluation mean : accuracy - 0.9991666674613953, loss - 0.0024108446668833494\n",
            "\n",
            "▶ Round 5 ◀\n",
            "selected clients : [22 23 59 73 38 91 21 96 41  5]\n",
            "    clint ID : 22 training complete.\n",
            "        accuracy : 1.0 - loss : 0.002768157282844186\n",
            "    clint ID : 23 training complete.\n",
            "        accuracy : 0.996666669845581 - loss : 0.007749775890260935\n",
            "    clint ID : 59 training complete.\n",
            "        accuracy : 0.9950000047683716 - loss : 0.011507216840982437\n",
            "    clint ID : 73 training complete.\n",
            "        accuracy : 1.0 - loss : 0.0002956788521260023\n",
            "    clint ID : 38 training complete.\n",
            "        accuracy : 0.996666669845581 - loss : 0.02069041319191456\n",
            "    clint ID : 91 training complete.\n",
            "        accuracy : 1.0 - loss : 0.00036892545176669955\n",
            "    clint ID : 21 training complete.\n",
            "        accuracy : 1.0 - loss : 0.0002275768929393962\n",
            "    clint ID : 96 training complete.\n",
            "        accuracy : 1.0 - loss : 0.0018025903264060616\n",
            "    clint ID : 41 training complete.\n",
            "        accuracy : 1.0 - loss : 0.00042925492743961513\n",
            "    clint ID : 5 training complete.\n",
            "        accuracy : 1.0 - loss : 0.0030051569920033216\n",
            "  evaluation mean : accuracy - 0.9988333582878113, loss - 0.004884474910795689\n",
            "\n",
            "▶ Round 6 ◀\n",
            "selected clients : [22 23 59 73 38 91 21 96 41  5]\n",
            "    clint ID : 22 training complete.\n",
            "        accuracy : 1.0 - loss : 0.0002998949203174561\n",
            "    clint ID : 23 training complete.\n",
            "        accuracy : 0.9950000047683716 - loss : 0.0110974982380867\n",
            "    clint ID : 59 training complete.\n",
            "        accuracy : 1.0 - loss : 0.00016727134061511606\n",
            "    clint ID : 73 training complete.\n",
            "        accuracy : 1.0 - loss : 0.0007312594680115581\n",
            "    clint ID : 38 training complete.\n",
            "        accuracy : 0.9950000047683716 - loss : 0.0081764105707407\n",
            "    clint ID : 91 training complete.\n",
            "        accuracy : 0.9850000143051147 - loss : 0.04395856708288193\n",
            "    clint ID : 21 training complete.\n",
            "        accuracy : 1.0 - loss : 0.000243559610680677\n",
            "    clint ID : 96 training complete.\n",
            "        accuracy : 0.9983333349227905 - loss : 0.004605592228472233\n",
            "    clint ID : 41 training complete.\n",
            "        accuracy : 1.0 - loss : 0.00025340801221318543\n",
            "    clint ID : 5 training complete.\n",
            "        accuracy : 1.0 - loss : 0.0004646191082429141\n",
            "  evaluation mean : accuracy - 0.9973333477973938, loss - 0.006999807897955179\n",
            "\n",
            "▶ Round 7 ◀\n",
            "selected clients : [22 23 59 73 38 91 21 96 41  5]\n",
            "    clint ID : 22 training complete.\n",
            "        accuracy : 1.0 - loss : 0.0002073347131954506\n",
            "    clint ID : 23 training complete.\n",
            "        accuracy : 1.0 - loss : 0.0005649809027090669\n",
            "    clint ID : 59 training complete.\n",
            "        accuracy : 1.0 - loss : 0.0006277589709497988\n",
            "    clint ID : 73 training complete.\n",
            "        accuracy : 1.0 - loss : 0.00013590164599008858\n",
            "    clint ID : 38 training complete.\n",
            "        accuracy : 0.9950000047683716 - loss : 0.010178973898291588\n",
            "    clint ID : 91 training complete.\n",
            "        accuracy : 1.0 - loss : 0.00030271909781731665\n",
            "    clint ID : 21 training complete.\n",
            "        accuracy : 1.0 - loss : 0.00013220230175647885\n",
            "    clint ID : 96 training complete.\n",
            "        accuracy : 1.0 - loss : 0.0007124183466657996\n",
            "    clint ID : 41 training complete.\n",
            "        accuracy : 0.996666669845581 - loss : 0.009828205220401287\n",
            "    clint ID : 5 training complete.\n",
            "        accuracy : 1.0 - loss : 0.0020561981946229935\n",
            "  evaluation mean : accuracy - 0.9991666674613953, loss - 0.0024746691342443228\n",
            "\n",
            "▶ Round 8 ◀\n",
            "selected clients : [22 23 59 73 38 91 21 96 41  5]\n",
            "    clint ID : 22 training complete.\n",
            "        accuracy : 1.0 - loss : 0.00011090700718341395\n",
            "    clint ID : 23 training complete.\n",
            "        accuracy : 1.0 - loss : 8.214438275899738e-05\n",
            "    clint ID : 59 training complete.\n",
            "        accuracy : 1.0 - loss : 7.089839346008375e-05\n",
            "    clint ID : 73 training complete.\n",
            "        accuracy : 1.0 - loss : 0.00010223635035799816\n",
            "    clint ID : 38 training complete.\n",
            "        accuracy : 1.0 - loss : 0.0023879832588136196\n",
            "    clint ID : 91 training complete.\n",
            "        accuracy : 1.0 - loss : 0.0030207063537091017\n",
            "    clint ID : 21 training complete.\n",
            "        accuracy : 1.0 - loss : 0.00012163410428911448\n",
            "    clint ID : 96 training complete.\n",
            "        accuracy : 1.0 - loss : 9.028323256643489e-05\n",
            "    clint ID : 41 training complete.\n",
            "        accuracy : 0.9883333444595337 - loss : 0.047039519995450974\n",
            "    clint ID : 5 training complete.\n",
            "        accuracy : 1.0 - loss : 0.00011039799574064091\n",
            "  evaluation mean : accuracy - 0.9988333582878113, loss - 0.0053136711940169334\n",
            "\n",
            "▶ Round 9 ◀\n",
            "selected clients : [22 23 59 73 38 91 21 96 41  5]\n",
            "    clint ID : 22 training complete.\n",
            "        accuracy : 1.0 - loss : 9.156527084996924e-05\n",
            "    clint ID : 23 training complete.\n",
            "        accuracy : 1.0 - loss : 4.599476596922614e-05\n",
            "    clint ID : 59 training complete.\n",
            "        accuracy : 1.0 - loss : 5.7247070799348876e-05\n",
            "    clint ID : 73 training complete.\n",
            "        accuracy : 1.0 - loss : 6.798233516747132e-05\n",
            "    clint ID : 38 training complete.\n",
            "        accuracy : 1.0 - loss : 0.0001776216086000204\n",
            "    clint ID : 91 training complete.\n",
            "        accuracy : 0.9933333396911621 - loss : 0.024100594222545624\n",
            "    clint ID : 21 training complete.\n",
            "        accuracy : 1.0 - loss : 0.00024102360475808382\n",
            "    clint ID : 96 training complete.\n",
            "        accuracy : 1.0 - loss : 0.00015155845903791487\n",
            "    clint ID : 41 training complete.\n",
            "        accuracy : 1.0 - loss : 6.293330079643056e-05\n",
            "    clint ID : 5 training complete.\n",
            "        accuracy : 0.9983333349227905 - loss : 0.0029323517810553312\n",
            "  evaluation mean : accuracy - 0.9991666674613953, loss - 0.002792887156829238\n",
            "\n",
            "▶ Round 10 ◀\n",
            "selected clients : [22 23 59 73 38 91 21 96 41  5]\n",
            "    clint ID : 22 training complete.\n",
            "        accuracy : 0.996666669845581 - loss : 0.014982479624450207\n",
            "    clint ID : 23 training complete.\n",
            "        accuracy : 1.0 - loss : 0.00013478529581334442\n",
            "    clint ID : 59 training complete.\n",
            "        accuracy : 1.0 - loss : 7.26622311049141e-05\n",
            "    clint ID : 73 training complete.\n",
            "        accuracy : 0.9983333349227905 - loss : 0.0026513293851166964\n",
            "    clint ID : 38 training complete.\n",
            "        accuracy : 1.0 - loss : 0.0001763953041518107\n",
            "    clint ID : 91 training complete.\n",
            "        accuracy : 1.0 - loss : 4.807014192920178e-05\n",
            "    clint ID : 21 training complete.\n",
            "        accuracy : 1.0 - loss : 0.00013510335702449083\n",
            "    clint ID : 96 training complete.\n",
            "        accuracy : 1.0 - loss : 4.508851270657033e-05\n",
            "    clint ID : 41 training complete.\n",
            "        accuracy : 0.9983333349227905 - loss : 0.003604946192353964\n",
            "    clint ID : 5 training complete.\n",
            "        accuracy : 1.0 - loss : 0.00013172594481147826\n",
            "  evaluation mean : accuracy - 0.9993332624435425, loss - 0.0021982588805258274\n",
            "\n",
            "▶ Round 11 ◀\n",
            "selected clients : [22 23 59 73 38 91 21 96 41  5]\n",
            "    clint ID : 22 training complete.\n",
            "        accuracy : 1.0 - loss : 6.72892783768475e-05\n",
            "    clint ID : 23 training complete.\n",
            "        accuracy : 1.0 - loss : 4.545486081042327e-05\n",
            "    clint ID : 59 training complete.\n",
            "        accuracy : 1.0 - loss : 5.202847387408838e-05\n",
            "    clint ID : 73 training complete.\n",
            "        accuracy : 0.9883333444595337 - loss : 0.03465673327445984\n",
            "    clint ID : 38 training complete.\n",
            "        accuracy : 1.0 - loss : 7.180259854067117e-05\n",
            "    clint ID : 91 training complete.\n",
            "        accuracy : 1.0 - loss : 0.0002565522736404091\n",
            "    clint ID : 21 training complete.\n",
            "        accuracy : 0.9983333349227905 - loss : 0.004116368480026722\n",
            "    clint ID : 96 training complete.\n",
            "        accuracy : 1.0 - loss : 5.756161408498883e-05\n",
            "    clint ID : 41 training complete.\n",
            "        accuracy : 1.0 - loss : 5.6949094869196415e-05\n",
            "    clint ID : 5 training complete.\n",
            "        accuracy : 1.0 - loss : 0.00011561329301912338\n",
            "  evaluation mean : accuracy - 0.9986666440963745, loss - 0.003949635662138462\n",
            "\n",
            "▶ Round 12 ◀\n",
            "selected clients : [22 23 59 73 38 91 21 96 41  5]\n",
            "    clint ID : 22 training complete.\n",
            "        accuracy : 1.0 - loss : 4.598903251462616e-05\n",
            "    clint ID : 23 training complete.\n",
            "        accuracy : 1.0 - loss : 2.898266575357411e-05\n",
            "    clint ID : 59 training complete.\n",
            "        accuracy : 1.0 - loss : 3.693302642204799e-05\n",
            "    clint ID : 73 training complete.\n",
            "        accuracy : 0.9983333349227905 - loss : 0.014884605072438717\n",
            "    clint ID : 38 training complete.\n",
            "        accuracy : 1.0 - loss : 6.539944297401235e-05\n",
            "    clint ID : 91 training complete.\n",
            "        accuracy : 1.0 - loss : 3.446897244430147e-05\n",
            "    clint ID : 21 training complete.\n",
            "        accuracy : 1.0 - loss : 3.697844294947572e-05\n",
            "    clint ID : 96 training complete.\n",
            "        accuracy : 0.9933333396911621 - loss : 0.022520041093230247\n",
            "    clint ID : 41 training complete.\n",
            "        accuracy : 1.0 - loss : 4.954475298291072e-05\n",
            "    clint ID : 5 training complete.\n",
            "        accuracy : 1.0 - loss : 5.6373191910097376e-05\n",
            "  evaluation mean : accuracy - 0.9991666674613953, loss - 0.0037759318947792053\n",
            "\n",
            "▶ Round 13 ◀\n",
            "selected clients : [22 23 59 73 38 91 21 96 41  5]\n",
            "    clint ID : 22 training complete.\n",
            "        accuracy : 1.0 - loss : 4.69205915578641e-05\n",
            "    clint ID : 23 training complete.\n",
            "        accuracy : 1.0 - loss : 2.5706898668431677e-05\n",
            "    clint ID : 59 training complete.\n",
            "        accuracy : 1.0 - loss : 4.213737338432111e-05\n",
            "    clint ID : 73 training complete.\n",
            "        accuracy : 1.0 - loss : 2.4879007469280623e-05\n",
            "    clint ID : 38 training complete.\n",
            "        accuracy : 0.996666669845581 - loss : 0.018176143988966942\n",
            "    clint ID : 91 training complete.\n",
            "        accuracy : 1.0 - loss : 4.402959893923253e-05\n",
            "    clint ID : 21 training complete.\n",
            "        accuracy : 1.0 - loss : 4.576751234708354e-05\n",
            "    clint ID : 96 training complete.\n",
            "        accuracy : 1.0 - loss : 4.062844891450368e-05\n",
            "    clint ID : 41 training complete.\n",
            "        accuracy : 1.0 - loss : 3.539137469488196e-05\n",
            "    clint ID : 5 training complete.\n",
            "        accuracy : 1.0 - loss : 3.1266434234566987e-05\n",
            "  evaluation mean : accuracy - 0.999666690826416, loss - 0.0018512870883569121\n",
            "\n",
            "▶ Round 14 ◀\n",
            "selected clients : [22 23 59 73 38 91 21 96 41  5]\n",
            "    clint ID : 22 training complete.\n",
            "        accuracy : 1.0 - loss : 3.251824455219321e-05\n",
            "    clint ID : 23 training complete.\n",
            "        accuracy : 1.0 - loss : 2.5009348973981105e-05\n",
            "    clint ID : 59 training complete.\n",
            "        accuracy : 1.0 - loss : 2.0960595065844245e-05\n",
            "    clint ID : 73 training complete.\n",
            "        accuracy : 1.0 - loss : 1.3769736142421607e-05\n",
            "    clint ID : 38 training complete.\n",
            "        accuracy : 1.0 - loss : 0.00240853289142251\n",
            "    clint ID : 91 training complete.\n",
            "        accuracy : 1.0 - loss : 2.9868780984543264e-05\n",
            "    clint ID : 21 training complete.\n",
            "        accuracy : 1.0 - loss : 2.7637941457214765e-05\n",
            "    clint ID : 96 training complete.\n",
            "        accuracy : 1.0 - loss : 3.27676571032498e-05\n",
            "    clint ID : 41 training complete.\n",
            "        accuracy : 1.0 - loss : 2.1318863218766637e-05\n",
            "    clint ID : 5 training complete.\n",
            "        accuracy : 0.9983333349227905 - loss : 0.0020714481361210346\n",
            "  evaluation mean : accuracy - 0.9998332858085632, loss - 0.0004683832230512053\n",
            "\n",
            "▶ Round 15 ◀\n",
            "selected clients : [22 23 59 73 38 91 21 96 41  5]\n",
            "    clint ID : 22 training complete.\n",
            "        accuracy : 1.0 - loss : 4.429354521562345e-05\n",
            "    clint ID : 23 training complete.\n",
            "        accuracy : 1.0 - loss : 3.54578260157723e-05\n",
            "    clint ID : 59 training complete.\n",
            "        accuracy : 1.0 - loss : 4.3167743569938466e-05\n",
            "    clint ID : 73 training complete.\n",
            "        accuracy : 1.0 - loss : 2.204933116445318e-05\n",
            "    clint ID : 38 training complete.\n",
            "        accuracy : 1.0 - loss : 2.286210838065017e-05\n",
            "    clint ID : 91 training complete.\n",
            "        accuracy : 0.9866666793823242 - loss : 0.03455761820077896\n",
            "    clint ID : 21 training complete.\n",
            "        accuracy : 1.0 - loss : 3.711132740136236e-05\n",
            "    clint ID : 96 training complete.\n",
            "        accuracy : 1.0 - loss : 3.909607039531693e-05\n",
            "    clint ID : 41 training complete.\n",
            "        accuracy : 1.0 - loss : 2.7204034267924726e-05\n",
            "    clint ID : 5 training complete.\n",
            "        accuracy : 1.0 - loss : 0.00015733858163002878\n",
            "  evaluation mean : accuracy - 0.9986666440963745, loss - 0.003498620120808482\n",
            "\n",
            "▶ Round 16 ◀\n",
            "selected clients : [22 23 59 73 38 91 21 96 41  5]\n",
            "    clint ID : 22 training complete.\n",
            "        accuracy : 1.0 - loss : 3.7080862966831774e-05\n",
            "    clint ID : 23 training complete.\n",
            "        accuracy : 1.0 - loss : 3.206678229616955e-05\n",
            "    clint ID : 59 training complete.\n",
            "        accuracy : 1.0 - loss : 4.281628571334295e-05\n",
            "    clint ID : 73 training complete.\n",
            "        accuracy : 1.0 - loss : 2.1777850633952767e-05\n",
            "    clint ID : 38 training complete.\n",
            "        accuracy : 1.0 - loss : 1.6982567103696056e-05\n",
            "    clint ID : 91 training complete.\n",
            "        accuracy : 1.0 - loss : 1.841185257944744e-05\n",
            "    clint ID : 21 training complete.\n",
            "        accuracy : 1.0 - loss : 1.4228654436010402e-05\n",
            "    clint ID : 96 training complete.\n",
            "        accuracy : 1.0 - loss : 0.002238079672679305\n",
            "    clint ID : 41 training complete.\n",
            "        accuracy : 1.0 - loss : 4.357007492217235e-05\n",
            "    clint ID : 5 training complete.\n",
            "        accuracy : 1.0 - loss : 3.627330079325475e-05\n",
            "  evaluation mean : accuracy - 1.0, loss - 0.00025012882542796433\n",
            "\n",
            "▶ Round 17 ◀\n",
            "selected clients : [22 23 59 73 38 91 21 96 41  5]\n",
            "    clint ID : 22 training complete.\n",
            "        accuracy : 1.0 - loss : 3.135310907964595e-05\n",
            "    clint ID : 23 training complete.\n",
            "        accuracy : 1.0 - loss : 2.5765764803509228e-05\n",
            "    clint ID : 59 training complete.\n",
            "        accuracy : 1.0 - loss : 3.380849739187397e-05\n",
            "    clint ID : 73 training complete.\n",
            "        accuracy : 1.0 - loss : 1.6625306670903228e-05\n",
            "    clint ID : 38 training complete.\n",
            "        accuracy : 1.0 - loss : 1.049317233992042e-05\n",
            "    clint ID : 91 training complete.\n",
            "        accuracy : 1.0 - loss : 1.3797216524835676e-05\n",
            "    clint ID : 21 training complete.\n",
            "        accuracy : 1.0 - loss : 8.815526598482393e-06\n",
            "    clint ID : 96 training complete.\n",
            "        accuracy : 1.0 - loss : 9.896758456306998e-06\n",
            "    clint ID : 41 training complete.\n",
            "        accuracy : 0.9950000047683716 - loss : 0.025956906378269196\n",
            "    clint ID : 5 training complete.\n",
            "        accuracy : 1.0 - loss : 2.9770117180305533e-05\n",
            "  evaluation mean : accuracy - 0.9994999766349792, loss - 0.0026137232780456543\n",
            "\n",
            "▶ Round 18 ◀\n",
            "selected clients : [22 23 59 73 38 91 21 96 41  5]\n",
            "    clint ID : 22 training complete.\n",
            "        accuracy : 1.0 - loss : 3.137031671940349e-05\n",
            "    clint ID : 23 training complete.\n",
            "        accuracy : 1.0 - loss : 1.866019556473475e-05\n",
            "    clint ID : 59 training complete.\n",
            "        accuracy : 1.0 - loss : 2.974767812702339e-05\n",
            "    clint ID : 73 training complete.\n",
            "        accuracy : 1.0 - loss : 1.745385816320777e-05\n",
            "    clint ID : 38 training complete.\n",
            "        accuracy : 1.0 - loss : 1.6760133803472854e-05\n",
            "    clint ID : 91 training complete.\n",
            "        accuracy : 1.0 - loss : 1.412291567248758e-05\n",
            "    clint ID : 21 training complete.\n",
            "        accuracy : 1.0 - loss : 1.1889226698258426e-05\n",
            "    clint ID : 96 training complete.\n",
            "        accuracy : 1.0 - loss : 9.756172403285746e-06\n",
            "    clint ID : 41 training complete.\n",
            "        accuracy : 1.0 - loss : 1.0229795407212805e-05\n",
            "    clint ID : 5 training complete.\n",
            "        accuracy : 1.0 - loss : 8.25948973215418e-06\n",
            "  evaluation mean : accuracy - 1.0, loss - 1.682497895671986e-05\n",
            "\n",
            "▶ Round 19 ◀\n",
            "selected clients : [22 23 59 73 38 91 21 96 41  5]\n",
            "    clint ID : 22 training complete.\n",
            "        accuracy : 1.0 - loss : 4.930790964863263e-06\n",
            "    clint ID : 23 training complete.\n",
            "        accuracy : 1.0 - loss : 3.685403271447285e-06\n",
            "    clint ID : 59 training complete.\n",
            "        accuracy : 1.0 - loss : 5.467688424687367e-06\n",
            "    clint ID : 73 training complete.\n",
            "        accuracy : 1.0 - loss : 3.4845713798858924e-06\n",
            "    clint ID : 38 training complete.\n",
            "        accuracy : 1.0 - loss : 2.2335213998303516e-06\n",
            "    clint ID : 91 training complete.\n",
            "        accuracy : 1.0 - loss : 2.600674861241714e-06\n",
            "    clint ID : 21 training complete.\n",
            "        accuracy : 1.0 - loss : 2.5422777980566025e-06\n",
            "    clint ID : 96 training complete.\n",
            "        accuracy : 1.0 - loss : 1.8564491028882912e-06\n",
            "    clint ID : 41 training complete.\n",
            "        accuracy : 1.0 - loss : 1.866592583610327e-06\n",
            "    clint ID : 5 training complete.\n",
            "        accuracy : 1.0 - loss : 1.6094934380816994e-06\n",
            "  evaluation mean : accuracy - 1.0, loss - 3.027746288353228e-06\n",
            "\n",
            "▶ Round 20 ◀\n",
            "selected clients : [22 23 59 73 38 91 21 96 41  5]\n",
            "    clint ID : 22 training complete.\n",
            "        accuracy : 0.996666669845581 - loss : 0.015213648788630962\n",
            "    clint ID : 23 training complete.\n",
            "        accuracy : 1.0 - loss : 5.0644439397729e-06\n",
            "    clint ID : 59 training complete.\n",
            "        accuracy : 1.0 - loss : 8.023974260140676e-06\n",
            "    clint ID : 73 training complete.\n",
            "        accuracy : 1.0 - loss : 3.468249815341551e-06\n",
            "    clint ID : 38 training complete.\n",
            "        accuracy : 1.0 - loss : 4.38729193774634e-06\n",
            "    clint ID : 91 training complete.\n",
            "        accuracy : 1.0 - loss : 2.5873537197185215e-06\n",
            "    clint ID : 21 training complete.\n",
            "        accuracy : 1.0 - loss : 2.6561006052361336e-06\n",
            "    clint ID : 96 training complete.\n",
            "        accuracy : 1.0 - loss : 3.3071260077122133e-06\n",
            "    clint ID : 41 training complete.\n",
            "        accuracy : 1.0 - loss : 2.904028406192083e-06\n",
            "    clint ID : 5 training complete.\n",
            "        accuracy : 1.0 - loss : 2.9356156119320076e-06\n",
            "  evaluation mean : accuracy - 0.999666690826416, loss - 0.0015248983399942517\n",
            "\n",
            "▶ Round 21 ◀\n",
            "selected clients : [22 23 59 73 38 91 21 96 41  5]\n",
            "    clint ID : 22 training complete.\n",
            "        accuracy : 1.0 - loss : 3.2391908462159336e-06\n",
            "    clint ID : 23 training complete.\n",
            "        accuracy : 1.0 - loss : 1.4338650089484872e-06\n",
            "    clint ID : 59 training complete.\n",
            "        accuracy : 1.0 - loss : 2.2581725716008805e-06\n",
            "    clint ID : 73 training complete.\n",
            "        accuracy : 1.0 - loss : 0.0022870022803545\n",
            "    clint ID : 38 training complete.\n",
            "        accuracy : 1.0 - loss : 8.846191121847369e-06\n",
            "    clint ID : 91 training complete.\n",
            "        accuracy : 1.0 - loss : 6.82298423271277e-06\n",
            "    clint ID : 21 training complete.\n",
            "        accuracy : 1.0 - loss : 6.198621122166514e-06\n",
            "    clint ID : 96 training complete.\n",
            "        accuracy : 1.0 - loss : 7.471184744645143e-06\n",
            "    clint ID : 41 training complete.\n",
            "        accuracy : 1.0 - loss : 5.72324643144384e-06\n",
            "    clint ID : 5 training complete.\n",
            "        accuracy : 1.0 - loss : 6.504322300315835e-06\n",
            "  evaluation mean : accuracy - 1.0, loss - 0.00023355001758318394\n",
            "\n",
            "▶ Round 22 ◀\n",
            "selected clients : [22 23 59 73 38 91 21 96 41  5]\n",
            "    clint ID : 22 training complete.\n",
            "        accuracy : 1.0 - loss : 5.345762019715039e-06\n",
            "    clint ID : 23 training complete.\n",
            "        accuracy : 1.0 - loss : 3.311303089503781e-06\n",
            "    clint ID : 59 training complete.\n",
            "        accuracy : 1.0 - loss : 3.8692073758284096e-06\n",
            "    clint ID : 73 training complete.\n",
            "        accuracy : 1.0 - loss : 3.7481863728316966e-06\n",
            "    clint ID : 38 training complete.\n",
            "        accuracy : 1.0 - loss : 2.7103378670290112e-06\n",
            "    clint ID : 91 training complete.\n",
            "        accuracy : 1.0 - loss : 2.9731863833148964e-06\n",
            "    clint ID : 21 training complete.\n",
            "        accuracy : 1.0 - loss : 1.916449491545791e-06\n",
            "    clint ID : 96 training complete.\n",
            "        accuracy : 1.0 - loss : 2.3509564925916493e-06\n",
            "    clint ID : 41 training complete.\n",
            "        accuracy : 1.0 - loss : 2.062482963083312e-06\n",
            "    clint ID : 5 training complete.\n",
            "        accuracy : 1.0 - loss : 1.7435961581213633e-06\n",
            "  evaluation mean : accuracy - 1.0, loss - 3.0031467304070247e-06\n",
            "\n",
            "▶ Round 23 ◀\n",
            "selected clients : [22 23 59 73 38 91 21 96 41  5]\n",
            "    clint ID : 22 training complete.\n",
            "        accuracy : 1.0 - loss : 1.4322732795335469e-06\n",
            "    clint ID : 23 training complete.\n",
            "        accuracy : 1.0 - loss : 7.438590614583518e-07\n",
            "    clint ID : 59 training complete.\n",
            "        accuracy : 1.0 - loss : 1.347249053651467e-06\n",
            "    clint ID : 73 training complete.\n",
            "        accuracy : 1.0 - loss : 1.2002258245047415e-06\n",
            "    clint ID : 38 training complete.\n",
            "        accuracy : 0.9950000047683716 - loss : 0.018578827381134033\n",
            "    clint ID : 91 training complete.\n",
            "        accuracy : 1.0 - loss : 4.602527951647062e-06\n",
            "    clint ID : 21 training complete.\n",
            "        accuracy : 1.0 - loss : 5.0579378694237676e-06\n",
            "    clint ID : 96 training complete.\n",
            "        accuracy : 1.0 - loss : 7.019330041657668e-06\n",
            "    clint ID : 41 training complete.\n",
            "        accuracy : 1.0 - loss : 5.183248958928743e-06\n",
            "    clint ID : 5 training complete.\n",
            "        accuracy : 1.0 - loss : 5.920825060456991e-06\n",
            "  evaluation mean : accuracy - 0.9994999766349792, loss - 0.0018611336126923561\n",
            "\n",
            "▶ Round 24 ◀\n",
            "selected clients : [22 23 59 73 38 91 21 96 41  5]\n",
            "    clint ID : 22 training complete.\n",
            "        accuracy : 1.0 - loss : 5.405929186963476e-06\n",
            "    clint ID : 23 training complete.\n",
            "        accuracy : 1.0 - loss : 5.456242433865555e-06\n",
            "    clint ID : 59 training complete.\n",
            "        accuracy : 1.0 - loss : 6.416713404178154e-06\n",
            "    clint ID : 73 training complete.\n",
            "        accuracy : 1.0 - loss : 3.0842227261018706e-06\n",
            "    clint ID : 38 training complete.\n",
            "        accuracy : 1.0 - loss : 3.86986403100309e-06\n",
            "    clint ID : 91 training complete.\n",
            "        accuracy : 1.0 - loss : 2.703976633711136e-06\n",
            "    clint ID : 21 training complete.\n",
            "        accuracy : 1.0 - loss : 2.161420297852601e-06\n",
            "    clint ID : 96 training complete.\n",
            "        accuracy : 1.0 - loss : 2.349363512621494e-06\n",
            "    clint ID : 41 training complete.\n",
            "        accuracy : 1.0 - loss : 1.8282421478943434e-06\n",
            "    clint ID : 5 training complete.\n",
            "        accuracy : 1.0 - loss : 1.7302918422501534e-06\n",
            "  evaluation mean : accuracy - 1.0, loss - 3.5006264624826144e-06\n",
            "\n",
            "▶ Round 25 ◀\n",
            "selected clients : [22 23 59 73 38 91 21 96 41  5]\n",
            "    clint ID : 22 training complete.\n",
            "        accuracy : 1.0 - loss : 1.2475048833948676e-06\n",
            "    clint ID : 23 training complete.\n",
            "        accuracy : 1.0 - loss : 1.2290264521652716e-06\n",
            "    clint ID : 59 training complete.\n",
            "        accuracy : 1.0 - loss : 1.4509605534840375e-06\n",
            "    clint ID : 73 training complete.\n",
            "        accuracy : 1.0 - loss : 8.626700491731754e-07\n",
            "    clint ID : 38 training complete.\n",
            "        accuracy : 1.0 - loss : 8.406144615946687e-07\n",
            "    clint ID : 91 training complete.\n",
            "        accuracy : 1.0 - loss : 6.167050514704897e-07\n",
            "    clint ID : 21 training complete.\n",
            "        accuracy : 1.0 - loss : 5.056432428318658e-07\n",
            "    clint ID : 96 training complete.\n",
            "        accuracy : 1.0 - loss : 5.737905439673341e-07\n",
            "    clint ID : 41 training complete.\n",
            "        accuracy : 1.0 - loss : 4.776299533659767e-07\n",
            "    clint ID : 5 training complete.\n",
            "        accuracy : 0.9983333349227905 - loss : 0.008244308643043041\n",
            "  evaluation mean : accuracy - 0.9998332858085632, loss - 0.0008252112893387675\n",
            "\n",
            "▶ Round 26 ◀\n",
            "selected clients : [22 23 59 73 38 91 21 96 41  5]\n",
            "    clint ID : 22 training complete.\n",
            "        accuracy : 1.0 - loss : 6.633556949964259e-06\n",
            "    clint ID : 23 training complete.\n",
            "        accuracy : 1.0 - loss : 5.868052085133968e-06\n",
            "    clint ID : 59 training complete.\n",
            "        accuracy : 1.0 - loss : 7.638577699253801e-06\n",
            "    clint ID : 73 training complete.\n",
            "        accuracy : 1.0 - loss : 3.519042593325139e-06\n",
            "    clint ID : 38 training complete.\n",
            "        accuracy : 1.0 - loss : 4.348923084762646e-06\n",
            "    clint ID : 91 training complete.\n",
            "        accuracy : 1.0 - loss : 3.687769549287623e-06\n",
            "    clint ID : 21 training complete.\n",
            "        accuracy : 1.0 - loss : 2.6761558729049284e-06\n",
            "    clint ID : 96 training complete.\n",
            "        accuracy : 1.0 - loss : 3.853261659969576e-06\n",
            "    clint ID : 41 training complete.\n",
            "        accuracy : 1.0 - loss : 3.3571955100342166e-06\n",
            "    clint ID : 5 training complete.\n",
            "        accuracy : 1.0 - loss : 3.584210389817599e-06\n",
            "  evaluation mean : accuracy - 1.0, loss - 4.516674380283803e-06\n",
            "\n",
            "▶ Round 27 ◀\n",
            "selected clients : [22 23 59 73 38 91 21 96 41  5]\n",
            "    clint ID : 22 training complete.\n",
            "        accuracy : 1.0 - loss : 2.3606464765180135e-06\n",
            "    clint ID : 23 training complete.\n",
            "        accuracy : 1.0 - loss : 1.676649503679073e-06\n",
            "    clint ID : 59 training complete.\n",
            "        accuracy : 1.0 - loss : 2.6662535219657e-06\n",
            "    clint ID : 73 training complete.\n",
            "        accuracy : 1.0 - loss : 1.3132651019986952e-06\n",
            "    clint ID : 38 training complete.\n",
            "        accuracy : 1.0 - loss : 1.3444482647173572e-06\n",
            "    clint ID : 91 training complete.\n",
            "        accuracy : 1.0 - loss : 1.233402485922852e-06\n",
            "    clint ID : 21 training complete.\n",
            "        accuracy : 1.0 - loss : 9.385655630467227e-07\n",
            "    clint ID : 96 training complete.\n",
            "        accuracy : 1.0 - loss : 1.0593622619126108e-06\n",
            "    clint ID : 41 training complete.\n",
            "        accuracy : 1.0 - loss : 1.0987008636220708e-06\n",
            "    clint ID : 5 training complete.\n",
            "        accuracy : 1.0 - loss : 1.1062494422731106e-06\n",
            "  evaluation mean : accuracy - 1.0, loss - 1.4797543599343044e-06\n",
            "\n",
            "▶ Round 28 ◀\n",
            "selected clients : [22 23 59 73 38 91 21 96 41  5]\n",
            "    clint ID : 22 training complete.\n",
            "        accuracy : 1.0 - loss : 6.822694444963417e-07\n",
            "    clint ID : 23 training complete.\n",
            "        accuracy : 1.0 - loss : 5.227299197940738e-07\n",
            "    clint ID : 59 training complete.\n",
            "        accuracy : 1.0 - loss : 7.800211960784509e-07\n",
            "    clint ID : 73 training complete.\n",
            "        accuracy : 1.0 - loss : 4.3749599853981636e-07\n",
            "    clint ID : 38 training complete.\n",
            "        accuracy : 1.0 - loss : 3.747124424080539e-07\n",
            "    clint ID : 91 training complete.\n",
            "        accuracy : 1.0 - loss : 3.5742789350479143e-07\n",
            "    clint ID : 21 training complete.\n",
            "        accuracy : 1.0 - loss : 2.7358456122783537e-07\n",
            "    clint ID : 96 training complete.\n",
            "        accuracy : 0.9883333444595337 - loss : 0.05047668516635895\n",
            "    clint ID : 41 training complete.\n",
            "        accuracy : 1.0 - loss : 3.265367922722362e-06\n",
            "    clint ID : 5 training complete.\n",
            "        accuracy : 1.0 - loss : 3.777235178858973e-06\n",
            "  evaluation mean : accuracy - 0.9988332986831665, loss - 0.0050487155094742775\n",
            "\n",
            "▶ Round 29 ◀\n",
            "selected clients : [22 23 59 73 38 91 21 96 41  5]\n",
            "    clint ID : 22 training complete.\n",
            "        accuracy : 1.0 - loss : 4.140121745876968e-06\n",
            "    clint ID : 23 training complete.\n",
            "        accuracy : 1.0 - loss : 2.9286702556419186e-06\n",
            "    clint ID : 59 training complete.\n",
            "        accuracy : 1.0 - loss : 4.726040970126633e-06\n",
            "    clint ID : 73 training complete.\n",
            "        accuracy : 1.0 - loss : 1.9396745756239397e-06\n",
            "    clint ID : 38 training complete.\n",
            "        accuracy : 1.0 - loss : 2.0860745735262753e-06\n",
            "    clint ID : 91 training complete.\n",
            "        accuracy : 1.0 - loss : 2.2827900920674438e-06\n",
            "    clint ID : 21 training complete.\n",
            "        accuracy : 1.0 - loss : 2.018355189647991e-06\n",
            "    clint ID : 96 training complete.\n",
            "        accuracy : 1.0 - loss : 2.524948286009021e-06\n",
            "    clint ID : 41 training complete.\n",
            "        accuracy : 1.0 - loss : 1.9826077277684817e-06\n",
            "    clint ID : 5 training complete.\n",
            "        accuracy : 1.0 - loss : 2.7073447199654765e-06\n",
            "  evaluation mean : accuracy - 1.0, loss - 2.7336627681506798e-06\n",
            "\n",
            "▶ Round 30 ◀\n",
            "selected clients : [22 23 59 73 38 91 21 96 41  5]\n",
            "    clint ID : 22 training complete.\n",
            "        accuracy : 1.0 - loss : 1.7568971770742792e-06\n",
            "    clint ID : 23 training complete.\n",
            "        accuracy : 1.0 - loss : 1.2308173609199002e-06\n",
            "    clint ID : 59 training complete.\n",
            "        accuracy : 1.0 - loss : 2.050765260719345e-06\n",
            "    clint ID : 73 training complete.\n",
            "        accuracy : 1.0 - loss : 7.166403861447179e-07\n",
            "    clint ID : 38 training complete.\n",
            "        accuracy : 1.0 - loss : 7.95314235801925e-07\n",
            "    clint ID : 91 training complete.\n",
            "        accuracy : 1.0 - loss : 9.59425960900262e-07\n",
            "    clint ID : 21 training complete.\n",
            "        accuracy : 1.0 - loss : 7.528007017754135e-07\n",
            "    clint ID : 96 training complete.\n",
            "        accuracy : 1.0 - loss : 9.693573019831092e-07\n",
            "    clint ID : 41 training complete.\n",
            "        accuracy : 1.0 - loss : 7.414764127133822e-07\n",
            "    clint ID : 5 training complete.\n",
            "        accuracy : 1.0 - loss : 7.096877538970148e-07\n",
            "  evaluation mean : accuracy - 1.0, loss - 1.0683182836146443e-06\n",
            "\n",
            "▶ Round 31 ◀\n",
            "selected clients : [22 23 59 73 38 91 21 96 41  5]\n",
            "    clint ID : 22 training complete.\n",
            "        accuracy : 1.0 - loss : 4.839869802708563e-07\n",
            "    clint ID : 23 training complete.\n",
            "        accuracy : 1.0 - loss : 3.7193132129687e-07\n",
            "    clint ID : 59 training complete.\n",
            "        accuracy : 1.0 - loss : 6.125341087681591e-07\n",
            "    clint ID : 73 training complete.\n",
            "        accuracy : 1.0 - loss : 2.6603470359987114e-07\n",
            "    clint ID : 38 training complete.\n",
            "        accuracy : 1.0 - loss : 2.1576821040980576e-07\n",
            "    clint ID : 91 training complete.\n",
            "        accuracy : 1.0 - loss : 2.9901573839197226e-07\n",
            "    clint ID : 21 training complete.\n",
            "        accuracy : 1.0 - loss : 2.1854989995517826e-07\n",
            "    clint ID : 96 training complete.\n",
            "        accuracy : 1.0 - loss : 2.749752070485556e-07\n",
            "    clint ID : 41 training complete.\n",
            "        accuracy : 1.0 - loss : 2.115961308390979e-07\n",
            "    clint ID : 5 training complete.\n",
            "        accuracy : 1.0 - loss : 1.7503863602996717e-07\n",
            "  evaluation mean : accuracy - 1.0, loss - 3.12943086555606e-07\n",
            "\n",
            "▶ Round 32 ◀\n",
            "selected clients : [22 23 59 73 38 91 21 96 41  5]\n",
            "    clint ID : 22 training complete.\n",
            "        accuracy : 1.0 - loss : 1.3391154141118022e-07\n",
            "    clint ID : 23 training complete.\n",
            "        accuracy : 1.0 - loss : 7.847935989957477e-08\n",
            "    clint ID : 59 training complete.\n",
            "        accuracy : 1.0 - loss : 1.3450767255562823e-07\n",
            "    clint ID : 73 training complete.\n",
            "        accuracy : 1.0 - loss : 8.742006940565261e-08\n",
            "    clint ID : 38 training complete.\n",
            "        accuracy : 1.0 - loss : 0.0003087700461037457\n",
            "    clint ID : 91 training complete.\n",
            "        accuracy : 1.0 - loss : 6.13325596532377e-07\n",
            "    clint ID : 21 training complete.\n",
            "        accuracy : 1.0 - loss : 5.797498374704446e-07\n",
            "    clint ID : 96 training complete.\n",
            "        accuracy : 1.0 - loss : 5.831268481415464e-07\n",
            "    clint ID : 41 training complete.\n",
            "        accuracy : 1.0 - loss : 4.172307797034591e-07\n",
            "    clint ID : 5 training complete.\n",
            "        accuracy : 1.0 - loss : 7.659107836843759e-07\n",
            "  evaluation mean : accuracy - 1.0, loss - 3.121636837022379e-05\n",
            "\n",
            "▶ Round 33 ◀\n",
            "selected clients : [22 23 59 73 38 91 21 96 41  5]\n",
            "    clint ID : 22 training complete.\n",
            "        accuracy : 1.0 - loss : 9.767085202838643e-07\n",
            "    clint ID : 23 training complete.\n",
            "        accuracy : 1.0 - loss : 9.383655310557515e-07\n",
            "    clint ID : 59 training complete.\n",
            "        accuracy : 1.0 - loss : 1.1990357506874716e-06\n",
            "    clint ID : 73 training complete.\n",
            "        accuracy : 1.0 - loss : 6.788919790778891e-07\n",
            "    clint ID : 38 training complete.\n",
            "        accuracy : 1.0 - loss : 6.886202754685655e-07\n",
            "    clint ID : 91 training complete.\n",
            "        accuracy : 1.0 - loss : 6.957788514228014e-07\n",
            "    clint ID : 21 training complete.\n",
            "        accuracy : 1.0 - loss : 5.507436640073138e-07\n",
            "    clint ID : 96 training complete.\n",
            "        accuracy : 1.0 - loss : 8.143899776769103e-07\n",
            "    clint ID : 41 training complete.\n",
            "        accuracy : 1.0 - loss : 4.6352337790267484e-07\n",
            "    clint ID : 5 training complete.\n",
            "        accuracy : 1.0 - loss : 6.699511345686915e-07\n",
            "  evaluation mean : accuracy - 1.0, loss - 7.676009659007832e-07\n",
            "\n",
            "▶ Round 34 ◀\n",
            "selected clients : [22 23 59 73 38 91 21 96 41  5]\n",
            "    clint ID : 22 training complete.\n",
            "        accuracy : 1.0 - loss : 4.4862207460028003e-07\n",
            "    clint ID : 23 training complete.\n",
            "        accuracy : 1.0 - loss : 4.3511167291399033e-07\n",
            "    clint ID : 59 training complete.\n",
            "        accuracy : 1.0 - loss : 5.972358962935687e-07\n",
            "    clint ID : 73 training complete.\n",
            "        accuracy : 1.0 - loss : 3.4232814982715354e-07\n",
            "    clint ID : 38 training complete.\n",
            "        accuracy : 1.0 - loss : 2.7835196192427247e-07\n",
            "    clint ID : 91 training complete.\n",
            "        accuracy : 1.0 - loss : 3.143140645534004e-07\n",
            "    clint ID : 21 training complete.\n",
            "        accuracy : 1.0 - loss : 2.5550463078616303e-07\n",
            "    clint ID : 96 training complete.\n",
            "        accuracy : 1.0 - loss : 2.9782347610307625e-07\n",
            "    clint ID : 41 training complete.\n",
            "        accuracy : 1.0 - loss : 2.0821848067953397e-07\n",
            "    clint ID : 5 training complete.\n",
            "        accuracy : 1.0 - loss : 2.6762387506096275e-07\n",
            "  evaluation mean : accuracy - 1.0, loss - 3.4451343822183844e-07\n",
            "\n",
            "▶ Round 35 ◀\n",
            "selected clients : [22 23 59 73 38 91 21 96 41  5]\n",
            "    clint ID : 22 training complete.\n",
            "        accuracy : 1.0 - loss : 1.8159509806991991e-07\n",
            "    clint ID : 23 training complete.\n",
            "        accuracy : 1.0 - loss : 1.5576654277538182e-07\n",
            "    clint ID : 59 training complete.\n",
            "        accuracy : 1.0 - loss : 2.1676189021491155e-07\n",
            "    clint ID : 73 training complete.\n",
            "        accuracy : 1.0 - loss : 1.4245489410313894e-07\n",
            "    clint ID : 38 training complete.\n",
            "        accuracy : 1.0 - loss : 9.914217713458129e-08\n",
            "    clint ID : 91 training complete.\n",
            "        accuracy : 1.0 - loss : 9.417524182708803e-08\n",
            "    clint ID : 21 training complete.\n",
            "        accuracy : 1.0 - loss : 9.159239766631799e-08\n",
            "    clint ID : 96 training complete.\n",
            "        accuracy : 1.0 - loss : 7.669125778875241e-08\n",
            "    clint ID : 41 training complete.\n",
            "        accuracy : 1.0 - loss : 7.98701762505516e-08\n",
            "    clint ID : 5 training complete.\n",
            "        accuracy : 0.9950000047683716 - loss : 0.016218997538089752\n",
            "  evaluation mean : accuracy - 0.9994999766349792, loss - 0.0016220135148614645\n",
            "\n",
            "▶ Round 36 ◀\n",
            "selected clients : [22 23 59 73 38 91 21 96 41  5]\n",
            "    clint ID : 22 training complete.\n",
            "        accuracy : 1.0 - loss : 7.903503842499049e-07\n",
            "    clint ID : 23 training complete.\n",
            "        accuracy : 1.0 - loss : 8.557145179111103e-07\n",
            "    clint ID : 59 training complete.\n",
            "        accuracy : 1.0 - loss : 1.3424822782326373e-06\n",
            "    clint ID : 73 training complete.\n",
            "        accuracy : 1.0 - loss : 9.786980399439926e-07\n",
            "    clint ID : 38 training complete.\n",
            "        accuracy : 1.0 - loss : 7.128635388653493e-07\n",
            "    clint ID : 91 training complete.\n",
            "        accuracy : 1.0 - loss : 6.816732138759107e-07\n",
            "    clint ID : 21 training complete.\n",
            "        accuracy : 1.0 - loss : 6.077650027691561e-07\n",
            "    clint ID : 96 training complete.\n",
            "        accuracy : 1.0 - loss : 8.45582690089941e-07\n",
            "    clint ID : 41 training complete.\n",
            "        accuracy : 1.0 - loss : 6.874356017760874e-07\n",
            "    clint ID : 5 training complete.\n",
            "        accuracy : 1.0 - loss : 9.069725592780742e-07\n",
            "  evaluation mean : accuracy - 1.0, loss - 8.4095370311843e-07\n",
            "\n",
            "▶ Round 37 ◀\n",
            "selected clients : [22 23 59 73 38 91 21 96 41  5]\n",
            "    clint ID : 22 training complete.\n",
            "        accuracy : 1.0 - loss : 5.322665970197704e-07\n",
            "    clint ID : 23 training complete.\n",
            "        accuracy : 1.0 - loss : 3.230560707834229e-07\n",
            "    clint ID : 59 training complete.\n",
            "        accuracy : 1.0 - loss : 6.600189408345614e-07\n",
            "    clint ID : 73 training complete.\n",
            "        accuracy : 1.0 - loss : 4.136545896926691e-07\n",
            "    clint ID : 38 training complete.\n",
            "        accuracy : 1.0 - loss : 2.996114289999241e-07\n",
            "    clint ID : 91 training complete.\n",
            "        accuracy : 1.0 - loss : 2.9206202611931076e-07\n",
            "    clint ID : 21 training complete.\n",
            "        accuracy : 1.0 - loss : 2.783530135275214e-07\n",
            "    clint ID : 96 training complete.\n",
            "        accuracy : 1.0 - loss : 3.006051372267393e-07\n",
            "    clint ID : 41 training complete.\n",
            "        accuracy : 1.0 - loss : 2.8451216849134653e-07\n",
            "    clint ID : 5 training complete.\n",
            "        accuracy : 1.0 - loss : 3.9060699918991304e-07\n",
            "  evaluation mean : accuracy - 1.0, loss - 3.7747471992588544e-07\n",
            "\n",
            "▶ Round 38 ◀\n",
            "selected clients : [22 23 59 73 38 91 21 96 41  5]\n",
            "    clint ID : 22 training complete.\n",
            "        accuracy : 1.0 - loss : 2.255037259146775e-07\n",
            "    clint ID : 23 training complete.\n",
            "        accuracy : 1.0 - loss : 1.2814982142117515e-07\n",
            "    clint ID : 59 training complete.\n",
            "        accuracy : 1.0 - loss : 2.604718645216053e-07\n",
            "    clint ID : 73 training complete.\n",
            "        accuracy : 1.0 - loss : 1.5974022460341075e-07\n",
            "    clint ID : 38 training complete.\n",
            "        accuracy : 1.0 - loss : 1.217919134433032e-07\n",
            "    clint ID : 91 training complete.\n",
            "        accuracy : 1.0 - loss : 1.0848034293076125e-07\n",
            "    clint ID : 21 training complete.\n",
            "        accuracy : 1.0 - loss : 1.1424211265875783e-07\n",
            "    clint ID : 96 training complete.\n",
            "        accuracy : 1.0 - loss : 1.1006979150351981e-07\n",
            "    clint ID : 41 training complete.\n",
            "        accuracy : 1.0 - loss : 1.0550013485044474e-07\n",
            "    clint ID : 5 training complete.\n",
            "        accuracy : 1.0 - loss : 1.374877882653891e-07\n",
            "  evaluation mean : accuracy - 1.0, loss - 1.4714376561641984e-07\n",
            "\n",
            "▶ Round 39 ◀\n",
            "selected clients : [22 23 59 73 38 91 21 96 41  5]\n",
            "    clint ID : 22 training complete.\n",
            "        accuracy : 1.0 - loss : 8.960556385773089e-08\n",
            "    clint ID : 23 training complete.\n",
            "        accuracy : 1.0 - loss : 4.5498186551640174e-08\n",
            "    clint ID : 59 training complete.\n",
            "        accuracy : 1.0 - loss : 9.775155973557048e-08\n",
            "    clint ID : 73 training complete.\n",
            "        accuracy : 1.0 - loss : 6.278352771005302e-08\n",
            "    clint ID : 38 training complete.\n",
            "        accuracy : 1.0 - loss : 4.351136695390778e-08\n",
            "    clint ID : 91 training complete.\n",
            "        accuracy : 1.0 - loss : 3.556409211569189e-08\n",
            "    clint ID : 21 training complete.\n",
            "        accuracy : 1.0 - loss : 3.894168898455064e-08\n",
            "    clint ID : 96 training complete.\n",
            "        accuracy : 1.0 - loss : 3.437199680433878e-08\n",
            "    clint ID : 41 training complete.\n",
            "        accuracy : 1.0 - loss : 3.7352233306364724e-08\n",
            "    clint ID : 5 training complete.\n",
            "        accuracy : 1.0 - loss : 3.9935091677989476e-08\n",
            "  evaluation mean : accuracy - 1.0, loss - 5.2531525795984635e-08\n",
            "\n",
            "▶ Round 40 ◀\n",
            "selected clients : [22 23 59 73 38 91 21 96 41  5]\n",
            "    clint ID : 22 training complete.\n",
            "        accuracy : 1.0 - loss : 2.7815495684535563e-08\n",
            "    clint ID : 23 training complete.\n",
            "        accuracy : 1.0 - loss : 0.0026140946429222822\n",
            "    clint ID : 59 training complete.\n",
            "        accuracy : 1.0 - loss : 3.323940518384916e-07\n",
            "    clint ID : 73 training complete.\n",
            "        accuracy : 1.0 - loss : 1.5616349458014156e-07\n",
            "    clint ID : 38 training complete.\n",
            "        accuracy : 1.0 - loss : 1.6271991398753016e-07\n",
            "    clint ID : 91 training complete.\n",
            "        accuracy : 1.0 - loss : 1.6629643084797863e-07\n",
            "    clint ID : 21 training complete.\n",
            "        accuracy : 1.0 - loss : 1.448389781444348e-07\n",
            "    clint ID : 96 training complete.\n",
            "        accuracy : 1.0 - loss : 2.0364852559850988e-07\n",
            "    clint ID : 41 training complete.\n",
            "        accuracy : 1.0 - loss : 1.7325044154858915e-07\n",
            "    clint ID : 5 training complete.\n",
            "        accuracy : 1.0 - loss : 1.9828360109386267e-07\n",
            "  evaluation mean : accuracy - 1.0, loss - 0.0002615659905131906\n",
            "\n",
            "▶ Round 41 ◀\n",
            "selected clients : [22 23 59 73 38 91 21 96 41  5]\n",
            "    clint ID : 22 training complete.\n",
            "        accuracy : 1.0 - loss : 4.5478111587726744e-07\n",
            "    clint ID : 23 training complete.\n",
            "        accuracy : 1.0 - loss : 3.1471111583414313e-07\n",
            "    clint ID : 59 training complete.\n",
            "        accuracy : 1.0 - loss : 5.410090579971438e-07\n",
            "    clint ID : 73 training complete.\n",
            "        accuracy : 1.0 - loss : 3.033859456991195e-07\n",
            "    clint ID : 38 training complete.\n",
            "        accuracy : 1.0 - loss : 2.4874893256310315e-07\n",
            "    clint ID : 91 training complete.\n",
            "        accuracy : 1.0 - loss : 3.0755887792111025e-07\n",
            "    clint ID : 21 training complete.\n",
            "        accuracy : 1.0 - loss : 2.467625392910122e-07\n",
            "    clint ID : 96 training complete.\n",
            "        accuracy : 1.0 - loss : 3.697458623719285e-07\n",
            "    clint ID : 41 training complete.\n",
            "        accuracy : 1.0 - loss : 2.882869694076362e-07\n",
            "    clint ID : 5 training complete.\n",
            "        accuracy : 1.0 - loss : 2.642462959556724e-07\n",
            "  evaluation mean : accuracy - 1.0, loss - 3.3392365139661706e-07\n",
            "\n",
            "▶ Round 42 ◀\n",
            "selected clients : [22 23 59 73 38 91 21 96 41  5]\n",
            "    clint ID : 22 training complete.\n",
            "        accuracy : 1.0 - loss : 2.2848394110042136e-07\n",
            "    clint ID : 23 training complete.\n",
            "        accuracy : 1.0 - loss : 1.5060074076700403e-07\n",
            "    clint ID : 59 training complete.\n",
            "        accuracy : 1.0 - loss : 2.2590118931020697e-07\n",
            "    clint ID : 73 training complete.\n",
            "        accuracy : 1.0 - loss : 1.305339765167446e-07\n",
            "    clint ID : 38 training complete.\n",
            "        accuracy : 1.0 - loss : 1.1503673391644043e-07\n",
            "    clint ID : 91 training complete.\n",
            "        accuracy : 1.0 - loss : 1.486139922235452e-07\n",
            "    clint ID : 21 training complete.\n",
            "        accuracy : 1.0 - loss : 9.616206853024778e-08\n",
            "    clint ID : 96 training complete.\n",
            "        accuracy : 1.0 - loss : 1.3033529455697135e-07\n",
            "    clint ID : 41 training complete.\n",
            "        accuracy : 1.0 - loss : 1.1801707699987674e-07\n",
            "    clint ID : 5 training complete.\n",
            "        accuracy : 1.0 - loss : 8.781742621977173e-08\n",
            "  evaluation mean : accuracy - 1.0, loss - 1.4315023122435377e-07\n",
            "\n",
            "▶ Round 43 ◀\n",
            "selected clients : [22 23 59 73 38 91 21 96 41  5]\n",
            "    clint ID : 22 training complete.\n",
            "        accuracy : 1.0 - loss : 8.126093575810955e-08\n",
            "    clint ID : 23 training complete.\n",
            "        accuracy : 1.0 - loss : 4.629291439073313e-08\n",
            "    clint ID : 59 training complete.\n",
            "        accuracy : 1.0 - loss : 6.97373963021164e-08\n",
            "    clint ID : 73 training complete.\n",
            "        accuracy : 1.0 - loss : 4.529951169729429e-08\n",
            "    clint ID : 38 training complete.\n",
            "        accuracy : 1.0 - loss : 4.6292900179878416e-08\n",
            "    clint ID : 91 training complete.\n",
            "        accuracy : 1.0 - loss : 5.225337318393031e-08\n",
            "    clint ID : 21 training complete.\n",
            "        accuracy : 1.0 - loss : 3.9736416823643594e-08\n",
            "    clint ID : 96 training complete.\n",
            "        accuracy : 1.0 - loss : 4.132587250182951e-08\n",
            "    clint ID : 41 training complete.\n",
            "        accuracy : 1.0 - loss : 4.072983372793715e-08\n",
            "    clint ID : 5 training complete.\n",
            "        accuracy : 1.0 - loss : 3.159045292022711e-08\n",
            "  evaluation mean : accuracy - 1.0, loss - 4.9451962524926785e-08\n",
            "\n",
            "▶ Round 44 ◀\n",
            "selected clients : [22 23 59 73 38 91 21 96 41  5]\n",
            "    clint ID : 22 training complete.\n",
            "        accuracy : 1.0 - loss : 2.9802317058624794e-08\n",
            "    clint ID : 23 training complete.\n",
            "        accuracy : 1.0 - loss : 1.688797901522321e-08\n",
            "    clint ID : 59 training complete.\n",
            "        accuracy : 1.0 - loss : 2.602735804657641e-08\n",
            "    clint ID : 73 training complete.\n",
            "        accuracy : 1.0 - loss : 1.4901159417490817e-08\n",
            "    clint ID : 38 training complete.\n",
            "        accuracy : 1.0 - loss : 1.2914336267044746e-08\n",
            "    clint ID : 91 training complete.\n",
            "        accuracy : 1.0 - loss : 1.5695889032940613e-08\n",
            "    clint ID : 21 training complete.\n",
            "        accuracy : 1.0 - loss : 1.3907748730446201e-08\n",
            "    clint ID : 96 training complete.\n",
            "        accuracy : 1.0 - loss : 1.1126199517264013e-08\n",
            "    clint ID : 41 training complete.\n",
            "        accuracy : 1.0 - loss : 1.2318292164081868e-08\n",
            "    clint ID : 5 training complete.\n",
            "        accuracy : 1.0 - loss : 7.549920688632028e-09\n",
            "  evaluation mean : accuracy - 1.0, loss - 1.6113119727378944e-08\n",
            "\n",
            "▶ Round 45 ◀\n",
            "selected clients : [22 23 59 73 38 91 21 96 41  5]\n",
            "    clint ID : 22 training complete.\n",
            "        accuracy : 1.0 - loss : 9.735424910672918e-09\n",
            "    clint ID : 23 training complete.\n",
            "        accuracy : 1.0 - loss : 5.563099758632006e-09\n",
            "    clint ID : 59 training complete.\n",
            "        accuracy : 1.0 - loss : 9.139378143174781e-09\n",
            "    clint ID : 73 training complete.\n",
            "        accuracy : 1.0 - loss : 5.165735394996318e-09\n",
            "    clint ID : 38 training complete.\n",
            "        accuracy : 0.9983333349227905 - loss : 0.005402286536991596\n",
            "    clint ID : 91 training complete.\n",
            "        accuracy : 1.0 - loss : 7.768456100620824e-08\n",
            "    clint ID : 21 training complete.\n",
            "        accuracy : 1.0 - loss : 8.00687800506239e-08\n",
            "    clint ID : 96 training complete.\n",
            "        accuracy : 1.0 - loss : 1.2854694375619147e-07\n",
            "    clint ID : 41 training complete.\n",
            "        accuracy : 1.0 - loss : 8.881076496436435e-08\n",
            "    clint ID : 5 training complete.\n",
            "        accuracy : 1.0 - loss : 7.549901681613846e-08\n",
            "  evaluation mean : accuracy - 0.9998332858085632, loss - 0.0005402766983024776\n",
            "\n",
            "▶ Round 46 ◀\n",
            "selected clients : [22 23 59 73 38 91 21 96 41  5]\n",
            "    clint ID : 22 training complete.\n",
            "        accuracy : 1.0 - loss : 6.496898663499451e-08\n",
            "    clint ID : 23 training complete.\n",
            "        accuracy : 1.0 - loss : 8.960549280345731e-08\n",
            "    clint ID : 59 training complete.\n",
            "        accuracy : 1.0 - loss : 1.9947648866036616e-07\n",
            "    clint ID : 73 training complete.\n",
            "        accuracy : 1.0 - loss : 1.0271846662135431e-07\n",
            "    clint ID : 38 training complete.\n",
            "        accuracy : 1.0 - loss : 1.5795149010955356e-07\n",
            "    clint ID : 91 training complete.\n",
            "        accuracy : 1.0 - loss : 1.486138785367075e-07\n",
            "    clint ID : 21 training complete.\n",
            "        accuracy : 1.0 - loss : 1.3351400696137716e-07\n",
            "    clint ID : 96 training complete.\n",
            "        accuracy : 1.0 - loss : 1.8676040269838268e-07\n",
            "    clint ID : 41 training complete.\n",
            "        accuracy : 1.0 - loss : 4.311400658707498e-08\n",
            "    clint ID : 5 training complete.\n",
            "        accuracy : 1.0 - loss : 9.278441837068385e-08\n",
            "  evaluation mean : accuracy - 1.0, loss - 1.2195076237730973e-07\n",
            "\n",
            "▶ Round 47 ◀\n",
            "selected clients : [22 23 59 73 38 91 21 96 41  5]\n",
            "    clint ID : 22 training complete.\n",
            "        accuracy : 1.0 - loss : 3.159044936751343e-08\n",
            "    clint ID : 23 training complete.\n",
            "        accuracy : 1.0 - loss : 2.622603467727913e-08\n",
            "    clint ID : 59 training complete.\n",
            "        accuracy : 1.0 - loss : 6.000198027322767e-08\n",
            "    clint ID : 73 training complete.\n",
            "        accuracy : 1.0 - loss : 5.1855991500815435e-08\n",
            "    clint ID : 38 training complete.\n",
            "        accuracy : 1.0 - loss : 6.516763306763096e-08\n",
            "    clint ID : 91 training complete.\n",
            "        accuracy : 1.0 - loss : 4.03324484921086e-08\n",
            "    clint ID : 21 training complete.\n",
            "        accuracy : 1.0 - loss : 3.933904224595608e-08\n",
            "    clint ID : 96 training complete.\n",
            "        accuracy : 1.0 - loss : 2.7219442699788488e-08\n",
            "    clint ID : 41 training complete.\n",
            "        accuracy : 1.0 - loss : 4.331268854684822e-08\n",
            "    clint ID : 5 training complete.\n",
            "        accuracy : 1.0 - loss : 5.1458627581268956e-08\n",
            "  evaluation mean : accuracy - 1.0, loss - 4.365043793086443e-08\n",
            "\n",
            "▶ Round 48 ◀\n",
            "selected clients : [22 23 59 73 38 91 21 96 41  5]\n",
            "    clint ID : 22 training complete.\n",
            "        accuracy : 1.0 - loss : 2.5232621325699256e-08\n",
            "    clint ID : 23 training complete.\n",
            "        accuracy : 1.0 - loss : 1.7285341158412848e-08\n",
            "    clint ID : 59 training complete.\n",
            "        accuracy : 1.0 - loss : 2.7418129988632245e-08\n",
            "    clint ID : 73 training complete.\n",
            "        accuracy : 1.0 - loss : 2.125898390659131e-08\n",
            "    clint ID : 38 training complete.\n",
            "        accuracy : 1.0 - loss : 2.0265567002297757e-08\n",
            "    clint ID : 91 training complete.\n",
            "        accuracy : 1.0 - loss : 2.4239216855903578e-08\n",
            "    clint ID : 21 training complete.\n",
            "        accuracy : 1.0 - loss : 1.5497205296810534e-08\n",
            "    clint ID : 96 training complete.\n",
            "        accuracy : 1.0 - loss : 1.5099839600907217e-08\n",
            "    clint ID : 41 training complete.\n",
            "        accuracy : 1.0 - loss : 1.86761184295392e-08\n",
            "    clint ID : 5 training complete.\n",
            "        accuracy : 1.0 - loss : 2.2053711745684268e-08\n",
            "  evaluation mean : accuracy - 1.0, loss - 2.0702673353412138e-08\n",
            "\n",
            "▶ Round 49 ◀\n",
            "selected clients : [22 23 59 73 38 91 21 96 41  5]\n",
            "    clint ID : 22 training complete.\n",
            "        accuracy : 1.0 - loss : 1.3907748730446201e-08\n",
            "    clint ID : 23 training complete.\n",
            "        accuracy : 1.0 - loss : 8.543331375676644e-09\n",
            "    clint ID : 59 training complete.\n",
            "        accuracy : 1.0 - loss : 1.3709066770672962e-08\n",
            "    clint ID : 73 training complete.\n",
            "        accuracy : 1.0 - loss : 9.139378143174781e-09\n",
            "    clint ID : 38 training complete.\n",
            "        accuracy : 1.0 - loss : 9.139375478639522e-09\n",
            "    clint ID : 91 training complete.\n",
            "        accuracy : 1.0 - loss : 7.351237840680369e-09\n",
            "    clint ID : 21 training complete.\n",
            "        accuracy : 1.0 - loss : 7.748602648405267e-09\n",
            "    clint ID : 96 training complete.\n",
            "        accuracy : 1.0 - loss : 8.145967456130165e-09\n",
            "    clint ID : 41 training complete.\n",
            "        accuracy : 1.0 - loss : 8.940696183401542e-09\n",
            "    clint ID : 5 training complete.\n",
            "        accuracy : 1.0 - loss : 1.0530152749765875e-08\n",
            "  evaluation mean : accuracy - 1.0, loss - 9.715554583067387e-09\n",
            "\n",
            "▶ Round 50 ◀\n",
            "selected clients : [22 23 59 73 38 91 21 96 41  5]\n",
            "    clint ID : 22 training complete.\n",
            "        accuracy : 1.0 - loss : 6.9538743652231005e-09\n",
            "    clint ID : 23 training complete.\n",
            "        accuracy : 1.0 - loss : 4.371007111814151e-09\n",
            "    clint ID : 59 training complete.\n",
            "        accuracy : 1.0 - loss : 6.755192405449861e-09\n",
            "    clint ID : 73 training complete.\n",
            "        accuracy : 1.0 - loss : 3.576278384542775e-09\n",
            "    clint ID : 38 training complete.\n",
            "        accuracy : 1.0 - loss : 3.576278384542775e-09\n",
            "    clint ID : 91 training complete.\n",
            "        accuracy : 1.0 - loss : 2.781549879316003e-09\n",
            "    clint ID : 21 training complete.\n",
            "        accuracy : 1.0 - loss : 2.9802320611338473e-09\n",
            "    clint ID : 96 training complete.\n",
            "        accuracy : 1.0 - loss : 2.781549879316003e-09\n",
            "    clint ID : 41 training complete.\n",
            "        accuracy : 1.0 - loss : 3.1789142429516914e-09\n",
            "    clint ID : 5 training complete.\n",
            "        accuracy : 1.0 - loss : 0.0007104678661562502\n",
            "  evaluation mean : accuracy - 1.0, loss - 7.105048280209303e-05\n",
            "\n",
            "\n",
            "▶▶▶ Round is over.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0xK8gEe5s0E3",
        "outputId": "a613ae2e-c2b4-48f5-8a94-18a6b9ec50df"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "#drive.flush_and_unmount()"
      ],
      "id": "0xK8gEe5s0E3",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r3-MwKohTbTK"
      },
      "source": [
        "# Looped Training"
      ],
      "id": "r3-MwKohTbTK"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HY1HV7h6TaEx",
        "outputId": "888624fa-7166-4a77-b455-ba03365b45fb"
      },
      "source": [
        "mnist_train, mnist_test = tf.keras.datasets.mnist.load_data() # This dataset is not \"E\"mnist. Don't confuse!\r\n",
        "raw_dataset_for_iid=list(zip(mnist_train[0].reshape(-1, 28, 28, 1).astype(\"float32\")/255.0, mnist_train[1].astype(\"float32\")))\r\n",
        "loop_number = 500\r\n",
        "for i in range(loop_number):\r\n",
        "  parameter_saver= ParameterSaver()\r\n",
        "  random.shuffle(raw_dataset_for_iid)\r\n",
        "\r\n",
        "  el_size=600\r\n",
        "  temp_list_for_image=[]\r\n",
        "  temp_list_for_label=[]\r\n",
        "  federated_train_data_for_iid=[]\r\n",
        "  for idx, el in enumerate(raw_dataset_for_iid) :\r\n",
        "      temp_list_for_image.append(el[0])\r\n",
        "      temp_list_for_label.append(el[1])\r\n",
        "      if (idx+1)%(el_size)==0 :\r\n",
        "          federated_train_data_for_iid.append((np.array(temp_list_for_image, dtype=\"float32\"), np.array(temp_list_for_label, dtype=\"float32\")))\r\n",
        "          temp_list_for_image=[]\r\n",
        "          temp_list_for_label=[]\r\n",
        "          \r\n",
        "  federated_train_data = federated_train_data_for_iid\r\n",
        "\r\n",
        "  TOTAL_CLIENTS = len(federated_train_data)\r\n",
        "  SELECTED_CLIENTS = int(TOTAL_CLIENTS*FRACTION)\r\n",
        "  print(\"total client :\", TOTAL_CLIENTS, \", selected client :\", SELECTED_CLIENTS)\r\n",
        "\r\n",
        "  # starting to training\r\n",
        "  selected_clients_list=clients_status_list=np.random.choice(TOTAL_CLIENTS, size=SELECTED_CLIENTS, replace=False) # that is relevant to 4-2 step.\r\n",
        "\r\n",
        "  global_parameter=keras_model.get_weights()\r\n",
        "  parameter_saver.save_initial_parameter(global_parameter)\r\n",
        "\r\n",
        "  print(\"-- prameter shape --\")\r\n",
        "  for layer in global_parameter :\r\n",
        "      print(layer.shape)\r\n",
        "\r\n",
        "  list_of_local_parameter=[]\r\n",
        "  list_of_local_dataset_size=[]\r\n",
        "  list_of_local_accuracy=[]\r\n",
        "  list_of_local_loss=[]\r\n",
        "\r\n",
        "  for round in range(TRAINING_ROUNDS) :\r\n",
        "      print(\"\\n▶ Round\", round+1, \"◀\")\r\n",
        "      parameter_saver.round_start(round+1)\r\n",
        "      \r\n",
        "          # check whether to apply shuffle mode per round\r\n",
        "      if CLIENTS_SHUFFLE_PER_ROUND == True :\r\n",
        "          selected_clients_list = np.random.choice(TOTAL_CLIENTS, size=SELECTED_CLIENTS, replace=False)\r\n",
        "      print(\"selected clients :\", selected_clients_list)\r\n",
        "\r\n",
        "          # receive Local parameter.\r\n",
        "      for client_dataset in selected_clients_list :\r\n",
        "          train_images, train_labels=federated_train_data[client_dataset]\r\n",
        "          \r\n",
        "          keras_model.set_weights(global_parameter)\r\n",
        "          \r\n",
        "          train_result=keras_model.fit(train_images, train_labels, batch_size=BATCH_SIZE, epochs=NUM_EPOCHS, verbose=0)\r\n",
        "              \r\n",
        "          local_parameter=keras_model.get_weights()\r\n",
        "          list_of_local_parameter.append(local_parameter)\r\n",
        "          parameter_saver.save_local_parameter(client_dataset, local_parameter)\r\n",
        "          list_of_local_dataset_size.append(len(train_images))\r\n",
        "          list_of_local_accuracy.append(train_result.history[\"accuracy\"][-1])\r\n",
        "          list_of_local_loss.append(train_result.history[\"loss\"][-1])\r\n",
        "          \r\n",
        "          print(\"    clint ID :\", client_dataset, \"training complete.\")\r\n",
        "          print(\"        accuracy :\", train_result.history[\"accuracy\"][-1], \"- loss :\", train_result.history[\"loss\"][-1])\r\n",
        "      \r\n",
        "          #4-5. aggregate Local parameters.\r\n",
        "      global_parameter = np.mean(list_of_local_parameter, axis=0)\r\n",
        "      #global_parameter = np.mean(list_of_local_parameter, axis=0)*np.sum(list_of_local_dataset_size)\r\n",
        "      #print(\"global_parameter :\",global_parameter)\r\n",
        "      parameter_saver.save_aggreated_global_parameter(global_parameter)\r\n",
        "      current_mean_accuracy = np.mean(np.array(list_of_local_accuracy, dtype=\"float32\"))\r\n",
        "      current_mean_loss = np.mean(np.array(list_of_local_loss, dtype=\"float32\"))\r\n",
        "      print(f\"  evaluation mean : accuracy - {current_mean_accuracy}, loss - {current_mean_loss}\")   \r\n",
        "      \r\n",
        "      list_of_local_parameter.clear()\r\n",
        "      list_of_local_dataset_size.clear()\r\n",
        "      list_of_local_accuracy.clear()\r\n",
        "      list_of_local_loss.clear()\r\n",
        "      \r\n",
        "  print(\"\\n\\n▶▶▶ Round is over.\")\r\n"
      ],
      "id": "HY1HV7h6TaEx",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "parameter_set_20210227080821 directory is created in /content/drive/MyDrive/Federated-Learning/fl-model-parameters-dataset\n",
            "total client : 100 , selected client : 10\n",
            "-- prameter shape --\n",
            "(5, 5, 1, 32)\n",
            "(32,)\n",
            "(5, 5, 32, 64)\n",
            "(64,)\n",
            "(3136, 512)\n",
            "(512,)\n",
            "(512, 10)\n",
            "(10,)\n",
            "\n",
            "▶ Round 1 ◀\n",
            "selected clients : [ 4 69 30 79 48  1 94 95 80 99]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/numpy/core/_asarray.py:83: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  return array(a, dtype, copy=False, order=order)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "    clint ID : 4 training complete.\n",
            "        accuracy : 1.0 - loss : 0.0033129143994301558\n",
            "    clint ID : 69 training complete.\n",
            "        accuracy : 0.9933333396911621 - loss : 0.018763573840260506\n",
            "    clint ID : 30 training complete.\n",
            "        accuracy : 1.0 - loss : 0.004421088378876448\n",
            "    clint ID : 79 training complete.\n",
            "        accuracy : 1.0 - loss : 0.0021966174244880676\n",
            "    clint ID : 48 training complete.\n",
            "        accuracy : 1.0 - loss : 0.0032321838662028313\n",
            "    clint ID : 1 training complete.\n",
            "        accuracy : 0.9883333444595337 - loss : 0.02827613241970539\n",
            "    clint ID : 94 training complete.\n",
            "        accuracy : 0.9950000047683716 - loss : 0.019042905420064926\n",
            "    clint ID : 95 training complete.\n",
            "        accuracy : 1.0 - loss : 0.003622181713581085\n",
            "    clint ID : 80 training complete.\n",
            "        accuracy : 0.996666669845581 - loss : 0.009850829839706421\n",
            "    clint ID : 99 training complete.\n",
            "        accuracy : 0.9933333396911621 - loss : 0.0183672234416008\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/numpy/core/_asarray.py:136: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  return array(a, dtype, copy=False, order=order, subok=True)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "  evaluation mean : accuracy - 0.9966667294502258, loss - 0.011108564212918282\n",
            "\n",
            "▶ Round 2 ◀\n",
            "selected clients : [ 4 69 30 79 48  1 94 95 80 99]\n",
            "    clint ID : 4 training complete.\n",
            "        accuracy : 1.0 - loss : 0.001043850788846612\n",
            "    clint ID : 69 training complete.\n",
            "        accuracy : 1.0 - loss : 0.001866255421191454\n",
            "    clint ID : 30 training complete.\n",
            "        accuracy : 0.9950000047683716 - loss : 0.02092166058719158\n",
            "    clint ID : 79 training complete.\n",
            "        accuracy : 0.9900000095367432 - loss : 0.03940178081393242\n",
            "    clint ID : 48 training complete.\n",
            "        accuracy : 1.0 - loss : 0.00046823441516608\n",
            "    clint ID : 1 training complete.\n",
            "        accuracy : 1.0 - loss : 0.0021347778383642435\n",
            "    clint ID : 94 training complete.\n",
            "        accuracy : 1.0 - loss : 0.000568116141948849\n",
            "    clint ID : 95 training complete.\n",
            "        accuracy : 0.996666669845581 - loss : 0.004579586908221245\n",
            "    clint ID : 80 training complete.\n",
            "        accuracy : 1.0 - loss : 0.00044035157770849764\n",
            "    clint ID : 99 training complete.\n",
            "        accuracy : 1.0 - loss : 0.0013801144668832421\n",
            "  evaluation mean : accuracy - 0.9981666803359985, loss - 0.007280472666025162\n",
            "\n",
            "▶ Round 3 ◀\n",
            "selected clients : [ 4 69 30 79 48  1 94 95 80 99]\n",
            "    clint ID : 4 training complete.\n",
            "        accuracy : 1.0 - loss : 0.0018294855253770947\n",
            "    clint ID : 69 training complete.\n",
            "        accuracy : 1.0 - loss : 0.0014245230704545975\n",
            "    clint ID : 30 training complete.\n",
            "        accuracy : 1.0 - loss : 0.000835439539514482\n",
            "    clint ID : 79 training complete.\n",
            "        accuracy : 0.9866666793823242 - loss : 0.032618872821331024\n",
            "    clint ID : 48 training complete.\n",
            "        accuracy : 1.0 - loss : 0.0006846555625088513\n",
            "    clint ID : 1 training complete.\n",
            "        accuracy : 0.996666669845581 - loss : 0.012642893008887768\n",
            "    clint ID : 94 training complete.\n",
            "        accuracy : 1.0 - loss : 0.00039026542799547315\n",
            "    clint ID : 95 training complete.\n",
            "        accuracy : 0.996666669845581 - loss : 0.009844392538070679\n",
            "    clint ID : 80 training complete.\n",
            "        accuracy : 1.0 - loss : 0.0005902969278395176\n",
            "    clint ID : 99 training complete.\n",
            "        accuracy : 1.0 - loss : 0.00044987493311055005\n",
            "  evaluation mean : accuracy - 0.9979999661445618, loss - 0.0061310697346925735\n",
            "\n",
            "▶ Round 4 ◀\n",
            "selected clients : [ 4 69 30 79 48  1 94 95 80 99]\n",
            "    clint ID : 4 training complete.\n",
            "        accuracy : 1.0 - loss : 0.0004978211945854127\n",
            "    clint ID : 69 training complete.\n",
            "        accuracy : 1.0 - loss : 0.00045620460878126323\n",
            "    clint ID : 30 training complete.\n",
            "        accuracy : 1.0 - loss : 0.000180480390554294\n",
            "    clint ID : 79 training complete.\n",
            "        accuracy : 0.996666669845581 - loss : 0.009839781560003757\n",
            "    clint ID : 48 training complete.\n",
            "        accuracy : 1.0 - loss : 0.0003863598976749927\n",
            "    clint ID : 1 training complete.\n",
            "        accuracy : 1.0 - loss : 0.0017149816267192364\n",
            "    clint ID : 94 training complete.\n",
            "        accuracy : 1.0 - loss : 0.001738096820190549\n",
            "    clint ID : 95 training complete.\n",
            "        accuracy : 1.0 - loss : 0.000612380972597748\n",
            "    clint ID : 80 training complete.\n",
            "        accuracy : 1.0 - loss : 0.0003954468993470073\n",
            "    clint ID : 99 training complete.\n",
            "        accuracy : 1.0 - loss : 0.00023204152239486575\n",
            "  evaluation mean : accuracy - 0.999666690826416, loss - 0.0016053594881668687\n",
            "\n",
            "▶ Round 5 ◀\n",
            "selected clients : [ 4 69 30 79 48  1 94 95 80 99]\n",
            "    clint ID : 4 training complete.\n",
            "        accuracy : 1.0 - loss : 0.00025701095000840724\n",
            "    clint ID : 69 training complete.\n",
            "        accuracy : 1.0 - loss : 0.0005806527915410697\n",
            "    clint ID : 30 training complete.\n",
            "        accuracy : 0.9983333349227905 - loss : 0.0038578736130148172\n",
            "    clint ID : 79 training complete.\n",
            "        accuracy : 1.0 - loss : 0.0001627374003874138\n",
            "    clint ID : 48 training complete.\n",
            "        accuracy : 1.0 - loss : 0.000763936317525804\n",
            "    clint ID : 1 training complete.\n",
            "        accuracy : 1.0 - loss : 0.00113300618249923\n",
            "    clint ID : 94 training complete.\n",
            "        accuracy : 1.0 - loss : 0.00041210014023818076\n",
            "    clint ID : 95 training complete.\n",
            "        accuracy : 1.0 - loss : 0.0006560912588611245\n",
            "    clint ID : 80 training complete.\n",
            "        accuracy : 1.0 - loss : 0.00025513028958812356\n",
            "    clint ID : 99 training complete.\n",
            "        accuracy : 1.0 - loss : 0.00046200951328501105\n",
            "  evaluation mean : accuracy - 0.9998332858085632, loss - 0.0008540548151358962\n",
            "\n",
            "▶ Round 6 ◀\n",
            "selected clients : [ 4 69 30 79 48  1 94 95 80 99]\n",
            "    clint ID : 4 training complete.\n",
            "        accuracy : 1.0 - loss : 0.002048307564109564\n",
            "    clint ID : 69 training complete.\n",
            "        accuracy : 1.0 - loss : 0.0003188695991411805\n",
            "    clint ID : 30 training complete.\n",
            "        accuracy : 1.0 - loss : 0.00024448451586067677\n",
            "    clint ID : 79 training complete.\n",
            "        accuracy : 1.0 - loss : 0.00017478715744800866\n",
            "    clint ID : 48 training complete.\n",
            "        accuracy : 1.0 - loss : 0.0001813228300306946\n",
            "    clint ID : 1 training complete.\n",
            "        accuracy : 0.9950000047683716 - loss : 0.031000375747680664\n",
            "    clint ID : 94 training complete.\n",
            "        accuracy : 1.0 - loss : 0.00015996431466192007\n",
            "    clint ID : 95 training complete.\n",
            "        accuracy : 0.9983333349227905 - loss : 0.009872006252408028\n",
            "    clint ID : 80 training complete.\n",
            "        accuracy : 1.0 - loss : 0.004306969232857227\n",
            "    clint ID : 99 training complete.\n",
            "        accuracy : 1.0 - loss : 0.00024369284801650792\n",
            "  evaluation mean : accuracy - 0.999333381652832, loss - 0.004855078179389238\n",
            "\n",
            "▶ Round 7 ◀\n",
            "selected clients : [ 4 69 30 79 48  1 94 95 80 99]\n",
            "    clint ID : 4 training complete.\n",
            "        accuracy : 1.0 - loss : 0.0002626744972076267\n",
            "    clint ID : 69 training complete.\n",
            "        accuracy : 1.0 - loss : 0.0002045627625193447\n",
            "    clint ID : 30 training complete.\n",
            "        accuracy : 0.9900000095367432 - loss : 0.030071821063756943\n",
            "    clint ID : 79 training complete.\n",
            "        accuracy : 1.0 - loss : 0.00010923937952611595\n",
            "    clint ID : 48 training complete.\n",
            "        accuracy : 0.9983333349227905 - loss : 0.0030859641265124083\n",
            "    clint ID : 1 training complete.\n",
            "        accuracy : 1.0 - loss : 0.00012346608855295926\n",
            "    clint ID : 94 training complete.\n",
            "        accuracy : 1.0 - loss : 0.0003047135833185166\n",
            "    clint ID : 95 training complete.\n",
            "        accuracy : 0.9983333349227905 - loss : 0.006494611036032438\n",
            "    clint ID : 80 training complete.\n",
            "        accuracy : 1.0 - loss : 0.00011884169362019747\n",
            "    clint ID : 99 training complete.\n",
            "        accuracy : 1.0 - loss : 8.351860742550343e-05\n",
            "  evaluation mean : accuracy - 0.9986666440963745, loss - 0.004085940774530172\n",
            "\n",
            "▶ Round 8 ◀\n",
            "selected clients : [ 4 69 30 79 48  1 94 95 80 99]\n",
            "    clint ID : 4 training complete.\n",
            "        accuracy : 1.0 - loss : 0.00010741352889453992\n",
            "    clint ID : 69 training complete.\n",
            "        accuracy : 1.0 - loss : 0.0006523015326820314\n",
            "    clint ID : 30 training complete.\n",
            "        accuracy : 0.9866666793823242 - loss : 0.04284394159913063\n",
            "    clint ID : 79 training complete.\n",
            "        accuracy : 1.0 - loss : 0.0016230581095442176\n",
            "    clint ID : 48 training complete.\n",
            "        accuracy : 1.0 - loss : 5.326342579792254e-05\n",
            "    clint ID : 1 training complete.\n",
            "        accuracy : 1.0 - loss : 0.00015772956248838454\n",
            "    clint ID : 94 training complete.\n",
            "        accuracy : 1.0 - loss : 0.001072360435500741\n",
            "    clint ID : 95 training complete.\n",
            "        accuracy : 0.996666669845581 - loss : 0.011103394441306591\n",
            "    clint ID : 80 training complete.\n",
            "        accuracy : 1.0 - loss : 0.00010350247612223029\n",
            "    clint ID : 99 training complete.\n",
            "        accuracy : 1.0 - loss : 0.00014224348706193268\n",
            "  evaluation mean : accuracy - 0.9983333349227905, loss - 0.005785920657217503\n",
            "\n",
            "▶ Round 9 ◀\n",
            "selected clients : [ 4 69 30 79 48  1 94 95 80 99]\n",
            "    clint ID : 4 training complete.\n",
            "        accuracy : 1.0 - loss : 0.0013131462037563324\n",
            "    clint ID : 69 training complete.\n",
            "        accuracy : 1.0 - loss : 0.0003932905092369765\n",
            "    clint ID : 30 training complete.\n",
            "        accuracy : 1.0 - loss : 9.406630852026865e-05\n",
            "    clint ID : 79 training complete.\n",
            "        accuracy : 1.0 - loss : 7.20688549336046e-05\n",
            "    clint ID : 48 training complete.\n",
            "        accuracy : 0.9950000047683716 - loss : 0.05490128695964813\n",
            "    clint ID : 1 training complete.\n",
            "        accuracy : 1.0 - loss : 0.00013352822861634195\n",
            "    clint ID : 94 training complete.\n",
            "        accuracy : 1.0 - loss : 0.00029952384647913277\n",
            "    clint ID : 95 training complete.\n",
            "        accuracy : 0.9983333349227905 - loss : 0.003245353465899825\n",
            "    clint ID : 80 training complete.\n",
            "        accuracy : 1.0 - loss : 8.313514990732074e-05\n",
            "    clint ID : 99 training complete.\n",
            "        accuracy : 1.0 - loss : 0.0030830169562250376\n",
            "  evaluation mean : accuracy - 0.999333381652832, loss - 0.006361842155456543\n",
            "\n",
            "▶ Round 10 ◀\n",
            "selected clients : [ 4 69 30 79 48  1 94 95 80 99]\n",
            "    clint ID : 4 training complete.\n",
            "        accuracy : 1.0 - loss : 0.00011174129031132907\n",
            "    clint ID : 69 training complete.\n",
            "        accuracy : 1.0 - loss : 0.0001564405538374558\n",
            "    clint ID : 30 training complete.\n",
            "        accuracy : 1.0 - loss : 6.008625132380985e-05\n",
            "    clint ID : 79 training complete.\n",
            "        accuracy : 1.0 - loss : 0.0002966932952404022\n",
            "    clint ID : 48 training complete.\n",
            "        accuracy : 1.0 - loss : 0.00010474942973814905\n",
            "    clint ID : 1 training complete.\n",
            "        accuracy : 1.0 - loss : 0.0002073643554467708\n",
            "    clint ID : 94 training complete.\n",
            "        accuracy : 1.0 - loss : 7.628867024322972e-05\n",
            "    clint ID : 95 training complete.\n",
            "        accuracy : 1.0 - loss : 6.144439976196736e-05\n",
            "    clint ID : 80 training complete.\n",
            "        accuracy : 0.9950000047683716 - loss : 0.02606082521378994\n",
            "    clint ID : 99 training complete.\n",
            "        accuracy : 1.0 - loss : 0.000789813173469156\n",
            "  evaluation mean : accuracy - 0.9994999766349792, loss - 0.002792544662952423\n",
            "\n",
            "▶ Round 11 ◀\n",
            "selected clients : [ 4 69 30 79 48  1 94 95 80 99]\n",
            "    clint ID : 4 training complete.\n",
            "        accuracy : 1.0 - loss : 4.2836869397433475e-05\n",
            "    clint ID : 69 training complete.\n",
            "        accuracy : 1.0 - loss : 0.0014183883322402835\n",
            "    clint ID : 30 training complete.\n",
            "        accuracy : 1.0 - loss : 6.445756298489869e-05\n",
            "    clint ID : 79 training complete.\n",
            "        accuracy : 1.0 - loss : 4.785913188243285e-05\n",
            "    clint ID : 48 training complete.\n",
            "        accuracy : 0.9916666746139526 - loss : 0.03276410698890686\n",
            "    clint ID : 1 training complete.\n",
            "        accuracy : 1.0 - loss : 0.00010427523375255987\n",
            "    clint ID : 94 training complete.\n",
            "        accuracy : 1.0 - loss : 4.715104296337813e-05\n",
            "    clint ID : 95 training complete.\n",
            "        accuracy : 1.0 - loss : 6.1029102653265e-05\n",
            "    clint ID : 80 training complete.\n",
            "        accuracy : 1.0 - loss : 5.623602555715479e-05\n",
            "    clint ID : 99 training complete.\n",
            "        accuracy : 0.9750000238418579 - loss : 0.08626658469438553\n",
            "  evaluation mean : accuracy - 0.9966667294502258, loss - 0.012087292037904263\n",
            "\n",
            "▶ Round 12 ◀\n",
            "selected clients : [ 4 69 30 79 48  1 94 95 80 99]\n",
            "    clint ID : 4 training complete.\n",
            "        accuracy : 1.0 - loss : 8.283628994831815e-05\n",
            "    clint ID : 69 training complete.\n",
            "        accuracy : 1.0 - loss : 0.0009662329102866352\n",
            "    clint ID : 30 training complete.\n",
            "        accuracy : 1.0 - loss : 6.205201498232782e-05\n",
            "    clint ID : 79 training complete.\n",
            "        accuracy : 1.0 - loss : 5.973778024781495e-05\n",
            "    clint ID : 48 training complete.\n",
            "        accuracy : 1.0 - loss : 3.831413050647825e-05\n",
            "    clint ID : 1 training complete.\n",
            "        accuracy : 1.0 - loss : 7.242795254569501e-05\n",
            "    clint ID : 94 training complete.\n",
            "        accuracy : 1.0 - loss : 0.00011208574142074212\n",
            "    clint ID : 95 training complete.\n",
            "        accuracy : 1.0 - loss : 6.647183181485161e-05\n",
            "    clint ID : 80 training complete.\n",
            "        accuracy : 1.0 - loss : 5.9194237110204995e-05\n",
            "    clint ID : 99 training complete.\n",
            "        accuracy : 1.0 - loss : 4.6401924919337034e-05\n",
            "  evaluation mean : accuracy - 1.0, loss - 0.00015657549374736845\n",
            "\n",
            "▶ Round 13 ◀\n",
            "selected clients : [ 4 69 30 79 48  1 94 95 80 99]\n",
            "    clint ID : 4 training complete.\n",
            "        accuracy : 1.0 - loss : 2.53903435805114e-05\n",
            "    clint ID : 69 training complete.\n",
            "        accuracy : 0.9933333396911621 - loss : 0.018310710787773132\n",
            "    clint ID : 30 training complete.\n",
            "        accuracy : 1.0 - loss : 6.135883450042456e-05\n",
            "    clint ID : 79 training complete.\n",
            "        accuracy : 1.0 - loss : 5.329271880327724e-05\n",
            "    clint ID : 48 training complete.\n",
            "        accuracy : 1.0 - loss : 3.0104993129498325e-05\n",
            "    clint ID : 1 training complete.\n",
            "        accuracy : 1.0 - loss : 3.703893889905885e-05\n",
            "    clint ID : 94 training complete.\n",
            "        accuracy : 1.0 - loss : 3.937381552532315e-05\n",
            "    clint ID : 95 training complete.\n",
            "        accuracy : 1.0 - loss : 2.969803063024301e-05\n",
            "    clint ID : 80 training complete.\n",
            "        accuracy : 1.0 - loss : 2.387491440458689e-05\n",
            "    clint ID : 99 training complete.\n",
            "        accuracy : 1.0 - loss : 1.8689437638386153e-05\n",
            "  evaluation mean : accuracy - 0.999333381652832, loss - 0.001862953184172511\n",
            "\n",
            "▶ Round 14 ◀\n",
            "selected clients : [ 4 69 30 79 48  1 94 95 80 99]\n",
            "    clint ID : 4 training complete.\n",
            "        accuracy : 0.996666669845581 - loss : 0.010630573146045208\n",
            "    clint ID : 69 training complete.\n",
            "        accuracy : 0.9983333349227905 - loss : 0.009393543936312199\n",
            "    clint ID : 30 training complete.\n",
            "        accuracy : 1.0 - loss : 4.24638856202364e-05\n",
            "    clint ID : 79 training complete.\n",
            "        accuracy : 1.0 - loss : 4.0191865991801023e-05\n",
            "    clint ID : 48 training complete.\n",
            "        accuracy : 1.0 - loss : 3.9123420719988644e-05\n",
            "    clint ID : 1 training complete.\n",
            "        accuracy : 0.9883333444595337 - loss : 0.03319019451737404\n",
            "    clint ID : 94 training complete.\n",
            "        accuracy : 1.0 - loss : 3.580930570024066e-05\n",
            "    clint ID : 95 training complete.\n",
            "        accuracy : 1.0 - loss : 4.217429886921309e-05\n",
            "    clint ID : 80 training complete.\n",
            "        accuracy : 1.0 - loss : 3.757137164939195e-05\n",
            "    clint ID : 99 training complete.\n",
            "        accuracy : 1.0 - loss : 2.760548159130849e-05\n",
            "  evaluation mean : accuracy - 0.9983333349227905, loss - 0.005347925238311291\n",
            "\n",
            "▶ Round 15 ◀\n",
            "selected clients : [ 4 69 30 79 48  1 94 95 80 99]\n",
            "    clint ID : 4 training complete.\n",
            "        accuracy : 1.0 - loss : 2.645334279804956e-05\n",
            "    clint ID : 69 training complete.\n",
            "        accuracy : 1.0 - loss : 1.921036709973123e-05\n",
            "    clint ID : 30 training complete.\n",
            "        accuracy : 1.0 - loss : 1.650275407882873e-05\n",
            "    clint ID : 79 training complete.\n",
            "        accuracy : 1.0 - loss : 1.2648379197344184e-05\n",
            "    clint ID : 48 training complete.\n",
            "        accuracy : 1.0 - loss : 0.0014655397972092032\n",
            "    clint ID : 1 training complete.\n",
            "        accuracy : 1.0 - loss : 7.223642751341686e-05\n",
            "    clint ID : 94 training complete.\n",
            "        accuracy : 1.0 - loss : 4.516764238360338e-05\n",
            "    clint ID : 95 training complete.\n",
            "        accuracy : 1.0 - loss : 4.1323892219224945e-05\n",
            "    clint ID : 80 training complete.\n",
            "        accuracy : 1.0 - loss : 3.2616557291476056e-05\n",
            "    clint ID : 99 training complete.\n",
            "        accuracy : 1.0 - loss : 2.1449126506922767e-05\n",
            "  evaluation mean : accuracy - 1.0, loss - 0.0001753148389980197\n",
            "\n",
            "▶ Round 16 ◀\n",
            "selected clients : [ 4 69 30 79 48  1 94 95 80 99]\n",
            "    clint ID : 4 training complete.\n",
            "        accuracy : 1.0 - loss : 2.0364263036753982e-05\n",
            "    clint ID : 69 training complete.\n",
            "        accuracy : 1.0 - loss : 0.004507353529334068\n",
            "    clint ID : 30 training complete.\n",
            "        accuracy : 1.0 - loss : 3.5983983252663165e-05\n",
            "    clint ID : 79 training complete.\n",
            "        accuracy : 1.0 - loss : 3.235967960790731e-05\n",
            "    clint ID : 48 training complete.\n",
            "        accuracy : 1.0 - loss : 2.7362495529814623e-05\n",
            "    clint ID : 1 training complete.\n",
            "        accuracy : 0.9800000190734863 - loss : 0.06198017671704292\n",
            "    clint ID : 94 training complete.\n",
            "        accuracy : 0.9983333349227905 - loss : 0.006418634206056595\n",
            "    clint ID : 95 training complete.\n",
            "        accuracy : 1.0 - loss : 0.001646704156883061\n",
            "    clint ID : 80 training complete.\n",
            "        accuracy : 1.0 - loss : 5.642885298584588e-05\n",
            "    clint ID : 99 training complete.\n",
            "        accuracy : 1.0 - loss : 4.008357063867152e-05\n",
            "  evaluation mean : accuracy - 0.9978333711624146, loss - 0.007476544938981533\n",
            "\n",
            "▶ Round 17 ◀\n",
            "selected clients : [ 4 69 30 79 48  1 94 95 80 99]\n",
            "    clint ID : 4 training complete.\n",
            "        accuracy : 1.0 - loss : 4.306796472519636e-05\n",
            "    clint ID : 69 training complete.\n",
            "        accuracy : 1.0 - loss : 3.284147896920331e-05\n",
            "    clint ID : 30 training complete.\n",
            "        accuracy : 1.0 - loss : 2.7228683393332176e-05\n",
            "    clint ID : 79 training complete.\n",
            "        accuracy : 1.0 - loss : 3.223343810532242e-05\n",
            "    clint ID : 48 training complete.\n",
            "        accuracy : 1.0 - loss : 2.3884360416559502e-05\n",
            "    clint ID : 1 training complete.\n",
            "        accuracy : 0.9850000143051147 - loss : 0.07559657096862793\n",
            "    clint ID : 94 training complete.\n",
            "        accuracy : 0.9900000095367432 - loss : 0.03406630828976631\n",
            "    clint ID : 95 training complete.\n",
            "        accuracy : 1.0 - loss : 0.0001130459422711283\n",
            "    clint ID : 80 training complete.\n",
            "        accuracy : 1.0 - loss : 5.519611295312643e-05\n",
            "    clint ID : 99 training complete.\n",
            "        accuracy : 1.0 - loss : 4.592283585225232e-05\n",
            "  evaluation mean : accuracy - 0.9975000619888306, loss - 0.011003630235791206\n",
            "\n",
            "▶ Round 18 ◀\n",
            "selected clients : [ 4 69 30 79 48  1 94 95 80 99]\n",
            "    clint ID : 4 training complete.\n",
            "        accuracy : 1.0 - loss : 4.4333923142403364e-05\n",
            "    clint ID : 69 training complete.\n",
            "        accuracy : 1.0 - loss : 3.482083775452338e-05\n",
            "    clint ID : 30 training complete.\n",
            "        accuracy : 1.0 - loss : 3.092538099735975e-05\n",
            "    clint ID : 79 training complete.\n",
            "        accuracy : 1.0 - loss : 2.6600624551065266e-05\n",
            "    clint ID : 48 training complete.\n",
            "        accuracy : 1.0 - loss : 1.821571095206309e-05\n",
            "    clint ID : 1 training complete.\n",
            "        accuracy : 0.9983333349227905 - loss : 0.008750688284635544\n",
            "    clint ID : 94 training complete.\n",
            "        accuracy : 1.0 - loss : 3.666847260319628e-05\n",
            "    clint ID : 95 training complete.\n",
            "        accuracy : 1.0 - loss : 3.036325506400317e-05\n",
            "    clint ID : 80 training complete.\n",
            "        accuracy : 1.0 - loss : 2.1547290089074522e-05\n",
            "    clint ID : 99 training complete.\n",
            "        accuracy : 1.0 - loss : 1.545186387374997e-05\n",
            "  evaluation mean : accuracy - 0.9998332858085632, loss - 0.0009009615750983357\n",
            "\n",
            "▶ Round 19 ◀\n",
            "selected clients : [ 4 69 30 79 48  1 94 95 80 99]\n",
            "    clint ID : 4 training complete.\n",
            "        accuracy : 0.9950000047683716 - loss : 0.007766363676637411\n",
            "    clint ID : 69 training complete.\n",
            "        accuracy : 1.0 - loss : 2.046056579274591e-05\n",
            "    clint ID : 30 training complete.\n",
            "        accuracy : 1.0 - loss : 2.853787191270385e-05\n",
            "    clint ID : 79 training complete.\n",
            "        accuracy : 1.0 - loss : 2.4875345843611285e-05\n",
            "    clint ID : 48 training complete.\n",
            "        accuracy : 1.0 - loss : 2.3312921257456765e-05\n",
            "    clint ID : 1 training complete.\n",
            "        accuracy : 1.0 - loss : 1.313888787990436e-05\n",
            "    clint ID : 94 training complete.\n",
            "        accuracy : 1.0 - loss : 1.7365448002237827e-05\n",
            "    clint ID : 95 training complete.\n",
            "        accuracy : 1.0 - loss : 1.3171358659747057e-05\n",
            "    clint ID : 80 training complete.\n",
            "        accuracy : 1.0 - loss : 1.0673660653992556e-05\n",
            "    clint ID : 99 training complete.\n",
            "        accuracy : 1.0 - loss : 6.178434887260664e-06\n",
            "  evaluation mean : accuracy - 0.9994999766349792, loss - 0.0007924077799543738\n",
            "\n",
            "▶ Round 20 ◀\n",
            "selected clients : [ 4 69 30 79 48  1 94 95 80 99]\n",
            "    clint ID : 4 training complete.\n",
            "        accuracy : 1.0 - loss : 6.993857823545113e-06\n",
            "    clint ID : 69 training complete.\n",
            "        accuracy : 1.0 - loss : 1.616652525626705e-06\n",
            "    clint ID : 30 training complete.\n",
            "        accuracy : 1.0 - loss : 4.921123945678119e-06\n",
            "    clint ID : 79 training complete.\n",
            "        accuracy : 0.9816666841506958 - loss : 0.05595095455646515\n",
            "    clint ID : 48 training complete.\n",
            "        accuracy : 1.0 - loss : 5.822598723170813e-06\n",
            "    clint ID : 1 training complete.\n",
            "        accuracy : 1.0 - loss : 1.3459421097650193e-05\n",
            "    clint ID : 94 training complete.\n",
            "        accuracy : 1.0 - loss : 2.1001565983169712e-05\n",
            "    clint ID : 95 training complete.\n",
            "        accuracy : 1.0 - loss : 1.6437659724033438e-05\n",
            "    clint ID : 80 training complete.\n",
            "        accuracy : 1.0 - loss : 1.6660584151395597e-05\n",
            "    clint ID : 99 training complete.\n",
            "        accuracy : 1.0 - loss : 1.2985220564587507e-05\n",
            "  evaluation mean : accuracy - 0.9981666803359985, loss - 0.005605085287243128\n",
            "\n",
            "▶ Round 21 ◀\n",
            "selected clients : [ 4 69 30 79 48  1 94 95 80 99]\n",
            "    clint ID : 4 training complete.\n",
            "        accuracy : 1.0 - loss : 1.1395299225114286e-05\n",
            "    clint ID : 69 training complete.\n",
            "        accuracy : 1.0 - loss : 3.531758011376951e-06\n",
            "    clint ID : 30 training complete.\n",
            "        accuracy : 1.0 - loss : 1.0871965969272424e-05\n",
            "    clint ID : 79 training complete.\n",
            "        accuracy : 1.0 - loss : 8.213945875468198e-06\n",
            "    clint ID : 48 training complete.\n",
            "        accuracy : 1.0 - loss : 6.503003078250913e-06\n",
            "    clint ID : 1 training complete.\n",
            "        accuracy : 1.0 - loss : 2.9809027637384133e-06\n",
            "    clint ID : 94 training complete.\n",
            "        accuracy : 0.9983333349227905 - loss : 0.013846348039805889\n",
            "    clint ID : 95 training complete.\n",
            "        accuracy : 1.0 - loss : 2.1186526282690465e-05\n",
            "    clint ID : 80 training complete.\n",
            "        accuracy : 1.0 - loss : 1.9528748453012668e-05\n",
            "    clint ID : 99 training complete.\n",
            "        accuracy : 1.0 - loss : 1.3559111721406225e-05\n",
            "  evaluation mean : accuracy - 0.9998332858085632, loss - 0.0013944118982180953\n",
            "\n",
            "▶ Round 22 ◀\n",
            "selected clients : [ 4 69 30 79 48  1 94 95 80 99]\n",
            "    clint ID : 4 training complete.\n",
            "        accuracy : 1.0 - loss : 1.387260726914974e-05\n",
            "    clint ID : 69 training complete.\n",
            "        accuracy : 1.0 - loss : 3.3093442652898375e-06\n",
            "    clint ID : 30 training complete.\n",
            "        accuracy : 1.0 - loss : 1.3238275641924702e-05\n",
            "    clint ID : 79 training complete.\n",
            "        accuracy : 1.0 - loss : 1.0578992259979714e-05\n",
            "    clint ID : 48 training complete.\n",
            "        accuracy : 1.0 - loss : 6.854197181382915e-06\n",
            "    clint ID : 1 training complete.\n",
            "        accuracy : 1.0 - loss : 6.167394076328492e-06\n",
            "    clint ID : 94 training complete.\n",
            "        accuracy : 1.0 - loss : 8.65393303683959e-06\n",
            "    clint ID : 95 training complete.\n",
            "        accuracy : 1.0 - loss : 4.858141437580343e-06\n",
            "    clint ID : 80 training complete.\n",
            "        accuracy : 1.0 - loss : 4.178948984190356e-06\n",
            "    clint ID : 99 training complete.\n",
            "        accuracy : 0.9933333396911621 - loss : 0.0172510277479887\n",
            "  evaluation mean : accuracy - 0.999333381652832, loss - 0.0017322739586234093\n",
            "\n",
            "▶ Round 23 ◀\n",
            "selected clients : [ 4 69 30 79 48  1 94 95 80 99]\n",
            "    clint ID : 4 training complete.\n",
            "        accuracy : 1.0 - loss : 1.4232378816814162e-05\n",
            "    clint ID : 69 training complete.\n",
            "        accuracy : 1.0 - loss : 5.533340754482197e-06\n",
            "    clint ID : 30 training complete.\n",
            "        accuracy : 1.0 - loss : 1.292972683586413e-05\n",
            "    clint ID : 79 training complete.\n",
            "        accuracy : 1.0 - loss : 1.0806833415699657e-05\n",
            "    clint ID : 48 training complete.\n",
            "        accuracy : 1.0 - loss : 9.47034186538076e-06\n",
            "    clint ID : 1 training complete.\n",
            "        accuracy : 1.0 - loss : 6.748248324583983e-06\n",
            "    clint ID : 94 training complete.\n",
            "        accuracy : 1.0 - loss : 1.1136290595459286e-05\n",
            "    clint ID : 95 training complete.\n",
            "        accuracy : 1.0 - loss : 7.127058324840618e-06\n",
            "    clint ID : 80 training complete.\n",
            "        accuracy : 1.0 - loss : 6.243050847842824e-06\n",
            "    clint ID : 99 training complete.\n",
            "        accuracy : 1.0 - loss : 5.714359758712817e-06\n",
            "  evaluation mean : accuracy - 1.0, loss - 8.994163181341719e-06\n",
            "\n",
            "▶ Round 24 ◀\n",
            "selected clients : [ 4 69 30 79 48  1 94 95 80 99]\n",
            "    clint ID : 4 training complete.\n",
            "        accuracy : 1.0 - loss : 3.5989498883282067e-06\n",
            "    clint ID : 69 training complete.\n",
            "        accuracy : 1.0 - loss : 0.0004440261982381344\n",
            "    clint ID : 30 training complete.\n",
            "        accuracy : 1.0 - loss : 1.2788907952199224e-05\n",
            "    clint ID : 79 training complete.\n",
            "        accuracy : 1.0 - loss : 9.1530264398898e-06\n",
            "    clint ID : 48 training complete.\n",
            "        accuracy : 1.0 - loss : 1.0375770216342062e-05\n",
            "    clint ID : 1 training complete.\n",
            "        accuracy : 1.0 - loss : 6.046620455890661e-06\n",
            "    clint ID : 94 training complete.\n",
            "        accuracy : 1.0 - loss : 8.215638445108198e-06\n",
            "    clint ID : 95 training complete.\n",
            "        accuracy : 1.0 - loss : 6.466157174145337e-06\n",
            "    clint ID : 80 training complete.\n",
            "        accuracy : 1.0 - loss : 6.957241112104384e-06\n",
            "    clint ID : 99 training complete.\n",
            "        accuracy : 1.0 - loss : 5.173606496100547e-06\n",
            "  evaluation mean : accuracy - 1.0, loss - 5.1280210755066946e-05\n",
            "\n",
            "▶ Round 25 ◀\n",
            "selected clients : [ 4 69 30 79 48  1 94 95 80 99]\n",
            "    clint ID : 4 training complete.\n",
            "        accuracy : 1.0 - loss : 5.178932497074129e-06\n",
            "    clint ID : 69 training complete.\n",
            "        accuracy : 1.0 - loss : 4.674964202422416e-06\n",
            "    clint ID : 30 training complete.\n",
            "        accuracy : 1.0 - loss : 4.139772499911487e-06\n",
            "    clint ID : 79 training complete.\n",
            "        accuracy : 1.0 - loss : 3.0097339731582906e-06\n",
            "    clint ID : 48 training complete.\n",
            "        accuracy : 1.0 - loss : 1.95713437278755e-06\n",
            "    clint ID : 1 training complete.\n",
            "        accuracy : 0.9900000095367432 - loss : 0.02372327260673046\n",
            "    clint ID : 94 training complete.\n",
            "        accuracy : 1.0 - loss : 2.112568290613126e-05\n",
            "    clint ID : 95 training complete.\n",
            "        accuracy : 1.0 - loss : 1.4930361430742778e-05\n",
            "    clint ID : 80 training complete.\n",
            "        accuracy : 1.0 - loss : 1.8246784748043865e-05\n",
            "    clint ID : 99 training complete.\n",
            "        accuracy : 1.0 - loss : 1.0260988346999511e-05\n",
            "  evaluation mean : accuracy - 0.9989999532699585, loss - 0.002380679827183485\n",
            "\n",
            "▶ Round 26 ◀\n",
            "selected clients : [ 4 69 30 79 48  1 94 95 80 99]\n",
            "    clint ID : 4 training complete.\n",
            "        accuracy : 1.0 - loss : 1.2297557077545207e-05\n",
            "    clint ID : 69 training complete.\n",
            "        accuracy : 1.0 - loss : 9.415920430910774e-06\n",
            "    clint ID : 30 training complete.\n",
            "        accuracy : 1.0 - loss : 1.1929358151974156e-05\n",
            "    clint ID : 79 training complete.\n",
            "        accuracy : 1.0 - loss : 8.8334845713689e-06\n",
            "    clint ID : 48 training complete.\n",
            "        accuracy : 1.0 - loss : 8.248816811828874e-06\n",
            "    clint ID : 1 training complete.\n",
            "        accuracy : 1.0 - loss : 6.041578672011383e-06\n",
            "    clint ID : 94 training complete.\n",
            "        accuracy : 1.0 - loss : 7.68769041314954e-06\n",
            "    clint ID : 95 training complete.\n",
            "        accuracy : 1.0 - loss : 4.109007022634614e-06\n",
            "    clint ID : 80 training complete.\n",
            "        accuracy : 1.0 - loss : 4.292564881325234e-06\n",
            "    clint ID : 99 training complete.\n",
            "        accuracy : 1.0 - loss : 2.6292470920452615e-06\n",
            "  evaluation mean : accuracy - 1.0, loss - 7.548523171863053e-06\n",
            "\n",
            "▶ Round 27 ◀\n",
            "selected clients : [ 4 69 30 79 48  1 94 95 80 99]\n",
            "    clint ID : 4 training complete.\n",
            "        accuracy : 1.0 - loss : 2.7730970941775013e-06\n",
            "    clint ID : 69 training complete.\n",
            "        accuracy : 1.0 - loss : 2.3870966288086493e-06\n",
            "    clint ID : 30 training complete.\n",
            "        accuracy : 1.0 - loss : 2.6286970751243643e-06\n",
            "    clint ID : 79 training complete.\n",
            "        accuracy : 1.0 - loss : 1.9410836102906615e-06\n",
            "    clint ID : 48 training complete.\n",
            "        accuracy : 1.0 - loss : 1.747959004205768e-06\n",
            "    clint ID : 1 training complete.\n",
            "        accuracy : 1.0 - loss : 1.545123723190045e-06\n",
            "    clint ID : 94 training complete.\n",
            "        accuracy : 1.0 - loss : 1.6220197949223802e-06\n",
            "    clint ID : 95 training complete.\n",
            "        accuracy : 0.996666669845581 - loss : 0.004992265719920397\n",
            "    clint ID : 80 training complete.\n",
            "        accuracy : 1.0 - loss : 8.173652531695552e-06\n",
            "    clint ID : 99 training complete.\n",
            "        accuracy : 1.0 - loss : 6.380821560014738e-06\n",
            "  evaluation mean : accuracy - 0.999666690826416, loss - 0.0005021465476602316\n",
            "\n",
            "▶ Round 28 ◀\n",
            "selected clients : [ 4 69 30 79 48  1 94 95 80 99]\n",
            "    clint ID : 4 training complete.\n",
            "        accuracy : 1.0 - loss : 8.452024303551298e-06\n",
            "    clint ID : 69 training complete.\n",
            "        accuracy : 1.0 - loss : 5.736175353376893e-06\n",
            "    clint ID : 30 training complete.\n",
            "        accuracy : 1.0 - loss : 7.994071893335786e-06\n",
            "    clint ID : 79 training complete.\n",
            "        accuracy : 1.0 - loss : 6.419691089831758e-06\n",
            "    clint ID : 48 training complete.\n",
            "        accuracy : 1.0 - loss : 5.3284734349290375e-06\n",
            "    clint ID : 1 training complete.\n",
            "        accuracy : 1.0 - loss : 3.7102095120644663e-06\n",
            "    clint ID : 94 training complete.\n",
            "        accuracy : 1.0 - loss : 5.691530532203615e-06\n",
            "    clint ID : 95 training complete.\n",
            "        accuracy : 1.0 - loss : 4.373600404505851e-06\n",
            "    clint ID : 80 training complete.\n",
            "        accuracy : 1.0 - loss : 3.6433223158383043e-06\n",
            "    clint ID : 99 training complete.\n",
            "        accuracy : 1.0 - loss : 2.9086256745358696e-06\n",
            "  evaluation mean : accuracy - 1.0, loss - 5.425772542366758e-06\n",
            "\n",
            "▶ Round 29 ◀\n",
            "selected clients : [ 4 69 30 79 48  1 94 95 80 99]\n",
            "    clint ID : 4 training complete.\n",
            "        accuracy : 1.0 - loss : 2.187203790526837e-06\n",
            "    clint ID : 69 training complete.\n",
            "        accuracy : 1.0 - loss : 1.5969812920957338e-06\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0OCf1CfRAIvE"
      },
      "source": [
        "# 1 client run test "
      ],
      "id": "0OCf1CfRAIvE"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dwJiy0iFAH72",
        "outputId": "ab12a12a-a256-4caf-fa57-abbed63717eb"
      },
      "source": [
        "TOTAL_CLIENTS = len(federated_train_data)\r\n",
        "SELECTED_CLIENTS = int(TOTAL_CLIENTS*FRACTION)\r\n",
        "selected_clients_list = np.random.choice(TOTAL_CLIENTS, size=SELECTED_CLIENTS, replace=False)\r\n",
        "global_parameter=keras_model.get_weights()\r\n",
        "\r\n",
        "#for client_dataset in selected_clients_list :\r\n",
        "train_images, train_labels=federated_train_data[1] #[client_dataset]\r\n",
        "\r\n",
        "keras_model.set_weights(global_parameter)\r\n",
        "\r\n",
        "train_result=keras_model.fit(train_images, train_labels, batch_size=BATCH_SIZE, epochs=NUM_EPOCHS, verbose=0)\r\n",
        "    \r\n",
        "local_parameter=keras_model.get_weights()\r\n",
        "print(local_parameter)"
      ],
      "id": "dwJiy0iFAH72",
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[array([[[[-2.74886359e-02,  3.53783257e-02, -4.06581573e-02,\n",
            "           7.62905106e-02,  9.81244892e-02,  5.93651757e-02,\n",
            "          -5.18175475e-02,  6.14474714e-02,  5.01662642e-02,\n",
            "          -3.48413065e-02,  7.50780944e-03,  2.70709489e-02,\n",
            "          -7.37376735e-02, -4.36170772e-02,  5.65690845e-02,\n",
            "           4.62972596e-02,  7.57771283e-02,  2.92156022e-02,\n",
            "           2.64296518e-03, -9.09788236e-02,  3.34205925e-02,\n",
            "          -8.82435888e-02,  1.68853812e-02, -4.34263833e-02,\n",
            "          -4.80180942e-02, -6.04289286e-02,  2.37708203e-02,\n",
            "           5.55101819e-02, -1.50298914e-02, -2.56965887e-02,\n",
            "           8.70327577e-02,  3.97624522e-02]],\n",
            "\n",
            "        [[ 1.14530675e-01, -9.90856141e-02,  1.45752085e-02,\n",
            "           1.26859307e-01,  2.86120418e-02,  9.67995524e-02,\n",
            "          -5.80959814e-03,  8.95505548e-02,  3.60283665e-02,\n",
            "           6.03249930e-02,  1.17196187e-01,  1.01696268e-01,\n",
            "          -2.33961586e-02, -3.65482457e-02,  6.18888158e-03,\n",
            "          -9.23059434e-02,  3.43362838e-02, -1.97398458e-02,\n",
            "           9.38334763e-02, -2.36547161e-02, -6.60194010e-02,\n",
            "          -4.18252423e-02, -2.76484503e-03, -8.13864321e-02,\n",
            "          -7.02907443e-02,  2.93355491e-02, -5.22869825e-02,\n",
            "          -4.21532393e-02,  5.55572100e-03, -4.90523130e-02,\n",
            "           1.31661575e-02, -4.99555692e-02]],\n",
            "\n",
            "        [[-6.52045831e-02, -9.23212431e-03, -2.68692765e-02,\n",
            "          -4.80461754e-02,  7.77572989e-02,  7.21030235e-02,\n",
            "          -2.82437988e-02, -2.69981660e-02,  9.32975486e-02,\n",
            "           1.58290099e-02,  1.06679715e-01,  9.99538973e-02,\n",
            "          -6.41218424e-02,  3.35398479e-03,  8.97190347e-02,\n",
            "          -1.24423224e-02,  1.06632277e-01, -4.92624007e-02,\n",
            "           4.67031598e-02,  5.52295968e-02, -3.47773544e-02,\n",
            "           1.67738814e-02, -1.63726471e-02, -3.76538709e-02,\n",
            "           3.07874195e-02,  2.27678176e-02,  2.15899553e-02,\n",
            "           4.35673781e-02,  8.17223266e-02,  4.04090025e-02,\n",
            "           2.28664023e-03,  4.88962345e-02]],\n",
            "\n",
            "        [[ 6.67550564e-02, -6.58364445e-02, -4.83807586e-02,\n",
            "          -9.29613039e-02, -1.59080233e-02, -5.36175258e-02,\n",
            "          -6.92094415e-02, -2.63345707e-02, -3.59339006e-02,\n",
            "           1.08296033e-02,  7.94063732e-02,  4.04980443e-02,\n",
            "           1.12085693e-01, -5.33913411e-02, -4.41909535e-03,\n",
            "          -9.29665044e-02,  5.23919659e-03,  3.69935040e-03,\n",
            "          -6.63330108e-02,  6.80703018e-03,  9.01748165e-02,\n",
            "           4.01360579e-02, -9.74424407e-02,  2.57078167e-02,\n",
            "          -3.04006375e-02,  7.18254298e-02, -6.20956086e-02,\n",
            "           5.96544892e-02,  8.00157711e-02, -6.05310164e-02,\n",
            "          -8.81570354e-02,  1.71603390e-03]],\n",
            "\n",
            "        [[-6.73122630e-02,  4.68570460e-03,  4.45960313e-02,\n",
            "          -7.58710923e-03,  4.14595306e-02,  1.67760730e-03,\n",
            "          -4.92358990e-02, -1.14329293e-01, -5.70499636e-02,\n",
            "           1.41786322e-01,  3.66896838e-02,  1.11326367e-01,\n",
            "           1.47731453e-02, -6.49736598e-02,  5.94282858e-02,\n",
            "          -6.24929518e-02,  4.69518527e-02, -4.32680547e-02,\n",
            "          -1.04371697e-01, -3.05511281e-02,  2.51782220e-02,\n",
            "          -2.77523068e-03, -4.12084125e-02, -3.63030881e-02,\n",
            "          -1.40585611e-02,  2.33699717e-02,  6.50185868e-02,\n",
            "          -1.15306132e-01,  8.82762149e-02,  6.74040467e-02,\n",
            "          -1.03390768e-01,  1.03687651e-01]]],\n",
            "\n",
            "\n",
            "       [[[ 2.36213598e-02,  3.21499482e-02, -1.12323686e-01,\n",
            "           1.75570119e-02,  5.04634641e-02, -8.20684880e-02,\n",
            "          -2.18334561e-03,  1.52775012e-02,  2.91424375e-02,\n",
            "          -1.08147347e-02,  4.71446440e-02,  9.79183242e-02,\n",
            "          -6.91192895e-02,  3.54159139e-02, -3.04372590e-02,\n",
            "           5.44536449e-02,  2.92927753e-02,  3.17122489e-02,\n",
            "           5.12360260e-02, -8.03409964e-02, -3.85001604e-03,\n",
            "          -4.89421636e-02, -8.64742771e-02, -1.13152094e-01,\n",
            "           7.05132484e-02, -2.62173843e-02,  8.39146506e-03,\n",
            "          -1.14492408e-03,  3.46085690e-02, -4.49376069e-02,\n",
            "           8.96311626e-02, -3.57788838e-02]],\n",
            "\n",
            "        [[ 1.81755647e-02, -2.01339424e-02,  5.67666404e-02,\n",
            "          -4.42927354e-04,  5.41402400e-02,  6.14699684e-02,\n",
            "          -5.27194655e-03,  8.05878192e-02,  5.00583537e-02,\n",
            "          -3.34669277e-02,  9.02210250e-02,  5.03523499e-02,\n",
            "           6.48053065e-02, -1.23320594e-01, -2.57465132e-02,\n",
            "          -5.80152832e-02,  7.95614943e-02,  1.01498306e-01,\n",
            "           9.25558358e-02,  3.20678465e-02, -4.27392982e-02,\n",
            "           1.09348539e-02, -1.31759271e-01,  3.24652232e-02,\n",
            "          -1.89201590e-02,  1.55432001e-02, -9.62755308e-02,\n",
            "          -5.62013611e-02, -8.95649791e-02, -1.15421854e-01,\n",
            "           3.16061825e-02,  5.88787273e-02]],\n",
            "\n",
            "        [[-1.90210715e-02, -5.44253625e-02,  3.94809954e-02,\n",
            "           3.11566219e-02,  8.31063241e-02,  7.59488996e-03,\n",
            "           6.25471957e-03, -4.98930402e-02, -6.28733216e-03,\n",
            "           1.44423455e-01, -2.70813573e-02,  7.44394511e-02,\n",
            "          -2.17893999e-03, -1.12585008e-01, -6.56047314e-02,\n",
            "          -2.04943009e-02,  2.27741301e-02,  5.50787635e-02,\n",
            "           5.47722764e-02,  9.23714563e-02, -3.51101570e-02,\n",
            "           4.25896421e-02, -2.39393059e-02,  9.18950662e-02,\n",
            "          -2.76171286e-02,  2.24345475e-02,  3.97345461e-02,\n",
            "           5.09405769e-02, -3.85204777e-02,  6.30079350e-03,\n",
            "           7.81508982e-02,  8.17570612e-02]],\n",
            "\n",
            "        [[-3.10694277e-02, -3.23121585e-02, -1.85850505e-02,\n",
            "          -9.86551419e-02,  5.19741476e-02,  3.63806412e-02,\n",
            "           6.21852167e-02, -9.49389860e-02, -3.17733586e-02,\n",
            "           1.13248631e-01, -1.60143506e-02,  1.16581395e-01,\n",
            "           1.00086078e-01, -1.37640700e-01,  4.79807928e-02,\n",
            "          -9.26134586e-02,  1.16700552e-01, -8.37695599e-02,\n",
            "          -1.13929875e-01,  5.36014289e-02,  8.82899240e-02,\n",
            "           1.15230523e-01, -1.01329304e-01,  8.50888118e-02,\n",
            "           3.56265865e-02, -2.31311675e-02, -4.83665988e-02,\n",
            "          -6.41768575e-02,  1.83225255e-02,  2.84290519e-02,\n",
            "          -3.11760101e-02,  8.54264721e-02]],\n",
            "\n",
            "        [[-7.16506019e-02, -1.70229468e-02, -7.87892863e-02,\n",
            "          -1.07734010e-01,  2.83042192e-02,  1.24970693e-02,\n",
            "           6.27361313e-02,  4.52553295e-03, -8.59306157e-02,\n",
            "           1.58050153e-02, -3.65603529e-02, -5.75553924e-02,\n",
            "           9.79688168e-02,  2.70579979e-02,  4.82946038e-02,\n",
            "           2.97103524e-02,  9.22218636e-02, -7.90463015e-02,\n",
            "          -8.21584016e-02, -7.70449340e-02, -1.38273872e-02,\n",
            "          -4.24669795e-02, -2.22003506e-03, -7.99174607e-02,\n",
            "           2.57950537e-02, -2.04568151e-02,  1.90571416e-02,\n",
            "          -8.46584067e-02,  8.14599544e-02,  8.35434273e-02,\n",
            "          -2.85726599e-02,  1.84977986e-02]]],\n",
            "\n",
            "\n",
            "       [[[ 1.17307946e-01, -1.34983454e-02, -3.78624573e-02,\n",
            "           9.11459103e-02, -8.25775415e-02, -7.78301954e-02,\n",
            "          -3.39780049e-03,  1.27818398e-02, -1.48331793e-02,\n",
            "           6.94541857e-02, -8.32320526e-02,  7.48720616e-02,\n",
            "          -4.38125862e-04,  9.64834820e-03, -9.13197547e-02,\n",
            "           6.11003153e-02,  9.87788960e-02,  8.94754976e-02,\n",
            "          -4.33945246e-02, -2.82617193e-02, -5.59417112e-03,\n",
            "          -2.22219191e-02, -2.46989466e-02, -1.02120399e-01,\n",
            "           4.94649038e-02,  6.82972744e-02,  3.50966565e-02,\n",
            "           3.01935468e-02,  3.81901860e-02,  3.20075313e-03,\n",
            "          -2.06346493e-02,  1.88215114e-02]],\n",
            "\n",
            "        [[ 3.53384130e-02, -8.20512474e-02, -6.29143417e-02,\n",
            "           5.32808751e-02, -4.61678617e-02, -8.85233060e-02,\n",
            "          -4.60855030e-02,  8.52283612e-02,  7.44008049e-02,\n",
            "           6.88427091e-02, -8.93298760e-02, -6.47021160e-02,\n",
            "          -1.57114659e-02, -4.93990667e-02, -5.36020771e-02,\n",
            "           3.74147333e-02,  1.29720252e-02,  3.71027291e-02,\n",
            "           2.11754628e-02, -5.83323687e-02,  5.72901517e-02,\n",
            "          -2.09834222e-02, -9.13129043e-05, -5.20060137e-02,\n",
            "           2.14190148e-02,  2.67128479e-02,  6.43603429e-02,\n",
            "          -6.02760259e-03, -5.61496615e-02, -5.50113842e-02,\n",
            "          -7.93166086e-03, -4.39607538e-02]],\n",
            "\n",
            "        [[-7.48292878e-02, -4.65175025e-02,  3.72142680e-02,\n",
            "           6.73813047e-03,  4.13531996e-02, -3.01961554e-04,\n",
            "          -8.27958882e-02,  5.89654408e-02,  1.12220496e-01,\n",
            "          -5.07952236e-02,  2.44997954e-03, -5.16756554e-04,\n",
            "           8.83474872e-02, -5.68806976e-02,  6.05722778e-02,\n",
            "           9.71660465e-02,  4.15909365e-02,  5.30044511e-02,\n",
            "           9.04844254e-02,  2.95023825e-02,  4.72567119e-02,\n",
            "           4.69662771e-02, -9.88173038e-02,  5.27170971e-02,\n",
            "           7.90617093e-02,  9.45187286e-02, -5.81549713e-03,\n",
            "           8.27274844e-02, -2.90086903e-02,  6.66917348e-03,\n",
            "           2.57127956e-02, -3.24231312e-02]],\n",
            "\n",
            "        [[-9.66033861e-02, -4.82075140e-02,  9.76091400e-02,\n",
            "          -8.79839212e-02, -1.85451079e-02,  9.91809219e-02,\n",
            "           7.57813230e-02, -4.56836857e-02,  3.49296741e-02,\n",
            "           3.97200733e-02, -1.18399020e-02, -4.05300455e-03,\n",
            "           1.06384486e-01,  3.85071822e-02, -5.53211868e-02,\n",
            "          -2.33681742e-02,  6.81728497e-02,  6.09994493e-02,\n",
            "          -9.63003337e-02, -3.08761895e-02,  1.06728658e-01,\n",
            "           1.19974777e-01, -2.55037984e-03, -6.06896579e-02,\n",
            "           1.13105588e-01,  9.81166884e-02,  2.50940733e-02,\n",
            "           9.09501761e-02,  9.88196060e-02, -4.18055728e-02,\n",
            "          -3.64540033e-02,  2.02070121e-02]],\n",
            "\n",
            "        [[ 3.96821694e-03, -5.63407950e-02,  7.59730637e-02,\n",
            "          -7.56918862e-02,  1.43515766e-02,  9.40279588e-02,\n",
            "          -6.74842745e-02, -8.92215446e-02, -6.70169219e-02,\n",
            "           7.74108618e-02,  8.42543542e-02,  4.13930751e-02,\n",
            "          -1.96570181e-03, -4.22057100e-02, -9.80657563e-02,\n",
            "          -2.04593185e-02,  4.40391973e-02, -5.58229275e-02,\n",
            "          -1.28069162e-01, -4.33701314e-02,  1.45293465e-02,\n",
            "           6.30230829e-02,  1.26720712e-01,  5.88022172e-02,\n",
            "           1.10559002e-01, -8.85565728e-02,  8.54072273e-02,\n",
            "          -7.84287155e-02,  3.01777776e-02, -3.81173305e-02,\n",
            "          -8.58530775e-02, -5.30441441e-02]]],\n",
            "\n",
            "\n",
            "       [[[ 1.19737312e-01,  1.09302387e-01,  1.35134561e-02,\n",
            "          -3.66913192e-02, -8.07756111e-02, -2.26274151e-02,\n",
            "          -1.23484395e-02,  7.69880936e-02, -6.97159842e-02,\n",
            "          -4.06879671e-02, -3.97319160e-02, -2.21754052e-02,\n",
            "          -2.16941303e-03,  3.33262905e-02,  6.20773137e-02,\n",
            "           1.03094123e-01, -1.03807256e-01,  7.40354285e-02,\n",
            "           5.35034463e-02, -2.22657435e-03, -9.67895519e-03,\n",
            "          -5.69781242e-03, -6.63834289e-02,  4.62353230e-02,\n",
            "           4.17243131e-02, -6.34350553e-02, -1.64651107e-02,\n",
            "           9.91015509e-02, -2.73214895e-02, -6.80040568e-02,\n",
            "           7.09224716e-02, -3.41901816e-02]],\n",
            "\n",
            "        [[-2.01095417e-02,  7.62421116e-02,  4.22878796e-03,\n",
            "           4.89724614e-02,  2.09215619e-02, -1.02564499e-01,\n",
            "           8.84237438e-02,  1.60866324e-02,  2.13887319e-02,\n",
            "          -9.23199877e-02, -9.84448865e-02,  7.82293174e-03,\n",
            "          -1.26638021e-02,  1.07603259e-01,  5.81246838e-02,\n",
            "           9.74117890e-02, -6.92990646e-02,  5.58092073e-02,\n",
            "           9.48608592e-02,  9.02575254e-02, -4.67443727e-02,\n",
            "           4.90211621e-02,  7.56676793e-02,  5.35437837e-02,\n",
            "          -1.89103186e-02,  4.44844961e-02,  4.82637808e-02,\n",
            "           9.45529938e-02,  4.98932786e-02, -6.02322519e-02,\n",
            "           9.11571681e-02, -5.98000549e-02]],\n",
            "\n",
            "        [[ 2.45567188e-02,  4.12239991e-02,  4.89981920e-02,\n",
            "           2.88437493e-02, -5.00910878e-02,  4.04141434e-02,\n",
            "           1.17123373e-01,  1.03865929e-01,  4.57994938e-02,\n",
            "          -1.17618077e-01, -9.94890407e-02,  3.00146081e-03,\n",
            "           3.16762924e-02,  1.15248233e-01,  5.53128049e-02,\n",
            "           9.75045711e-02, -9.22735259e-02,  8.76187161e-02,\n",
            "          -3.22281830e-02,  8.93644020e-02,  5.94203509e-02,\n",
            "          -1.76437795e-02, -2.74463054e-02,  5.36547676e-02,\n",
            "           2.58153453e-02,  3.58176418e-02,  6.09934703e-02,\n",
            "           3.93968783e-02,  8.98369029e-03,  4.17757779e-02,\n",
            "           1.06534325e-01, -4.09677103e-02]],\n",
            "\n",
            "        [[-1.01495340e-01,  3.46102864e-02, -1.06723036e-03,\n",
            "          -1.25628650e-01, -1.34609807e-02,  3.83683816e-02,\n",
            "           8.80792961e-02,  2.21179835e-02,  7.41377994e-02,\n",
            "          -9.97405499e-02,  6.94016218e-02, -9.35333073e-02,\n",
            "           8.70036632e-02, -1.57631245e-02,  1.91876143e-02,\n",
            "           1.02900624e-01, -3.98220085e-02,  8.47048871e-03,\n",
            "           2.16816040e-03, -5.44589339e-03, -5.47345951e-02,\n",
            "           6.45936409e-04,  1.33500203e-01, -2.82565821e-02,\n",
            "           2.92621460e-02, -3.97701822e-02, -4.39650007e-02,\n",
            "           8.20931345e-02,  8.26387182e-02,  2.18375362e-02,\n",
            "           7.39902630e-02, -7.68724382e-02]],\n",
            "\n",
            "        [[ 4.75143641e-02, -6.79281279e-02, -5.52596711e-03,\n",
            "          -5.86841106e-02, -1.45330152e-03, -1.63999647e-02,\n",
            "          -2.28295717e-02, -2.34118123e-02,  6.55599087e-02,\n",
            "          -9.40970480e-02,  4.78643887e-02, -6.00896403e-02,\n",
            "          -3.55893634e-02, -1.68880229e-04, -9.42091830e-03,\n",
            "           2.09231377e-02,  7.17864037e-02,  4.15740050e-02,\n",
            "          -1.09392619e-02,  9.42381248e-02, -8.15269798e-02,\n",
            "           3.99967879e-02,  5.91925010e-02, -9.74670425e-03,\n",
            "           1.09048203e-01,  8.63030404e-02,  1.98081806e-02,\n",
            "          -2.25657271e-03,  4.03824858e-02,  6.15972131e-02,\n",
            "           3.28513025e-03, -8.58651102e-02]]],\n",
            "\n",
            "\n",
            "       [[[ 8.93926397e-02,  5.44410199e-02,  1.15030259e-01,\n",
            "           2.82264967e-02, -1.23725884e-01,  6.16704463e-04,\n",
            "           3.03705558e-02,  4.54647914e-02, -7.21603110e-02,\n",
            "          -8.89221728e-02, -1.33914696e-02, -4.89738584e-02,\n",
            "          -7.37904757e-02,  6.88814074e-02, -2.95653529e-02,\n",
            "          -3.17574777e-02, -1.07414974e-02,  6.58397935e-03,\n",
            "           1.60148460e-02, -5.29794693e-02, -3.59971598e-02,\n",
            "           1.34614399e-02,  9.29763615e-02,  1.16602451e-01,\n",
            "          -1.84092522e-02, -7.43661821e-02,  3.09926700e-02,\n",
            "           5.65026440e-02, -1.76912993e-02,  4.71713506e-02,\n",
            "           8.57856721e-02,  2.32680663e-02]],\n",
            "\n",
            "        [[-3.23569104e-02, -1.79188121e-02,  9.18681696e-02,\n",
            "          -8.07742064e-04, -7.84741193e-02, -9.15874392e-02,\n",
            "           7.91077390e-02,  8.86235237e-02,  6.49022590e-03,\n",
            "          -6.62010461e-02, -1.04103751e-01, -4.04703990e-02,\n",
            "           1.55232465e-02, -1.70226879e-02,  4.41038497e-02,\n",
            "          -8.77389014e-02, -1.34287834e-01,  5.77477627e-02,\n",
            "           4.16172855e-02,  1.89335402e-02,  6.49918169e-02,\n",
            "          -6.57314137e-02,  7.56886676e-02,  7.16661438e-02,\n",
            "           4.58318964e-02, -1.01377964e-01, -4.06691320e-02,\n",
            "           7.12035447e-02,  4.77923974e-02,  7.79233500e-02,\n",
            "           7.45533630e-02,  4.29196656e-02]],\n",
            "\n",
            "        [[-1.40544306e-02,  4.36726734e-02,  1.02955014e-01,\n",
            "          -7.03466544e-03, -8.02504085e-03,  3.53031941e-02,\n",
            "          -1.36331348e-02,  5.29884323e-02,  2.04095263e-02,\n",
            "          -1.28278315e-01,  3.23986150e-02, -6.51722327e-02,\n",
            "           6.78254813e-02,  1.18143588e-01, -1.75668672e-02,\n",
            "          -3.56809087e-02, -1.29125297e-01, -2.84677371e-02,\n",
            "           1.04651920e-01,  3.23066972e-02,  2.66788411e-03,\n",
            "           6.41228110e-02,  4.77860384e-02,  6.65144175e-02,\n",
            "           9.41773728e-02, -8.53199661e-02, -7.72240236e-02,\n",
            "          -1.31575251e-02, -7.16285110e-02,  9.41202566e-02,\n",
            "           3.42056267e-02, -1.14146575e-01]],\n",
            "\n",
            "        [[ 1.08665861e-02,  3.55502218e-02,  7.68528208e-02,\n",
            "          -7.84696862e-02, -2.65122484e-02, -3.60864773e-02,\n",
            "           9.38071012e-02,  4.68219407e-02,  2.89372262e-03,\n",
            "          -1.63523071e-02, -5.65222353e-02, -1.33469954e-01,\n",
            "          -1.11010373e-02,  1.56578235e-02,  4.47780788e-02,\n",
            "          -5.26265576e-02, -4.08796743e-02, -1.90815572e-02,\n",
            "           8.67849886e-02,  4.68884856e-02,  7.71380514e-02,\n",
            "           4.89754379e-02,  7.92053193e-02, -1.42509090e-02,\n",
            "           2.16332637e-03,  8.60779062e-02, -2.17825430e-03,\n",
            "           4.77985553e-02,  5.86438067e-02,  7.74041936e-02,\n",
            "          -6.85193315e-02, -5.04558384e-02]],\n",
            "\n",
            "        [[-7.78657496e-02,  1.05400600e-01,  3.02594174e-02,\n",
            "           4.41623107e-02,  3.77072506e-02, -2.84499582e-02,\n",
            "           5.22896387e-02, -5.49598895e-02, -3.84194404e-02,\n",
            "          -8.20160210e-02, -6.20177388e-02,  8.21436930e-04,\n",
            "          -7.18811378e-02,  9.30965021e-02,  9.62253753e-03,\n",
            "          -1.42077459e-02, -9.09799784e-02,  1.19040906e-02,\n",
            "           3.47633776e-03,  2.65448615e-02,  3.64945196e-02,\n",
            "          -8.17373395e-02,  1.98399182e-02,  5.00636697e-02,\n",
            "          -9.52926353e-02, -3.96342315e-02,  6.97231889e-02,\n",
            "           8.29027146e-02, -5.08797206e-02, -4.77310233e-02,\n",
            "          -8.63907859e-02,  3.35304737e-02]]]], dtype=float32), array([-0.00696413, -0.00457561, -0.01622465, -0.0042442 , -0.00126111,\n",
            "        0.00207195,  0.00821279, -0.01989667, -0.01905373,  0.02083008,\n",
            "        0.00793875, -0.00149679, -0.00859656,  0.00568726, -0.02756182,\n",
            "       -0.00714332, -0.00186261, -0.02555557, -0.02145378, -0.01147474,\n",
            "       -0.0356014 , -0.01562525,  0.01765589,  0.00809174, -0.01586685,\n",
            "       -0.00942575, -0.02890308, -0.02295759, -0.02433682, -0.02716105,\n",
            "       -0.01746617, -0.00389621], dtype=float32), array([[[[ 5.34273423e-02,  1.24303792e-02,  6.10449128e-02, ...,\n",
            "          -7.13846274e-03,  1.45043004e-02,  2.80425157e-02],\n",
            "         [-7.56799988e-03, -4.60244305e-02,  4.59482372e-02, ...,\n",
            "          -5.48447222e-02, -3.97431217e-02,  1.79384369e-02],\n",
            "         [-1.66148283e-02, -3.86976898e-02, -1.84726680e-03, ...,\n",
            "          -7.95150921e-03,  4.23052050e-02, -1.14228837e-02],\n",
            "         ...,\n",
            "         [ 4.94621582e-02, -8.76288116e-03,  4.98633347e-02, ...,\n",
            "           3.10308076e-02, -1.31647624e-02,  1.15230531e-02],\n",
            "         [ 1.53617635e-02,  2.79618613e-02,  4.99424264e-02, ...,\n",
            "          -3.19996700e-02,  1.34615991e-02, -2.03338172e-02],\n",
            "         [-1.08616066e-03, -4.16293181e-02, -1.45438826e-02, ...,\n",
            "          -1.07695339e-02, -1.41187022e-02, -2.97136325e-02]],\n",
            "\n",
            "        [[ 3.35075753e-03,  1.35855172e-02,  2.93834172e-02, ...,\n",
            "          -1.97145995e-02, -4.61517163e-02, -4.67219874e-02],\n",
            "         [-3.13177519e-02, -4.05262373e-02, -4.10236754e-02, ...,\n",
            "          -1.60024166e-02,  2.52541676e-02, -1.63227674e-02],\n",
            "         [-4.03853096e-02, -1.33391349e-02, -6.49581924e-02, ...,\n",
            "           3.37763093e-02, -5.37764980e-03, -3.17209214e-02],\n",
            "         ...,\n",
            "         [-5.49312495e-03,  1.77814420e-02, -5.77889048e-02, ...,\n",
            "           3.16332765e-02, -1.81399919e-02,  1.54276807e-02],\n",
            "         [-4.15594541e-02, -2.24804059e-02, -8.09427910e-03, ...,\n",
            "           2.56859977e-02,  1.50083443e-02, -1.89831238e-02],\n",
            "         [-3.55075970e-02, -3.73589508e-02,  3.36941369e-02, ...,\n",
            "           4.76177149e-02,  6.29633293e-02, -1.08333798e-02]],\n",
            "\n",
            "        [[-1.83647852e-02, -6.58622012e-02,  2.56780093e-03, ...,\n",
            "          -3.18050236e-02,  2.06950624e-02,  2.71973144e-02],\n",
            "         [-5.52674383e-02,  2.58198492e-02, -7.51106888e-02, ...,\n",
            "          -1.36857713e-02, -3.29377316e-02,  2.37835408e-03],\n",
            "         [ 4.26619733e-03,  7.32219871e-03, -1.02221500e-02, ...,\n",
            "           1.92184690e-02,  3.98059674e-02, -1.04659172e-02],\n",
            "         ...,\n",
            "         [ 4.78454120e-02,  2.12043021e-02, -4.70619788e-03, ...,\n",
            "          -4.44836020e-02, -1.24699110e-02, -9.22729843e-04],\n",
            "         [-5.19968420e-02, -6.72639608e-02, -7.32375458e-02, ...,\n",
            "           1.46630015e-02,  3.37762199e-02,  2.94339079e-02],\n",
            "         [-1.75616564e-03, -3.96514237e-02,  5.62083237e-02, ...,\n",
            "           5.31737730e-02,  2.76802853e-02,  5.99543331e-03]],\n",
            "\n",
            "        [[-2.68019140e-02, -6.26975391e-03,  5.59625402e-03, ...,\n",
            "          -2.69530322e-02, -2.70081945e-02, -4.47839834e-02],\n",
            "         [-3.34841907e-02, -9.87529871e-04, -1.09571377e-02, ...,\n",
            "           6.39497396e-03,  4.69104052e-02, -4.50088568e-02],\n",
            "         [-1.04541071e-02, -3.76772396e-02,  3.82855386e-02, ...,\n",
            "           7.80640543e-03, -5.08510694e-02,  2.21296325e-02],\n",
            "         ...,\n",
            "         [-3.93438265e-02,  1.15678301e-02, -1.82162113e-02, ...,\n",
            "           9.23978165e-03, -2.78887916e-02, -3.77505459e-02],\n",
            "         [-5.03663383e-02, -1.05861565e-02, -3.14268954e-02, ...,\n",
            "           2.57960912e-02,  1.45342695e-02, -6.27665669e-02],\n",
            "         [-2.35943384e-02, -1.27325989e-02, -5.13708852e-02, ...,\n",
            "          -4.28147353e-02,  5.65838553e-02,  2.74897516e-02]],\n",
            "\n",
            "        [[-2.29595080e-02, -5.29717989e-02,  3.19145732e-02, ...,\n",
            "          -6.14641681e-02,  1.27345342e-02, -4.16171178e-02],\n",
            "         [-1.12867048e-02,  4.77886610e-02,  1.03892172e-02, ...,\n",
            "          -1.03364568e-02,  3.56629677e-02,  2.29920503e-02],\n",
            "         [ 1.69342645e-02,  3.59920301e-02, -3.51435095e-02, ...,\n",
            "           3.64122428e-02, -3.79937887e-02,  1.90849102e-03],\n",
            "         ...,\n",
            "         [ 1.10852625e-02,  5.67684807e-02,  5.20493742e-03, ...,\n",
            "           1.91522576e-02, -4.72884625e-02, -2.87259798e-02],\n",
            "         [ 5.43891601e-02,  4.95816097e-02,  7.00693950e-02, ...,\n",
            "          -5.20620979e-02,  4.33861092e-02, -1.48435701e-02],\n",
            "         [-2.47506835e-02, -4.37644729e-03, -4.40779179e-02, ...,\n",
            "          -4.68075313e-02,  2.20758189e-02, -3.50395441e-02]]],\n",
            "\n",
            "\n",
            "       [[[-3.86279672e-02, -4.50773649e-02,  8.86424109e-02, ...,\n",
            "           2.49939319e-02,  4.68154959e-02, -3.59273255e-02],\n",
            "         [ 4.90967520e-02, -4.58992179e-03,  4.22173664e-02, ...,\n",
            "          -4.40671993e-03, -2.43311320e-02, -3.42690721e-02],\n",
            "         [-4.02465276e-03,  2.51443293e-02,  4.03982177e-02, ...,\n",
            "           4.86669876e-03,  5.17856106e-02,  2.81388536e-02],\n",
            "         ...,\n",
            "         [-4.83375043e-02, -3.67712528e-02, -2.41214409e-02, ...,\n",
            "          -3.72980423e-02,  5.38367592e-02, -1.42749529e-02],\n",
            "         [ 1.12000108e-02,  3.16060893e-02,  6.12197444e-02, ...,\n",
            "          -2.73205061e-02,  3.48122939e-02,  1.44021902e-02],\n",
            "         [ 2.43809726e-02, -2.65884609e-03, -3.68756168e-02, ...,\n",
            "           4.23446596e-02,  2.93656830e-02, -4.45991755e-03]],\n",
            "\n",
            "        [[-1.36638964e-02, -1.37708830e-02,  4.97520342e-02, ...,\n",
            "           1.32259717e-02, -3.00441310e-03,  2.63113566e-02],\n",
            "         [ 1.40138380e-02,  1.41016766e-02, -2.65043806e-02, ...,\n",
            "           4.40766215e-02, -5.00611402e-02, -2.64664758e-02],\n",
            "         [-1.64882001e-02, -5.09475963e-03, -3.85460779e-02, ...,\n",
            "          -5.06448038e-02,  2.83378307e-02,  2.59952415e-02],\n",
            "         ...,\n",
            "         [-3.96585278e-02, -4.85439822e-02, -2.45719720e-02, ...,\n",
            "          -2.39955429e-02, -3.38401571e-02, -2.80215349e-02],\n",
            "         [ 2.94904727e-02,  1.83059908e-02, -4.67878133e-02, ...,\n",
            "           3.96355987e-02,  4.69983742e-02, -3.50283086e-02],\n",
            "         [ 4.16839914e-03,  2.51673646e-02, -2.61791367e-02, ...,\n",
            "          -2.11269949e-02,  1.34255225e-02,  3.99845652e-02]],\n",
            "\n",
            "        [[ 1.76001736e-03,  1.48430411e-02,  1.15032792e-02, ...,\n",
            "          -4.88951430e-03, -1.49121732e-02,  3.20926532e-02],\n",
            "         [ 1.14660589e-02, -3.89406979e-02, -3.62836197e-02, ...,\n",
            "           5.85295958e-03, -2.01643799e-02, -6.78071240e-03],\n",
            "         [-3.15730162e-02,  4.64331508e-02,  2.43887380e-02, ...,\n",
            "          -6.62097335e-02, -2.35107467e-02,  1.52996881e-02],\n",
            "         ...,\n",
            "         [-4.98151034e-02, -1.78115293e-02, -2.92554703e-02, ...,\n",
            "          -6.30690753e-02, -5.32778911e-02,  1.39172806e-03],\n",
            "         [-7.01276585e-02,  1.55869387e-02, -6.28802925e-02, ...,\n",
            "          -4.11360338e-02, -1.60147119e-02, -2.83975084e-03],\n",
            "         [-5.06520644e-02,  2.81588770e-02, -4.21859848e-04, ...,\n",
            "          -4.74717692e-02, -2.74026264e-02, -8.98444653e-03]],\n",
            "\n",
            "        [[ 2.65023224e-02, -5.19275554e-02,  1.80048849e-02, ...,\n",
            "          -5.47755882e-03, -3.10063325e-02, -2.79796179e-02],\n",
            "         [-6.93226978e-02, -6.99947262e-03, -2.01635938e-02, ...,\n",
            "          -3.41203585e-02, -2.00869236e-02, -5.46901301e-02],\n",
            "         [ 3.52393463e-03,  4.14959118e-02,  6.40443712e-02, ...,\n",
            "          -4.14412506e-02, -8.00029468e-03, -3.98940779e-02],\n",
            "         ...,\n",
            "         [-1.79067496e-02, -3.27894203e-02,  1.51342619e-02, ...,\n",
            "           6.72355434e-03, -3.46229412e-02, -5.53093702e-02],\n",
            "         [ 6.84588961e-03,  4.83149104e-02, -1.52977612e-02, ...,\n",
            "           5.24985185e-03, -7.51598971e-03,  2.88025849e-02],\n",
            "         [ 3.44569013e-02, -6.16985857e-02, -2.62668822e-03, ...,\n",
            "          -3.86789776e-02,  2.34283297e-03,  7.71038420e-03]],\n",
            "\n",
            "        [[ 1.25231361e-03, -1.30002601e-02,  9.80705619e-02, ...,\n",
            "           2.02011527e-03,  6.17788546e-02,  2.28848290e-02],\n",
            "         [-3.16967675e-03, -7.67550468e-02,  1.19562298e-02, ...,\n",
            "          -3.58764119e-02, -6.22315332e-04, -5.41620366e-02],\n",
            "         [ 1.37876011e-02,  5.36202081e-02,  5.19344322e-02, ...,\n",
            "           6.05527591e-03, -3.67480256e-02, -2.52914685e-03],\n",
            "         ...,\n",
            "         [ 6.42627254e-02, -5.51921390e-02,  1.42710172e-02, ...,\n",
            "           6.39187768e-02,  3.18756439e-02, -2.65323604e-03],\n",
            "         [ 2.11769040e-03, -1.36034312e-02, -3.26232519e-03, ...,\n",
            "          -3.40617299e-02,  1.65794883e-02, -5.73390648e-02],\n",
            "         [ 1.61826294e-02,  4.86256927e-02, -5.54102436e-02, ...,\n",
            "           3.04351468e-03,  1.10997949e-02, -4.65102270e-02]]],\n",
            "\n",
            "\n",
            "       [[[ 2.27562338e-02,  2.98290271e-02,  6.95485100e-02, ...,\n",
            "          -2.20297761e-02, -9.10243206e-03, -1.89509373e-02],\n",
            "         [ 4.12473977e-02, -4.79389615e-02, -2.97806710e-02, ...,\n",
            "          -1.88648142e-02, -4.56283726e-02,  2.67051682e-02],\n",
            "         [ 4.51533236e-02, -3.10253128e-02, -3.02625075e-03, ...,\n",
            "          -2.81343199e-02, -4.21995968e-02,  5.15348874e-02],\n",
            "         ...,\n",
            "         [ 2.17811167e-02, -7.04583153e-02, -4.69534099e-02, ...,\n",
            "          -1.26312487e-02,  4.08675484e-02, -1.73668086e-04],\n",
            "         [-3.31050646e-03, -4.79506701e-02,  7.47507438e-02, ...,\n",
            "          -3.72174755e-02, -1.04534691e-02,  2.25544423e-02],\n",
            "         [ 3.72785181e-02,  2.09299065e-02, -1.29567031e-02, ...,\n",
            "           4.18362506e-02,  1.50370086e-02, -5.05765714e-03]],\n",
            "\n",
            "        [[ 6.59922557e-03, -5.63469976e-02,  3.05135027e-02, ...,\n",
            "           3.58563997e-02,  3.74480002e-02,  6.58012852e-02],\n",
            "         [ 4.39585745e-02, -6.91002458e-02,  5.08538261e-02, ...,\n",
            "          -3.19223176e-03,  3.69703136e-02, -8.08972958e-03],\n",
            "         [ 2.27457155e-02, -1.10588977e-02, -7.44459331e-02, ...,\n",
            "           8.90238676e-03, -6.47176653e-02,  5.58336978e-05],\n",
            "         ...,\n",
            "         [ 3.69041786e-02, -9.12881456e-03,  3.21690813e-02, ...,\n",
            "           2.90647382e-03, -4.11707945e-02, -6.19286373e-02],\n",
            "         [-6.70014881e-03,  1.50119476e-02, -6.05386421e-02, ...,\n",
            "           1.86222289e-02,  5.97573407e-02,  8.26573186e-03],\n",
            "         [-5.71660371e-03, -1.62586547e-03, -3.21887918e-02, ...,\n",
            "          -6.91129044e-02,  1.10968268e-02,  1.77924223e-02]],\n",
            "\n",
            "        [[ 1.69362836e-02, -5.56510612e-02, -8.97976384e-03, ...,\n",
            "           1.12317540e-02, -2.75586508e-02, -1.77850965e-02],\n",
            "         [ 3.85960825e-02,  1.44641418e-02, -2.95449421e-02, ...,\n",
            "          -3.31467874e-02, -2.07074806e-02, -6.33566901e-02],\n",
            "         [ 3.14024538e-02, -2.19124388e-02, -3.28658856e-02, ...,\n",
            "          -3.81765142e-02, -3.33677419e-02, -5.92330284e-02],\n",
            "         ...,\n",
            "         [ 4.20249477e-02,  2.99093314e-02,  1.47502813e-02, ...,\n",
            "           1.64734554e-02, -3.21969017e-02, -4.96067256e-02],\n",
            "         [ 3.49454698e-03, -4.94685546e-02, -7.29627386e-02, ...,\n",
            "          -6.04027845e-02,  1.83071829e-02, -4.38908152e-02],\n",
            "         [ 1.88432951e-02,  1.76921785e-02, -2.21098643e-02, ...,\n",
            "          -1.19455280e-02,  1.11307967e-02, -4.78710867e-02]],\n",
            "\n",
            "        [[ 1.06597012e-02,  1.65622793e-02,  2.92693228e-02, ...,\n",
            "          -2.81147882e-02, -2.89600585e-02, -4.33591194e-02],\n",
            "         [ 1.02540646e-02, -9.13982280e-03, -5.11519015e-02, ...,\n",
            "          -6.30854815e-02,  9.55084991e-03,  1.29340179e-02],\n",
            "         [-2.29022391e-02, -3.77922803e-02,  4.61317971e-02, ...,\n",
            "           9.81108565e-03, -2.98297126e-02,  5.20708971e-03],\n",
            "         ...,\n",
            "         [ 2.82459948e-02, -3.41511853e-02,  1.48907192e-02, ...,\n",
            "          -1.43076563e-02,  7.61414552e-03, -4.01081480e-02],\n",
            "         [-4.31794189e-02,  1.00996131e-02, -2.36090403e-02, ...,\n",
            "          -2.24208701e-02, -4.86750044e-02,  2.85807420e-02],\n",
            "         [-1.66654568e-02,  3.99571098e-02, -7.88304955e-03, ...,\n",
            "          -5.99134825e-02, -3.63605171e-02, -3.80148441e-02]],\n",
            "\n",
            "        [[-6.91269264e-02,  1.63543765e-02,  4.99849990e-02, ...,\n",
            "           3.41021903e-02,  1.57290734e-02, -8.20999313e-03],\n",
            "         [-1.52167119e-02, -5.23208976e-02,  5.65036051e-02, ...,\n",
            "          -2.23190822e-02, -5.23396842e-02,  2.94354949e-02],\n",
            "         [ 5.46036847e-03, -2.89372429e-02, -2.77133565e-02, ...,\n",
            "           2.77492907e-02,  4.10005711e-02, -3.32115702e-02],\n",
            "         ...,\n",
            "         [ 5.65630943e-02, -4.97538298e-02, -6.80366457e-02, ...,\n",
            "           2.47698817e-02, -1.37100890e-02, -5.44968583e-02],\n",
            "         [ 4.07049358e-02, -1.10238325e-02,  7.16806948e-02, ...,\n",
            "          -5.97804412e-02,  5.53248040e-02,  3.22555266e-02],\n",
            "         [-4.74668033e-02,  6.03934899e-02, -6.28930554e-02, ...,\n",
            "           7.96495192e-03, -3.57329771e-02, -3.27631086e-02]]],\n",
            "\n",
            "\n",
            "       [[[-1.47109069e-02, -2.13734228e-02, -4.31591794e-02, ...,\n",
            "           3.03527154e-02,  5.93918562e-03,  1.45602394e-02],\n",
            "         [-2.52567604e-02, -2.19229870e-02,  3.78275546e-03, ...,\n",
            "           1.80696994e-02,  7.70988350e-04,  1.69863701e-02],\n",
            "         [ 5.01465499e-02,  2.58928984e-02, -4.75610420e-02, ...,\n",
            "          -5.32758981e-02, -2.71638818e-02, -2.56733522e-02],\n",
            "         ...,\n",
            "         [ 8.20724759e-03, -6.28064561e-04, -2.04080585e-02, ...,\n",
            "          -5.89089841e-02,  1.06099648e-02,  4.57167672e-03],\n",
            "         [ 3.76511514e-02, -2.51098373e-03, -2.72113141e-02, ...,\n",
            "          -3.22034098e-02,  6.60089329e-02, -4.90875728e-02],\n",
            "         [-3.22686844e-02,  2.98722796e-02,  9.23188124e-03, ...,\n",
            "          -4.05422747e-02,  5.64024691e-03,  3.90224904e-02]],\n",
            "\n",
            "        [[ 3.17604169e-02, -2.39638815e-04,  3.82634066e-02, ...,\n",
            "           6.75512198e-03,  6.58281520e-02,  2.98829074e-03],\n",
            "         [ 3.03436108e-02, -3.68332585e-05, -1.92433279e-02, ...,\n",
            "          -4.38243803e-03,  1.36107188e-02,  2.96135303e-02],\n",
            "         [ 5.35216648e-04, -1.76741723e-02, -9.78046004e-03, ...,\n",
            "          -4.80848365e-02, -2.77522504e-02,  2.23697294e-02],\n",
            "         ...,\n",
            "         [-3.20159947e-03, -2.91118193e-02, -1.04615251e-02, ...,\n",
            "          -4.21736576e-02, -5.50751053e-02, -4.99359593e-02],\n",
            "         [ 5.37306704e-02,  6.51567243e-03, -6.54909983e-02, ...,\n",
            "           3.74570042e-02,  3.80698778e-02,  2.55944878e-02],\n",
            "         [-3.47326398e-02,  1.34623488e-02, -3.05691883e-02, ...,\n",
            "          -4.47222590e-02, -7.48484358e-02,  7.33466540e-03]],\n",
            "\n",
            "        [[-3.88405770e-02,  2.09760871e-02,  1.39459018e-02, ...,\n",
            "           5.26286382e-03,  2.88935415e-02, -1.60597973e-02],\n",
            "         [-5.55853546e-02, -3.90505902e-02, -3.72958891e-02, ...,\n",
            "          -1.51812090e-02,  6.40489208e-03,  1.15914829e-02],\n",
            "         [ 2.15202719e-02,  3.67557853e-02, -2.29862500e-02, ...,\n",
            "           5.18684101e-05, -9.60408803e-03, -4.00695726e-02],\n",
            "         ...,\n",
            "         [ 2.40077749e-02,  2.04013735e-02,  7.49034956e-02, ...,\n",
            "           1.59944650e-02,  6.21128781e-03, -7.47199496e-03],\n",
            "         [ 2.77580190e-02,  6.48225285e-03,  2.49837004e-02, ...,\n",
            "           1.89593919e-02, -7.36684352e-02,  5.57039818e-03],\n",
            "         [ 2.74767801e-02,  5.52697293e-03, -4.26749140e-03, ...,\n",
            "          -2.98028085e-02, -1.61553584e-02,  1.67382695e-02]],\n",
            "\n",
            "        [[-1.08327186e-02,  3.05207707e-02,  5.91304973e-02, ...,\n",
            "          -1.99068245e-02, -1.76274832e-02, -4.21379134e-03],\n",
            "         [ 3.34181450e-02,  2.86366176e-02, -6.31865859e-02, ...,\n",
            "          -7.11834282e-02, -6.01709113e-02, -3.28716636e-02],\n",
            "         [ 1.81751400e-02,  2.19954997e-02,  5.28866835e-02, ...,\n",
            "           4.37548384e-03, -3.22298296e-02, -6.15999363e-02],\n",
            "         ...,\n",
            "         [ 3.08412220e-03, -6.90751243e-03,  7.81276356e-03, ...,\n",
            "           3.25081535e-02, -1.34820892e-02, -5.28378189e-02],\n",
            "         [-2.08018702e-02,  3.15392688e-02, -1.82845052e-02, ...,\n",
            "          -3.97333428e-02,  3.86953801e-02, -7.03180432e-02],\n",
            "         [ 5.04440702e-02, -6.68801293e-02,  3.94175574e-02, ...,\n",
            "          -1.26902629e-02,  2.99929753e-02,  2.95715220e-02]],\n",
            "\n",
            "        [[-1.59359165e-02,  4.36164923e-02,  3.58269252e-02, ...,\n",
            "          -6.39226474e-03, -2.47578900e-02, -5.03797866e-02],\n",
            "         [-2.34387070e-02,  3.98522951e-02,  4.70131375e-02, ...,\n",
            "           5.61866444e-03, -3.16274166e-02,  1.96200106e-02],\n",
            "         [-2.46363948e-03, -3.68578872e-03,  6.01382228e-04, ...,\n",
            "          -1.25157591e-02,  3.82496305e-02, -4.10522856e-02],\n",
            "         ...,\n",
            "         [-3.29894684e-02, -1.14884377e-02, -5.14664836e-02, ...,\n",
            "          -2.23311421e-04,  4.50952686e-02,  1.62726566e-02],\n",
            "         [-8.86850804e-03,  1.14904102e-02,  5.38946874e-02, ...,\n",
            "          -3.30041721e-02, -3.09819970e-02, -1.18337907e-02],\n",
            "         [-4.55634147e-02,  1.56242428e-02, -4.43883017e-02, ...,\n",
            "          -4.49500829e-02, -4.17002365e-02, -3.13092172e-02]]],\n",
            "\n",
            "\n",
            "       [[[ 9.22429189e-03,  3.39182429e-02, -1.92059414e-03, ...,\n",
            "          -4.31835577e-02,  5.56075647e-02, -4.47544195e-02],\n",
            "         [-5.55711314e-02, -2.25963965e-02,  3.92502360e-02, ...,\n",
            "           1.28055864e-03, -4.07721214e-02, -5.26868962e-02],\n",
            "         [-1.41465990e-03, -5.92341973e-03,  4.10212651e-02, ...,\n",
            "          -8.93625803e-03, -5.43035679e-02, -7.62257501e-02],\n",
            "         ...,\n",
            "         [ 2.58667883e-03,  3.13026123e-02,  5.11067286e-02, ...,\n",
            "           1.81939211e-02, -7.76391942e-03, -7.50063807e-02],\n",
            "         [-3.83530222e-02, -3.19735147e-02, -2.51984689e-02, ...,\n",
            "           2.83570234e-02,  3.00809853e-02, -6.65410422e-03],\n",
            "         [-3.02464478e-02, -3.86583842e-02, -4.57619987e-02, ...,\n",
            "          -4.02376242e-02, -3.59187499e-02, -9.12713166e-03]],\n",
            "\n",
            "        [[-9.19300597e-03,  1.21812103e-02, -2.14976911e-02, ...,\n",
            "          -3.74666713e-02,  4.86731306e-02, -8.02905336e-02],\n",
            "         [ 2.20770715e-03, -1.53898280e-02,  2.83312183e-02, ...,\n",
            "           4.04055007e-02,  7.96817616e-03,  3.71610522e-02],\n",
            "         [-6.24203309e-02, -2.45939177e-02,  4.69833985e-02, ...,\n",
            "           2.99848747e-02, -5.92027754e-02, -7.36010149e-02],\n",
            "         ...,\n",
            "         [-2.64424365e-02,  3.39784808e-02,  2.31925659e-02, ...,\n",
            "          -4.59282324e-02, -7.62618631e-02, -2.89086271e-02],\n",
            "         [-4.23207805e-02,  2.17528716e-02,  1.75314061e-02, ...,\n",
            "           2.71329079e-02, -3.44035886e-02, -3.73851284e-02],\n",
            "         [ 4.47522961e-02, -5.14696352e-02, -3.44896391e-02, ...,\n",
            "           2.14561317e-02, -6.96476400e-02, -4.29606512e-02]],\n",
            "\n",
            "        [[-8.77351016e-02,  2.43457500e-03,  4.56282310e-02, ...,\n",
            "           3.18002771e-03, -2.89922655e-02, -1.66321686e-03],\n",
            "         [-5.74254571e-03, -5.95024563e-02,  2.46926416e-02, ...,\n",
            "          -1.58949243e-03, -4.72365804e-02, -4.07959446e-02],\n",
            "         [-5.85136563e-02, -6.49354905e-02,  6.41711578e-02, ...,\n",
            "          -3.19589972e-02,  9.63600166e-03, -6.54925331e-02],\n",
            "         ...,\n",
            "         [-7.55707771e-02,  5.90434065e-03,  4.25714627e-02, ...,\n",
            "          -1.12364041e-02,  7.69516779e-03, -4.14437875e-02],\n",
            "         [-6.41394183e-02, -5.19682579e-02,  3.56529355e-02, ...,\n",
            "           2.27406174e-02, -3.93667929e-02,  2.01816522e-02],\n",
            "         [ 8.18857364e-03,  2.82413159e-02, -4.69519310e-02, ...,\n",
            "           3.81898768e-02, -4.24145684e-02,  1.41469268e-02]],\n",
            "\n",
            "        [[-6.22253828e-02, -5.74073158e-02,  5.47088534e-02, ...,\n",
            "          -3.58796827e-02,  8.43567699e-02, -6.45721480e-02],\n",
            "         [-7.11841136e-02,  2.54714750e-02,  2.67274212e-02, ...,\n",
            "          -5.20857004e-03, -1.04791269e-01,  2.46162452e-02],\n",
            "         [-6.01734258e-02, -3.09951743e-03, -3.13127227e-02, ...,\n",
            "          -3.08307707e-02, -3.58155295e-02, -6.68849889e-03],\n",
            "         ...,\n",
            "         [-6.31195009e-02, -6.43095234e-03, -2.28489321e-02, ...,\n",
            "           5.14784455e-02,  6.09602183e-02,  1.48598570e-02],\n",
            "         [-5.65921776e-02,  4.01845165e-02,  3.72899286e-02, ...,\n",
            "          -7.30977431e-02, -2.27724034e-02, -4.73427512e-02],\n",
            "         [ 5.22604398e-02,  1.11572975e-02, -1.27439033e-02, ...,\n",
            "           2.92617101e-02, -2.70057283e-02, -1.06929699e-02]],\n",
            "\n",
            "        [[-2.28155311e-02,  2.71554012e-02,  7.48736039e-02, ...,\n",
            "          -5.42274527e-02,  3.24514322e-02,  9.15808976e-03],\n",
            "         [-1.01223020e-02,  1.18102282e-02,  5.73204122e-02, ...,\n",
            "          -3.80229577e-02, -6.48240447e-02,  4.07350622e-02],\n",
            "         [ 3.40085775e-02,  1.15216458e-02,  2.50772890e-02, ...,\n",
            "           3.08214929e-02,  4.84451838e-02,  1.73738785e-02],\n",
            "         ...,\n",
            "         [ 3.96390678e-03,  2.63918713e-02, -5.83991874e-03, ...,\n",
            "           2.93988995e-02,  1.73910391e-02, -2.19977763e-03],\n",
            "         [-3.97358537e-02, -2.56265253e-02,  1.76584558e-03, ...,\n",
            "          -3.85182239e-02,  1.43882185e-02, -2.59581152e-02],\n",
            "         [-2.11551739e-03, -8.33687838e-03, -3.19235697e-02, ...,\n",
            "          -2.87040020e-03,  1.45981985e-03,  3.41923274e-02]]]],\n",
            "      dtype=float32), array([-0.01397127, -0.00803355, -0.01030315, -0.01142255, -0.00686215,\n",
            "       -0.01456433, -0.01701651, -0.00211021, -0.01325091, -0.00185106,\n",
            "       -0.00809239, -0.01575415, -0.02015426, -0.02055188, -0.00137216,\n",
            "       -0.00123116, -0.01553204, -0.00189935, -0.0112841 , -0.0297249 ,\n",
            "       -0.01554384, -0.02419116, -0.00395152, -0.0186611 , -0.00406495,\n",
            "       -0.01467629, -0.00773042, -0.01161422, -0.01618112, -0.01026381,\n",
            "       -0.01415686, -0.00556741, -0.02169172, -0.01024496, -0.01241349,\n",
            "       -0.00084113, -0.01689601, -0.01118686,  0.00295825, -0.01844706,\n",
            "       -0.00853158, -0.01501093, -0.0073718 , -0.00536679, -0.00221453,\n",
            "       -0.00706804, -0.008244  , -0.0048637 ,  0.00066331, -0.01631674,\n",
            "       -0.0094562 , -0.00784195, -0.00598421, -0.0106616 , -0.01522474,\n",
            "       -0.01748279, -0.01056413, -0.00400737, -0.00343837, -0.00925712,\n",
            "       -0.01002279, -0.00624363, -0.02134082, -0.0078877 ], dtype=float32), array([[-0.02382648, -0.00112582, -0.03050778, ..., -0.01876406,\n",
            "        -0.01711982, -0.04530266],\n",
            "       [ 0.00608783,  0.06341223,  0.01614514, ...,  0.02014474,\n",
            "        -0.01650948, -0.02852497],\n",
            "       [-0.02455414,  0.06137914,  0.00934902, ...,  0.02233061,\n",
            "         0.03470473,  0.03192067],\n",
            "       ...,\n",
            "       [-0.01326024,  0.03453899,  0.02914789, ..., -0.0142374 ,\n",
            "        -0.001808  ,  0.03260809],\n",
            "       [-0.01847435,  0.05208766,  0.0109686 , ..., -0.03369562,\n",
            "         0.01603646,  0.02758654],\n",
            "       [-0.00556756, -0.03708549,  0.01877246, ...,  0.00892684,\n",
            "         0.06949864, -0.03339125]], dtype=float32), array([ 9.60628595e-03,  3.85147426e-03, -5.55666117e-03,  7.61642354e-03,\n",
            "       -5.53960353e-03,  5.43812802e-03,  8.50458723e-03, -6.00392418e-03,\n",
            "       -5.29473694e-03,  9.16246790e-03,  2.56255851e-03,  1.40004163e-03,\n",
            "        7.32315285e-03, -6.22351374e-03,  8.47999938e-03, -5.22332825e-03,\n",
            "       -6.00286433e-03, -1.23114930e-03, -5.52662695e-03,  4.70224489e-03,\n",
            "        4.17368254e-03, -8.03257717e-06, -1.73721660e-03,  3.00399167e-03,\n",
            "       -2.39476748e-03, -5.82233397e-03,  1.24238839e-03, -6.00303430e-03,\n",
            "       -6.00517448e-03, -6.00419985e-03,  4.96609323e-03,  2.61505577e-03,\n",
            "        1.09032039e-02,  2.13873223e-03,  5.03668142e-03, -6.00453420e-03,\n",
            "       -2.92307674e-03, -6.95516216e-03, -6.00134116e-03, -3.32075031e-03,\n",
            "        5.84805477e-03, -2.58259010e-03,  3.28196143e-03,  7.16724154e-03,\n",
            "       -4.37636115e-03, -1.15484465e-02,  2.23548058e-03,  6.75299391e-03,\n",
            "        5.57828462e-04,  6.01417199e-03,  7.77017791e-03, -7.72066833e-03,\n",
            "        1.04684830e-02,  6.00104686e-04, -8.83442257e-03,  6.01267023e-03,\n",
            "        5.56370569e-03, -6.00218121e-03,  2.68262275e-03,  9.11173047e-05,\n",
            "        1.09874383e-02, -6.00330997e-03, -1.73666538e-03, -6.00495562e-03,\n",
            "        9.56755690e-03,  9.57065448e-03,  5.28263673e-03,  7.11507211e-03,\n",
            "       -7.56660476e-03,  6.22164551e-03, -6.00465480e-03,  1.39676658e-02,\n",
            "        2.60621891e-04, -6.87185535e-03, -2.39845295e-03, -8.11520312e-03,\n",
            "       -7.76646845e-03, -7.62882642e-03, -6.00445922e-03, -1.49475057e-02,\n",
            "       -6.00344921e-03,  6.75101546e-06, -6.00445969e-03, -6.00395491e-03,\n",
            "       -9.49058216e-03, -1.23443743e-02,  2.21837056e-03, -1.21148210e-03,\n",
            "       -6.00484619e-03,  2.87376065e-03, -5.50720794e-03,  3.08330898e-04,\n",
            "       -6.00129692e-03, -6.36914279e-03, -2.55120732e-03,  6.70334883e-03,\n",
            "       -5.34426700e-03, -7.58648617e-03, -5.89044811e-03,  7.96342082e-03,\n",
            "       -6.00472419e-03, -4.92875418e-03, -5.40426001e-03,  6.96191844e-03,\n",
            "       -6.00448158e-03, -7.91060086e-03,  2.23536650e-03,  7.70157017e-03,\n",
            "        4.06351453e-03, -6.00358984e-03,  2.45267316e-03,  8.66230670e-03,\n",
            "       -8.71981215e-03,  3.25055444e-03, -2.87735392e-03,  1.03293303e-02,\n",
            "       -2.65743979e-03,  6.73459377e-03, -1.06566669e-02, -6.00476516e-03,\n",
            "       -1.38795208e-02,  8.69454889e-05, -6.13902882e-03,  6.21216884e-03,\n",
            "        8.91000312e-03, -5.99005865e-03,  4.08904487e-03,  4.38689347e-03,\n",
            "        3.20232729e-03, -7.26392353e-03,  5.64501481e-03,  1.06616933e-02,\n",
            "       -5.99639351e-03, -5.50264725e-03,  5.20354323e-03, -5.51827718e-03,\n",
            "        8.44719168e-03, -9.55789909e-03, -6.00448903e-03, -7.58736581e-03,\n",
            "        7.37540144e-03, -6.00282988e-03,  5.58247883e-03,  4.72300034e-03,\n",
            "        1.29051728e-03,  1.31965266e-03, -6.00449555e-03, -6.44747540e-03,\n",
            "        3.65313492e-03,  2.75003747e-03,  4.00893623e-05, -2.46049045e-03,\n",
            "        1.54973427e-03, -7.09606148e-03, -1.69452163e-03, -6.00324664e-03,\n",
            "        9.26813984e-04, -2.54288781e-03,  4.85790335e-03, -5.77321835e-03,\n",
            "        4.74275835e-03, -6.00249367e-03,  3.98733001e-03,  6.03943656e-04,\n",
            "       -1.27306515e-02, -5.34534361e-03, -5.22247888e-03, -6.73630740e-03,\n",
            "       -6.00369507e-03,  7.43967423e-04,  1.49359438e-03,  2.08738144e-03,\n",
            "        1.97887956e-03, -8.19514226e-03, -7.32206926e-03, -5.22614131e-03,\n",
            "        4.46259091e-03,  7.01236911e-03,  1.38379377e-03, -1.28331664e-03,\n",
            "       -5.24680410e-03, -6.00439869e-03,  5.34891442e-04, -6.00419985e-03,\n",
            "       -2.25364510e-03,  1.10661732e-02,  1.09123215e-02, -2.66913092e-03,\n",
            "       -6.00362848e-03, -6.00105152e-03, -5.99364238e-03, -5.34640206e-03,\n",
            "       -6.00473583e-03,  6.17006933e-03,  4.40843264e-03, -5.11375349e-03,\n",
            "       -3.19665950e-03, -6.00440707e-03,  3.78181506e-03, -1.08415568e-02,\n",
            "       -6.22195285e-03,  3.58902686e-03, -5.99777699e-03, -4.74607153e-03,\n",
            "       -6.23042462e-03, -5.54592814e-03, -1.10679865e-03, -6.60373596e-03,\n",
            "       -2.39966880e-03,  3.90368374e-03, -5.22330822e-03,  7.91831687e-03,\n",
            "        7.44515099e-03, -6.00464409e-03,  2.67593726e-03,  5.77134779e-03,\n",
            "       -6.00396749e-03,  5.71848359e-03, -3.68856569e-03, -6.00493560e-03,\n",
            "       -8.57229810e-03, -5.90675138e-03,  2.61907047e-03,  1.09701678e-02,\n",
            "       -7.22591439e-03, -6.00514235e-03,  4.51478455e-03, -3.93646350e-03,\n",
            "        8.68661888e-03, -6.00434979e-03, -2.83929915e-03,  1.14901066e-02,\n",
            "       -5.55812754e-03,  2.61090160e-03, -6.00464735e-03,  7.82820676e-03,\n",
            "        8.35855585e-03, -5.22534549e-03, -5.99804847e-03, -1.33440841e-03,\n",
            "       -5.78736374e-03, -8.90394486e-03,  7.78241130e-03, -4.65443544e-03,\n",
            "        4.06940002e-03, -6.74972136e-04, -6.05034176e-03,  5.10324677e-03,\n",
            "       -5.09556709e-03, -7.56254699e-03, -3.19841714e-03,  4.73648543e-04,\n",
            "       -7.71438563e-03, -4.58774436e-03,  1.04905767e-02, -2.44223443e-03,\n",
            "        7.89655652e-03,  1.22957649e-02, -1.58663350e-03, -3.74119845e-03,\n",
            "       -6.00431487e-03, -4.19290876e-03, -6.00444712e-03,  8.33051652e-03,\n",
            "       -5.15396381e-03,  5.35259536e-03, -3.92540544e-03, -1.81415286e-02,\n",
            "       -6.00422174e-03,  3.12335440e-03, -3.79081140e-03, -6.00385107e-03,\n",
            "       -1.72507355e-03,  1.23926960e-02,  7.22025102e-03,  1.10785235e-02,\n",
            "       -6.00417843e-03,  8.59737769e-03, -4.67166211e-03,  4.06646356e-03,\n",
            "        4.56470251e-03, -4.91880870e-04,  1.30842533e-02, -3.02586285e-03,\n",
            "       -7.41833961e-03,  9.31851473e-03,  5.10947502e-05,  3.07731167e-03,\n",
            "        4.53977380e-03,  4.98036109e-03, -6.00373279e-03,  8.27116240e-03,\n",
            "       -5.34349727e-03,  5.79306856e-03, -6.00424036e-03,  6.78249728e-03,\n",
            "        5.30035794e-03,  8.26341938e-03,  1.04919327e-02, -5.31775039e-03,\n",
            "       -6.00443780e-03, -6.28700433e-03,  5.57090109e-03, -6.24711951e-03,\n",
            "        5.63969463e-03, -4.07969020e-03,  8.66654911e-04, -5.22461487e-03,\n",
            "       -6.04689587e-03, -6.09184196e-03, -4.98273829e-03, -5.14937798e-04,\n",
            "        9.32231918e-03,  5.89560531e-03, -6.00422313e-03,  5.05323242e-03,\n",
            "        1.56995077e-02, -5.70355100e-04,  2.59148073e-03,  4.29759547e-03,\n",
            "       -8.54808465e-03, -6.00328250e-03,  4.47122427e-03,  1.44906696e-02,\n",
            "        8.58837552e-03,  9.39557049e-03,  3.33365775e-03, -1.09264499e-03,\n",
            "       -5.11242775e-03,  3.13843461e-03,  5.04025072e-03, -8.55493080e-03,\n",
            "        5.60547318e-03,  4.52744449e-03,  4.11085831e-03,  6.71620294e-03,\n",
            "       -2.86388968e-04, -6.00151019e-03, -6.42309804e-03, -6.00418402e-03,\n",
            "       -5.34567703e-03,  7.18376087e-03,  5.35870716e-03,  1.53060525e-03,\n",
            "        6.75285235e-03,  1.79218629e-03,  3.53460596e-03, -9.16378945e-03,\n",
            "       -7.86365755e-03,  2.84624565e-03,  1.10805081e-02, -4.20073187e-03,\n",
            "       -9.05712508e-03, -6.39249803e-03, -4.34575509e-03, -5.22690779e-03,\n",
            "        7.07175024e-03,  3.30258557e-03,  1.05298273e-02,  2.16843560e-03,\n",
            "       -5.12305880e-03, -6.57688454e-03,  3.99548188e-03,  6.07937900e-03,\n",
            "        1.10866539e-02,  8.90656747e-03,  9.22593474e-03, -5.61819412e-03,\n",
            "       -5.99462120e-03,  6.98214211e-03, -2.19730555e-05, -5.15942369e-03,\n",
            "       -1.43643213e-03,  2.71701138e-03,  5.78830903e-03, -6.00477075e-03,\n",
            "        4.73183766e-03, -5.55340992e-03, -2.63266475e-03, -6.00515259e-03,\n",
            "       -6.43221149e-03, -1.13731634e-03, -6.00266363e-03, -6.00472512e-03,\n",
            "        1.08264925e-04,  8.27386219e-04, -9.89615265e-03, -7.60387571e-04,\n",
            "        6.25320303e-04, -8.47105402e-03, -2.96977628e-03,  3.32046603e-03,\n",
            "       -6.00336771e-03, -5.54382289e-03, -6.00477075e-03, -7.16491509e-03,\n",
            "       -5.99175878e-03, -1.44267606e-03, -6.00376306e-03, -8.42760224e-03,\n",
            "        4.76670306e-04, -6.00496028e-03,  5.58111304e-03, -3.51714436e-03,\n",
            "       -5.55788912e-03,  1.12480372e-02, -7.93454144e-03,  1.82495895e-03,\n",
            "       -2.21964926e-03, -6.00405317e-03,  2.11182050e-03,  9.16000828e-03,\n",
            "        8.70302226e-03,  4.84033627e-03,  2.90908618e-03, -5.79859875e-03,\n",
            "        8.98137875e-03,  9.64032486e-03,  6.83032209e-03, -6.00134814e-03,\n",
            "       -6.00302219e-03, -5.59340697e-03, -6.00464968e-03,  3.16066225e-03,\n",
            "       -2.26631970e-03, -8.17389321e-03,  1.70608191e-03,  7.06441887e-03,\n",
            "       -6.80509768e-03,  2.30756728e-03,  7.57752871e-03,  7.23352982e-03,\n",
            "        1.48725677e-02, -2.38562212e-03, -6.00462733e-03, -1.74472737e-03,\n",
            "       -3.73711041e-03, -6.00347994e-03,  2.54055997e-03,  2.83885095e-03,\n",
            "        5.47457719e-04,  2.69055320e-03, -2.04204768e-03, -1.38543372e-03,\n",
            "        1.24198338e-03, -5.99359535e-03,  2.07034219e-03,  4.66133282e-03,\n",
            "       -4.80704848e-03, -6.00131787e-03,  3.24511155e-03, -5.68853598e-03,\n",
            "       -5.62518649e-03, -6.56762975e-04, -5.51215420e-03,  1.49809392e-02,\n",
            "       -1.57269568e-03,  1.09107548e-03, -2.11473205e-03, -1.59048577e-04,\n",
            "        4.46650991e-03, -5.55528980e-03, -6.00090763e-03, -5.12975408e-03,\n",
            "        2.98768724e-03, -6.00480940e-03,  1.23157045e-02, -1.20420055e-03,\n",
            "        1.84993187e-05,  4.33457410e-03,  2.37017800e-03, -6.00341521e-03,\n",
            "       -7.95305241e-03, -8.38720053e-03, -5.31330286e-03, -6.00298634e-03,\n",
            "       -5.11120260e-03,  7.44714867e-03, -2.44993158e-03, -8.85816664e-03,\n",
            "       -6.00306969e-03, -6.00317307e-03, -5.36501314e-03,  8.60809349e-03,\n",
            "       -5.28276479e-03,  1.35164184e-03,  4.23155166e-03, -5.22457995e-03,\n",
            "        9.78087890e-04, -6.00156561e-03, -1.62428170e-02, -6.40362361e-03,\n",
            "        8.72608647e-03,  1.12297861e-02, -1.51935359e-02,  2.49869027e-03,\n",
            "        1.00816914e-03,  6.54772157e-04, -6.11295970e-03, -5.13030263e-03,\n",
            "        0.00000000e+00, -5.12329256e-03, -6.00418122e-03,  9.47550032e-03,\n",
            "       -6.00261474e-03,  1.64961664e-03, -3.23923235e-03,  4.97116800e-03,\n",
            "       -9.20874253e-03, -9.62749310e-03,  5.48235839e-03, -6.00345805e-03],\n",
            "      dtype=float32), array([[-0.04342376, -0.04609724, -0.00580098, ..., -0.13526598,\n",
            "         0.07337307, -0.05325136],\n",
            "       [-0.11429611,  0.01609852,  0.09758894, ..., -0.00336347,\n",
            "         0.085637  ,  0.04438603],\n",
            "       [ 0.08587699,  0.05110275, -0.04980787, ..., -0.11044256,\n",
            "         0.07270978, -0.03889981],\n",
            "       ...,\n",
            "       [ 0.10954465,  0.05695121, -0.06280988, ..., -0.02740169,\n",
            "         0.07159123, -0.03690017],\n",
            "       [ 0.10603425,  0.06799152, -0.0624066 , ..., -0.04706323,\n",
            "        -0.0390465 ,  0.07844747],\n",
            "       [ 0.06420122, -0.06873565, -0.10115771, ...,  0.0089101 ,\n",
            "        -0.05313844, -0.00574606]], dtype=float32), array([-1.2850157e-03, -3.9446973e-03, -5.9197401e-03, -1.1145604e-03,\n",
            "        2.5268365e-03, -6.4228851e-05, -1.9983456e-03, -3.6506508e-03,\n",
            "        5.2977032e-03,  3.0452155e-03], dtype=float32)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KHN6OV4VpKB1",
        "outputId": "cbf25610-cc19-4d78-9183-5d5cc05a7a32"
      },
      "source": [
        "print(type(local_parameter))"
      ],
      "id": "KHN6OV4VpKB1",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'list'>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kppstqHiqiP0",
        "outputId": "fa38c29f-a341-450b-ee58-c8ca7b7074c5"
      },
      "source": [
        "model_array = np.asarray(local_parameter)"
      ],
      "id": "kppstqHiqiP0",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/numpy/core/_asarray.py:83: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  return array(a, dtype, copy=False, order=order)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k7TZ7c4qqpOU"
      },
      "source": [
        "parameter_saver.save_aggreated_global_parameter(global_parameter)\r\n",
        "parameter_saver.save_local_parameter(1, local_parameter)"
      ],
      "id": "k7TZ7c4qqpOU",
      "execution_count": 26,
      "outputs": []
    }
  ]
}